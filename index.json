[{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/prerequis/","title":"Prérequis","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/fleet/","title":"Fleet &amp; Elastic Agent","tags":[],"description":"","content":"Serveur Fleet Fleet Server est un composant de la pile Elastic utilisé pour gérer de manière centralisée les agents Elastic. Il est lancé en tant que partie d\u0026rsquo;un agent Elastic sur un hôte destiné à servir de serveur. Un processus Fleet Server peut prendre en charge de nombreuses connexions d\u0026rsquo;agents Elastic et sert de plan de contrôle pour la mise à jour des stratégies d\u0026rsquo;agents, la collecte d\u0026rsquo;informations d\u0026rsquo;état et la coordination des actions entre les agents Elastic.\nFleet Server est le mécanisme utilisé par les agents Elastic pour communiquer avec Elasticsearch :\n Lorsqu\u0026rsquo;une nouvelle politique d\u0026rsquo;agent est créée, elle est enregistrée dans Elasticsearch. Pour s\u0026rsquo;inscrire à la politique, les agents Elastic envoient une demande à Fleet Server, en utilisant la clé d\u0026rsquo;inscription générée pour l\u0026rsquo;authentification. Le serveur Fleet reçoit la demande et extrait la politique d\u0026rsquo;agent d\u0026rsquo;Elasticsearch, puis l\u0026rsquo;envoie à tous les agents Elastic inscrits à cette politique. L\u0026rsquo;agent Elastic utilise les informations de configuration de la politique pour collecter et envoyer des données à Elasticsearch. Elastic Agent vérifie les mises à jour auprès de Fleet Server, en maintenant une connexion ouverte. Lorsqu\u0026rsquo;une politique est mise à jour, Fleet Server récupère la politique mise à jour dans Elasticsearch et l\u0026rsquo;envoie aux agents Elastic connectés.  Ajoutez les deux services ci-dessous dans le fichier elastic-docker-tls.yml :\n package-registry:\rimage: docker.elastic.co/package-registry/distribution:${VERSION}\rcontainer_name: package-registry\rports:\r- 443\renvironment:\r- EPR_ADDRESS=0.0.0.0:443\r- EPR_TLS_KEY=$CERTS_DIR/package-registry/package-registry.key\r- EPR_TLS_CERT=$CERTS_DIR/package-registry/package-registry.crt\rhealthcheck:\rtest: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost/health \u0026gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi\rretries: 100\rinterval: 5s\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rfleet-server:\rimage: docker.elastic.co/beats/elastic-agent:${VERSION}\rcontainer_name: fleet-server\rports:\r- 8220:8220\rhealthcheck:\rtest: [\u0026quot;CMD-SHELL\u0026quot;, \u0026quot;curl -s -k https://localhost:8220/api/status | grep -q 'HEALTHY'\u0026quot;]\rretries: 300\rinterval: 1s\renvironment:\rFLEET_SERVER_ENABLE: \u0026quot;1\u0026quot;\rELASTICSEARCH_HOST: \u0026quot;https://es01:9200\u0026quot;\rELASTICSEARCH_CA: $CERTS_DIR/ca/ca.crt\rELASTICSEARCH_USERNAME: elastic\rELASTICSEARCH_PASSWORD: CHANGEME\rFLEET_URL: \u0026quot;https://fleet-server:8220\u0026quot;\rFLEET_SERVER_CERT: $CERTS_DIR/fleet-server/fleet-server.crt\rFLEET_SERVER_CERT_KEY: $CERTS_DIR/fleet-server/fleet-server.key\rKIBANA_FLEET_SETUP: \u0026quot;true\u0026quot;\rKIBANA_HOST: \u0026quot;https://kib01:5601\u0026quot;\rKIBANA_USERNAME: elastic\rKIBANA_PASSWORD: CHANGEME\rKIBANA_CA: $CERTS_DIR/ca/ca.crt\rdepends_on:\res01: { condition: service_healthy }\rkib01: { condition: service_healthy }\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rDéfinissez ELASTICSEARCH_PASSWORD et KIBANA_PASSWORD dans le fichier elastic-docker-tls.yml avec le mot de passe généré pour l\u0026rsquo;utilisateur elastic.\nfleet-server:\rimage: docker.elastic.co/beats/elastic-agent:${VERSION}\rcontainer_name: fleet-server\rports:\r- 8220:8220\rhealthcheck:\rtest: [\u0026quot;CMD-SHELL\u0026quot;, \u0026quot;curl -s -k https://localhost:8220/api/status | grep -q 'HEALTHY'\u0026quot;]\rretries: 300\rinterval: 1s\renvironment:\rFLEET_SERVER_ENABLE: \u0026quot;1\u0026quot;\rELASTICSEARCH_HOST: \u0026quot;https://es01:9200\u0026quot;\rELASTICSEARCH_CA: $CERTS_DIR/ca/ca.crt\rELASTICSEARCH_USERNAME: elastic\rELASTICSEARCH_PASSWORD: CHANGEME\rFLEET_URL: \u0026quot;https://fleet-server:8220\u0026quot;\rFLEET_SERVER_CERT: $CERTS_DIR/fleet-server/fleet-server.crt\rFLEET_SERVER_CERT_KEY: $CERTS_DIR/fleet-server/fleet-server.key\rKIBANA_FLEET_SETUP: \u0026quot;true\u0026quot;\rKIBANA_HOST: \u0026quot;https://kib01:5601\u0026quot;\rKIBANA_USERNAME: elastic\rKIBANA_PASSWORD: CHANGEME\rKIBANA_CA: $CERTS_DIR/ca/ca.crt\rdocker-compose -f elastic-docker-tls.yml up -d\rVérifiez la connexion entre le serveur Fleet et Kibana :\nManagement -\u0026gt; Fleet\nServeur APM Ajoutez le service ELastic Agent dans le fichier elastic-docker-tls.yml : :\n elastic-agent:\rimage: docker.elastic.co/beats/elastic-agent-complete:${VERSION}\rcontainer_name: elastic-agent\rrestart: always\ruser: root # note, synthetic browser monitors require this set to `elastic-agent`\renvironment:\rFLEET_ENROLL: 1\rFLEET_URL: \u0026quot;https://fleet-server:8220\u0026quot;\rFLEET_TOKEN_POLICY_NAME: \u0026quot;Default policy\u0026quot;\rFLEET_CA: $CERTS_DIR/ca/ca.crt\rKIBANA_FLEET_HOST: https://kib01:5601\rKIBANA_FLEET_USERNAME: elastic\rKIBANA_FLEET_PASSWORD: CHANGEME\rKIBANA_FLEET_CA: $CERTS_DIR/ca/ca.crt\rdepends_on:\res01: { condition: service_healthy }\rfleet-server: { condition: service_healthy }\rvolumes:\r- certs:$CERTS_DIR\r- /var/run/docker.sock:/var/run/docker.sock:ro\r- /var/log:/var/log:ro\r- /var/lib/docker/containers:/var/lib/docker/containers:ro\r- /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\r- /proc:/hostfs/proc:ro\r- /:/hostfs:ro\rnetworks:\r- elastic\rModifier la configuration par défaut des agents elastic via le serveur fleet sur l\u0026rsquo;interface Kibana :\nManagement -\u0026gt; Fleet\nCliquez sur Fleet settings\nFleet Server Hosts\nhttps://fleet-server:8220\rElasticsearch Output Configuration (YAML)\nssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\rDéfinissez KIBANA_FLEET_PASSWORD dans le fichier elastic-docker-tls.yml avec le mot de passe généré pour l\u0026rsquo;utilisateur elastic.\n elastic-agent:\rimage: docker.elastic.co/beats/elastic-agent-complete:${VERSION}\rcontainer_name: elastic-agent\rrestart: always\ruser: root # note, synthetic browser monitors require this set to `elastic-agent`\renvironment:\rFLEET_ENROLL: 1\rFLEET_URL: \u0026quot;https://fleet-server:8220\u0026quot;\rFLEET_TOKEN_POLICY_NAME: \u0026quot;Default policy\u0026quot;\rFLEET_CA: $CERTS_DIR/ca/ca.crt\rKIBANA_FLEET_HOST: https://kib01:5601\rKIBANA_FLEET_USERNAME: elastic\rKIBANA_FLEET_PASSWORD: CHANGEME\rKIBANA_FLEET_CA: $CERTS_DIR/ca/ca.crt\rdepends_on:\res01: { condition: service_healthy }\rfleet-server: { condition: service_healthy }\rvolumes:\r- certs:$CERTS_DIR\r- /var/run/docker.sock:/var/run/docker.sock:ro\r- /var/log:/var/log:ro\r- /var/lib/docker/containers:/var/lib/docker/containers:ro\r- /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\r- /proc:/hostfs/proc:ro\r- /:/hostfs:ro\rnetworks:\r- elastic\rAprès quelques minutes vous devez voir apparaitre l\u0026rsquo;agent elastic sur l\u0026rsquo;interface Kibana.\nIntégration du module APM "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/prerequis/installation/","title":"Installation","tags":[],"description":"","content":"Prérequis  Ubuntu ou Debian Docker Exécuter la commande ci-dessous  sudo sysctl -w vm.max_map_count=262144\rDéployer la stack Elasticsearch Kibana dans Docker avec TLS activé Si les fonctions de sécurité sont activées, vous devez configurer le chiffrement TLS (Transport Layer Security) pour la couche de transport d\u0026rsquo;Elasticsearch. Bien qu\u0026rsquo;il soit possible d\u0026rsquo;utiliser une licence d\u0026rsquo;essai sans configurer TLS, nous vous conseillons de sécuriser votre pile dès le départ.\nPour obtenir un cluster Elasticsearch et Kibana opérationnel dans Docker avec la sécurité activée, vous pouvez utiliser Docker Compose :\nCréez les fichiers de composition et de configuration suivants. Ces fichiers sont également disponibles dans le dépôt elastic/stack-docs sur GitHub.\ninstances.yml identifie les instances pour lesquelles vous devez créer des certificats. .env définit des variables d\u0026rsquo;environnement pour spécifier la version d\u0026rsquo;Elasticsearch et l\u0026rsquo;emplacement où les certificats Elasticsearch seront créés. create-certs.yml est un fichier Docker Compose qui lance un conteneur pour générer les certificats pour Elasticsearch et Kibana. elastic-docker-tls.yml est un fichier Docker Compose qui met en place un cluster Elasticsearch à trois nœuds et une instance Kibana avec TLS activé afin que vous puissiez voir comment les choses fonctionnent. Cette configuration tout-en-un est un moyen pratique de mettre en place votre premier cluster de développement avant de construire un déploiement distribué avec plusieurs hôtes.\ninstances.yml :\ninstances:\r- name: es01\rdns:\r- es01\r- localhost\rip:\r- 127.0.0.1\r- name: es02\rdns:\r- es02\r- localhost\rip:\r- 127.0.0.1\r- name: es03\rdns:\r- es03\r- localhost\rip:\r- 127.0.0.1\r- name: 'kib01'\rdns:\r- kib01\r- localhost\r- name: 'package-registry'\rdns:\r- package-registry\r- localhost\r- name: 'fleet-server'\rdns:\r- fleet-server\r- localhost\r.env:\nCOMPOSE_PROJECT_NAME=es\rCERTS_DIR=/usr/share/elasticsearch/config/certificates\rVERSION=7.17.0\rcreate-certs.yml:\nversion: '2.2'\rservices:\rcreate_certs:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: create_certs\rcommand: \u0026gt;\rbash -c '\ryum install -y -q -e 0 unzip;\rif [[ ! -f /certs/bundle.zip ]]; then\rbin/elasticsearch-certutil cert --silent --pem --in config/certificates/instances.yml -out /certs/bundle.zip;\runzip /certs/bundle.zip -d /certs;\rfi;\rchown -R 1000:0 /certs\r'\rworking_dir: /usr/share/elasticsearch\rvolumes:\r- certs:/certs\r- .:/usr/share/elasticsearch/config/certificates\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge\relastic-docker-tls.yml:\nversion: '2.2'\rservices:\res01:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: es01\renvironment:\r- node.name=es01\r- cluster.name=es-docker-cluster\r- discovery.seed_hosts=es02,es03\r- cluster.initial_master_nodes=es01,es02,es03\r- bootstrap.memory_lock=true\r- \u0026quot;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026quot;\r- xpack.license.self_generated.type=trial\r- xpack.security.enabled=true\r- xpack.security.http.ssl.enabled=true\r- xpack.security.http.ssl.key=$CERTS_DIR/es01/es01.key\r- xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.http.ssl.certificate=$CERTS_DIR/es01/es01.crt\r- xpack.security.transport.ssl.enabled=true\r- xpack.security.transport.ssl.verification_mode=certificate\r- xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.transport.ssl.certificate=$CERTS_DIR/es01/es01.crt\r- xpack.security.transport.ssl.key=$CERTS_DIR/es01/es01.key\r- xpack.security.authc.api_key.enabled=true\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- data01:/usr/share/elasticsearch/data\r- certs:$CERTS_DIR\rports:\r- 9200:9200\rnetworks:\r- elastic\rhealthcheck:\rtest: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost:9200 \u0026gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi\rinterval: 30s\rtimeout: 10s\rretries: 5\res02:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: es02\renvironment:\r- node.name=es02\r- cluster.name=es-docker-cluster\r- discovery.seed_hosts=es01,es03\r- cluster.initial_master_nodes=es01,es02,es03\r- bootstrap.memory_lock=true\r- \u0026quot;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026quot;\r- xpack.license.self_generated.type=trial\r- xpack.security.enabled=true\r- xpack.security.http.ssl.enabled=true\r- xpack.security.http.ssl.key=$CERTS_DIR/es02/es02.key\r- xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.http.ssl.certificate=$CERTS_DIR/es02/es02.crt\r- xpack.security.transport.ssl.enabled=true\r- xpack.security.transport.ssl.verification_mode=certificate\r- xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.transport.ssl.certificate=$CERTS_DIR/es02/es02.crt\r- xpack.security.transport.ssl.key=$CERTS_DIR/es02/es02.key\r- xpack.security.authc.api_key.enabled=true\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- data02:/usr/share/elasticsearch/data\r- certs:$CERTS_DIR\rnetworks:\r- elastic\res03:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: es03\renvironment:\r- node.name=es03\r- cluster.name=es-docker-cluster\r- discovery.seed_hosts=es01,es02\r- cluster.initial_master_nodes=es01,es02,es03\r- bootstrap.memory_lock=true\r- \u0026quot;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026quot;\r- xpack.license.self_generated.type=trial\r- xpack.security.enabled=true\r- xpack.security.http.ssl.enabled=true\r- xpack.security.http.ssl.key=$CERTS_DIR/es03/es03.key\r- xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.http.ssl.certificate=$CERTS_DIR/es03/es03.crt\r- xpack.security.transport.ssl.enabled=true\r- xpack.security.transport.ssl.verification_mode=certificate\r- xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.transport.ssl.certificate=$CERTS_DIR/es03/es03.crt\r- xpack.security.transport.ssl.key=$CERTS_DIR/es03/es03.key\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- data03:/usr/share/elasticsearch/data\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rkib01:\rimage: docker.elastic.co/kibana/kibana:${VERSION}\rcontainer_name: kib01\rdepends_on:\res01: { condition: service_healthy}\rpackage-registry: { condition: service_healthy }\rports:\r- 5601:5601\renvironment:\rSERVERNAME: localhost\rELASTICSEARCH_URL: https://es01:9200\rELASTICSEARCH_HOSTS: https://es01:9200\rELASTICSEARCH_USERNAME: kibana_system\rELASTICSEARCH_PASSWORD: UZuuB5ABGjTBZPez4aDl\rELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES: $CERTS_DIR/ca/ca.crt\rSERVER_SSL_ENABLED: \u0026quot;true\u0026quot;\rSERVER_SSL_KEY: $CERTS_DIR/kib01/kib01.key\rSERVER_SSL_CERTIFICATE: $CERTS_DIR/kib01/kib01.crt\rSERVER_SSL_CERTIFICATEAUTHORITIES: $CERTS_DIR/ca/ca.crt\rXPACK_SECURITY_ENCRYPTIONKEY: \u0026quot;fhjskloppd678ehkdfdlliverpoolfcr\u0026quot;\rXPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: \u0026quot;fhjskloppd678ehkdfdlliverpoolfcr\u0026quot;\rXPACK_FLEET_AGENTS_ELASTICSEARCH_HOST: \u0026quot;https://es01:9200\u0026quot;\rXPACK_FLEET_REGISTRYURL: \u0026quot;https://package-registry\u0026quot;\rNODE_EXTRA_CA_CERTS: $CERTS_DIR/ca/ca.crt\rhealthcheck:\rtest: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost/api/status | grep -q 'Looking good' \u0026gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi\rretries: 100\rinterval: 5s\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rdata01:\rdriver: local\rdata02:\rdriver: local\rdata03:\rdriver: local\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge\r1- Générez et appliquez une licence d\u0026rsquo;essai qui prend en charge Transport Layer Security.\n2- Activez Transport Layer Security pour crypter les communications des clients.\n3- Activez Transport Layer Security pour crypter les communications internodales.\n4- Autorisez l\u0026rsquo;utilisation de certificats auto-signés en ne demandant pas de vérification du nom d\u0026rsquo;hôte.\nGénérez des certificats pour Elasticsearch en faisant apparaître le conteneur create-certs :\ndocker-compose -f create-certs.yml run --rm create_certs\rVérifiez a présence des volumes\ndocker volume ls\rDRIVER VOLUME NAME\rlocal es_certs\rVérifiez la présence des certificats\nsudo ls -R /var/lib/docker/volumes/es_certs/_data/\r/var/lib/docker/volumes/es_certs/_data/:\rbundle.zip ca\tes01 es02 es03 fleet-server\tkib01 package-registry\r/var/lib/docker/volumes/es_certs/_data/ca:\rca.crt\r/var/lib/docker/volumes/es_certs/_data/es01:\res01.crt es01.key\r/var/lib/docker/volumes/es_certs/_data/es02:\res02.crt es02.key\r/var/lib/docker/volumes/es_certs/_data/es03:\res03.crt es03.key\r/var/lib/docker/volumes/es_certs/_data/fleet-server:\rfleet-server.crt fleet-server.key\r/var/lib/docker/volumes/es_certs/_data/kib01:\rkib01.crt kib01.key\r/var/lib/docker/volumes/es_certs/_data/package-registry:\rpackage-registry.crt package-registry.key\rMettez en place le cluster Elasticsearch à trois nœuds :\ndocker-compose -f elastic-docker-tls.yml up -d\rÀ ce stade, Kibana ne peut pas se connecter au cluster Elasticsearch. Vous devez générer un mot de passe pour l\u0026rsquo;utilisateur intégré kibana_system, mettre à jour le mot de passe ELASTICSEARCH_PASSWORD dans le fichier compose, et redémarrer pour permettre à Kibana de communiquer avec le cluster sécurisé.\nExécutez l\u0026rsquo;outil elasticsearch-setup-passwords pour générer des mots de passe pour tous les utilisateurs intégrés, y compris l\u0026rsquo;utilisateur kibana_system. Si vous n\u0026rsquo;utilisez pas PowerShell sous Windows, supprimez les caractères \\de fin de ligne et joignez les lignes avant d\u0026rsquo;exécuter cette commande.\ndocker exec es01 /bin/bash -c \u0026quot;bin/elasticsearch-setup-passwords \\\rauto --batch --url https://es01:9200\u0026quot;\rSi la commande tombe en erreur, veuillez relancer la commande quand le noeud Elasticsearch est pret.\nChanged password for user apm_system\rPASSWORD apm_system = cFupG97Ha1vh8Ntdmi8V\rChanged password for user kibana_system\rPASSWORD kibana_system = im0I9MGIDXHSy5gpUgmm\rChanged password for user kibana\rPASSWORD kibana = im0I9MGIDXHSy5gpUgmm\rChanged password for user logstash_system\rPASSWORD logstash_system = 3ZunAd3WpUcp1tKnb3Rq\rChanged password for user beats_system\rPASSWORD beats_system = yn88diKHJhU5wF7h9Rh9\rChanged password for user remote_monitoring_user\rPASSWORD remote_monitoring_user = wfliiMix1pep0Gnm6Ah8\rChanged password for user elastic\rPASSWORD elastic = fLzlyoIb8RsCT639v7HH\rPrenez note des mots de passe générés. Vous devez configurer le mot de passe de l\u0026rsquo;utilisateur kibana_system dans le fichier compose pour permettre à Kibana de se connecter à Elasticsearch, et vous aurez besoin du mot de passe du superutilisateur elastic pour vous connecter à Kibana et soumettre des requêtes à Elasticsearch.\nDéfinissez les variables d\u0026rsquo;authentification dans le fichier .env.\nCOMPOSE_PROJECT_NAME=es\rCERTS_DIR=/usr/share/elasticsearch/config/certificates\rVERSION=7.17.0\r### Credentials\rUSER_APM_SYSTEM=apm_system\rPASSWORD_APM_SYSTEM=tE7F2LePRNPgUC4SN0nT\rUSER_KIBANA_SYSTEM=kibana_system\rPASSWORD_KIBANA_SYSTEM=zJE8y8KlV79dv6OCmfpF\rUSER_KIBANA=kibana\rPASSWORD_KIBANA=zJE8y8KlV79dv6OCmfpF\rUSER_BEATS_SYSTEM=beats_system\rPASSWORD_BEATS_SYSTEM=ITklPCO1oTCWQIMdpWFT\rUSER_ELASTIC=elastic\rPASSWORD_ELASTIC=ASf3lYu7xoKMeesYuMPc\rUtilisez docker-compose pour redémarrer le cluster et Kibana :\ndocker-compose stop\rdocker-compose -f elastic-docker-tls.yml up -d\rOuvrez Kibana pour charger les données de l\u0026rsquo;échantillon et interagir avec le cluster : Kibana\nComme SSL est également activé pour les communications entre Kibana et les navigateurs clients, vous devez accéder à Kibana via le protocole HTTPS.\nOuvrez le menu de droit et cliquez sur \u0026ldquo;Stack Monitorng\u0026rdquo;\nCliquez sur l\u0026rsquo;option \u0026ldquo;Or, set up with self monitoring\u0026rdquo;\nDéloyer une application blanche mkdir -P app/conf\rvim app/petclinic.yml\rpetclinic.yml\nversion: '2.2'\rservices:\rnginx:\rimage: nginx:1.17.3\rcontainer_name: nginx\rlabels:\r\u0026quot;co.elastic.logs/module\u0026quot;: \u0026quot;nginx\u0026quot;\r\u0026quot;co.elastic.logs/fileset.stdout\u0026quot;: \u0026quot;access\u0026quot;\r\u0026quot;co.elastic.logs/fileset.stderr\u0026quot;: \u0026quot;error\u0026quot;\r\u0026quot;co.elastic.metrics/module\u0026quot;: \u0026quot;nginx\u0026quot;\r\u0026quot;co.elastic.metrics/hosts\u0026quot;: \u0026quot;nginx:80\u0026quot;\r\u0026quot;co.elastic.metrics/metricsets\u0026quot;: \u0026quot;stubstatus\u0026quot;\rports:\r- 80:80\rvolumes:\r- ./conf/default.conf:/etc/nginx/conf.d/default.conf:ro\rnetworks:\r- elastic\rpetclinic:\rimage: docker.io/michaelhyatt/elastic-k8s-o11y-workshop-petclinic:1.25.0\rcontainer_name: petclinic\rlabels:\r\u0026quot;co.elastic.metrics/module\u0026quot;: \u0026quot;prometheus\u0026quot;\r\u0026quot;co.elastic.metrics/hosts\u0026quot;: \u0026quot;$${data.host}:$${data.port}\u0026quot;\r\u0026quot;co.elastic.metrics/metrics_path\u0026quot;: \u0026quot;/metrics/prometheus\u0026quot;\r\u0026quot;co.elastic.metrics/period\u0026quot;: \u0026quot;1m\u0026quot;\renvironment:\rELASTIC_APM_SERVER_URLS: \u0026quot;http://apm-server:8200\u0026quot;\rELASTIC_APM_SERVER_URLS_FOR_RUM: \u0026quot;http://localhost:8200\u0026quot;\rELASTIC_APM_SECRET_TOKEN: \u0026quot;\u0026quot;\rELASTIC_APM_SERVICE_NAME: \u0026quot;spring-petclinic-monolith\u0026quot;\rELASTIC_APM_APPLICATION_PACKAGES: \u0026quot;org.springframework.samples\u0026quot;\rELASTIC_APM_ENABLE_LOG_CORRELATION: \u0026quot;true\u0026quot;\rELASTIC_APM_CAPTURE_JMX_METRICS: \u0026gt;\robject_name[java.lang:type=GarbageCollector,name=*] attribute[CollectionCount:metric_name=collection_count] attribute[CollectionTime:metric_name=collection_time],\robject_name[java.lang:type=Memory] attribute[HeapMemoryUsage:metric_name=heap]\rJAVA_OPTS: \u0026gt;\r-Xms100m\r-Xmx256m\r-Dspring.profiles.active=mysql\r-Ddatabase=mysql\r-Dspring.datasource.username=root\r-Dspring.datasource.password=petclinic\r-Dspring.datasource.initialization-mode=always\r-Dspring.datasource.url=jdbc:mysql://mysql:3306/petclinic?autoReconnect=true\u0026amp;useSSL=false\r-XX:+StartAttachListener\rports:\r- 8080:8080\rnetworks:\r- elastic\rmysql:\rimage: mysql:5.7.27\rcontainer_name: mysql\rlabels:\r\u0026quot;co.elastic.logs/module\u0026quot;: \u0026quot;mysql\u0026quot;\r\u0026quot;co.elastic.metrics/module\u0026quot;: \u0026quot;mysql\u0026quot;\r\u0026quot;co.elastic.metrics/hosts\u0026quot;: \u0026quot;root:petclinic@tcp($${data.host}:3306)/\u0026quot;\renvironment:\rMYSQL_ROOT_PASSWORD: petclinic\rMYSQL_DATABASE: petclinic\rports:\r- 3306\rnetworks:\r- elastic\rnetworks:\relastic:\rdriver: bridge\rvim app/conf/default.conf\rdefault.conf\nserver {\rlisten 80;\rserver_name localhost;\rlocation /intake {\rif ($request_method = 'OPTIONS') {\r# This is a bit too wide, would be enough to replace it with only APM server url for CORS support.\radd_header 'Access-Control-Allow-Origin' '*';\radd_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';\radd_header 'Access-Control-Allow-Headers' 'Accept:,Accept-Encoding,Accept-Language:,Cache-Control,Connection,DNT,Pragma,Host,Referer,Upgrade-Insecure-Requests,User-Agent,elastic-apm-traceparent';\radd_header 'Access-Control-Max-Age' 1728000;\radd_header 'Access-Control-Allow-Credentials' 'true';\radd_header 'Content-Type' 'text/plain; charset=utf-8';\radd_header 'Content-Length' 0;\rreturn 200;\r}\r}\rlocation / {\rproxy_pass http://petclinic:8080/;\r}\rlocation /server-status {\rstub_status;\rallow all; # A bit too wide\r# deny all;\r}\rerror_page 500 502 503 504 /50x.html;\rlocation = /50x.html {\rroot /usr/share/nginx/html;\r}\r}\rdocker-compose -f app/petclinic.yml up -d\rAccédez à la application blanche en cliquant ici\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/security/","title":"Lab - Habilitation","tags":[],"description":"","content":"Roles Kibana Les rôles sont un ensemble de privilèges qui vous permettent d\u0026rsquo;effectuer des actions dans Kibana et Elasticsearch. Les utilisateurs ne reçoivent pas directement de privilèges, mais se voient plutôt attribuer un ou plusieurs rôles qui décrivent le niveau d\u0026rsquo;accès souhaité. Lorsque vous attribuez plusieurs rôles à un utilisateur, ce dernier reçoit une union des privilèges des rôles. Cela signifie que vous ne pouvez pas réduire les privilèges d\u0026rsquo;un utilisateur en lui attribuant un rôle supplémentaire. Vous devez plutôt supprimer ou modifier l\u0026rsquo;un de ses rôles existants.\nUser Observability Vous allez créer un role pour les utilisateurs qui doivent consulter les différentes informations de leurs applications sur le menu Observability. Cette création sera faite via API d\u0026rsquo;Elasticsearch. Pour cela vous allez ouvrir un dans le menu Kibana Management -\u0026gt; DevTool.\nPOST /_security/role/read_observability\r{\r\u0026quot;cluster\u0026quot;: [],\r\u0026quot;indices\u0026quot;: [\r{\r\u0026quot;names\u0026quot;: [\r\u0026quot;metricbeat-*\u0026quot;,\r\u0026quot;filebeat-*\u0026quot;,\r\u0026quot;traces-apm*,apm-*,logs-apm*,apm-*,metrics-apm*,apm-*\u0026quot;\r],\r\u0026quot;privileges\u0026quot;: [\r\u0026quot;read\u0026quot;\r],\r\u0026quot;allow_restricted_indices\u0026quot;: false\r}\r],\r\u0026quot;applications\u0026quot;: [\r{\r\u0026quot;application\u0026quot;: \u0026quot;kibana-.kibana\u0026quot;,\r\u0026quot;privileges\u0026quot;: [\r\u0026quot;feature_logs.read\u0026quot;,\r\u0026quot;feature_infrastructure.read\u0026quot;,\r\u0026quot;feature_apm.read\u0026quot;,\r\u0026quot;feature_uptime.read\u0026quot;,\r\u0026quot;feature_observabilityCases.read\u0026quot;\r],\r\u0026quot;resources\u0026quot;: [\r\u0026quot;space:default\u0026quot;\r]\r}\r],\r\u0026quot;run_as\u0026quot;: [],\r\u0026quot;metadata\u0026quot;: {},\r\u0026quot;transient_metadata\u0026quot;: {\r\u0026quot;enabled\u0026quot;: true\r}\r}\r{\r\u0026quot;role\u0026quot; : {\r\u0026quot;created\u0026quot; : true\r}\r}\rVérifions la configuration du role :\nGET /_security/role/read_observability\r{\r\u0026quot;read_observability\u0026quot; : {\r\u0026quot;cluster\u0026quot; : [ ],\r\u0026quot;indices\u0026quot; : [\r{\r\u0026quot;names\u0026quot; : [\r\u0026quot;metricbeat-*\u0026quot;,\r\u0026quot;filebeat-*\u0026quot;,\r\u0026quot;traces-apm*,apm-*,logs-apm*,apm-*,metrics-apm*,apm-*\u0026quot;\r],\r\u0026quot;privileges\u0026quot; : [\r\u0026quot;read\u0026quot;\r],\r\u0026quot;allow_restricted_indices\u0026quot; : false\r}\r],\r\u0026quot;applications\u0026quot; : [\r{\r\u0026quot;application\u0026quot; : \u0026quot;kibana-.kibana\u0026quot;,\r\u0026quot;privileges\u0026quot; : [\r\u0026quot;feature_logs.read\u0026quot;,\r\u0026quot;feature_infrastructure.read\u0026quot;,\r\u0026quot;feature_apm.read\u0026quot;,\r\u0026quot;feature_uptime.read\u0026quot;,\r\u0026quot;feature_observabilityCases.read\u0026quot;\r],\r\u0026quot;resources\u0026quot; : [\r\u0026quot;space:default\u0026quot;\r]\r}\r],\r\u0026quot;run_as\u0026quot; : [ ],\r\u0026quot;metadata\u0026quot; : { },\r\u0026quot;transient_metadata\u0026quot; : {\r\u0026quot;enabled\u0026quot; : true\r}\r}\r}\rEnsuite vous allez définir un utilisateur qui aura l\u0026rsquo;habilitation de lire les données d\u0026rsquo;observabilité grace au role précédament crée.\nPOST /_security/user/user_observability\r{\r\u0026quot;username\u0026quot;: \u0026quot;user_observability\u0026quot;,\r\u0026quot;password\u0026quot;: \u0026quot;test1234\u0026quot;,\r\u0026quot;roles\u0026quot;: [\r\u0026quot;read_observability\u0026quot;\r],\r\u0026quot;full_name\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;email\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;metadata\u0026quot;: {},\r\u0026quot;enabled\u0026quot;: true\r}\r{\r\u0026quot;created\u0026quot; : true\r}\rVérifions la configuration du role :\nGET /_security/user/user_observability\r{\r\u0026quot;user_observability\u0026quot; : {\r\u0026quot;username\u0026quot; : \u0026quot;user_observability\u0026quot;,\r\u0026quot;roles\u0026quot; : [\r\u0026quot;read_observability\u0026quot;\r],\r\u0026quot;full_name\u0026quot; : \u0026quot;\u0026quot;,\r\u0026quot;email\u0026quot; : \u0026quot;\u0026quot;,\r\u0026quot;metadata\u0026quot; : { },\r\u0026quot;enabled\u0026quot; : true\r}\r}\rMaintenant ouvrez une page de votre navigateur privé pour vous connectez à Kibana avec cet utilisateur : Accerder à Kibana\nSélectionnez dans le menu Observability\nPuis observer que l\u0026rsquo;utilisateur ne voit pas les données de type APM et Uptime.\nA vous de corriger les habilitations de l\u0026rsquo;utilisateur pour la lecture de données manquantes, voici quelque lien utile pour votre problème :\n https://www.elastic.co/guide/en/elasticsearch/reference/current/security-api-put-role.html https://www.elastic.co/guide/en/kibana/current/kibana-role-management.html https://www.elastic.co/guide/en/elasticsearch/reference/8.0/security-privileges.html#privileges-list-indices   Administrator Observability Vous allez créer un role pour les administrateurs qui doivent consulter/modifier/supprimer les différentes informations de leurs applications sur le menu Observability. Cette création sera faite via API d\u0026rsquo;Elasticsearch. Pour cela vous allez ouvrir un dans le menu Kibana Management -\u0026gt; DevTool.\nCorriger l\u0026rsquo;erreur dans le role administrateur que vous avez trouver sur le role user, puis exécuter cette requete :\nPOST /_security/role/admin_observability\r{\r\u0026quot;cluster\u0026quot;: [\r\u0026quot;create_snapshot\u0026quot;,\r\u0026quot;manage_ccr\u0026quot;,\r\u0026quot;manage_ilm\u0026quot;,\r\u0026quot;manage_saml\u0026quot;,\r\u0026quot;manage_watcher\u0026quot;,\r\u0026quot;monitor\u0026quot;,\r\u0026quot;read_ilm\u0026quot;\r],\r\u0026quot;indices\u0026quot;: [\r{\r\u0026quot;names\u0026quot;: [\r\u0026quot;metricbeat-*\u0026quot;,\r\u0026quot;filebeat-*\u0026quot;,\r\u0026quot;traces-apm*,apm-*,logs-apm*,apm-*,metrics-apm*,apm-*\u0026quot;\r],\r\u0026quot;privileges\u0026quot;: [\r\u0026quot;read\u0026quot;,\r\u0026quot;monitor\u0026quot;,\r\u0026quot;create\u0026quot;,\r\u0026quot;write\u0026quot;,\r\u0026quot;delete\u0026quot;,\r\u0026quot;delete_index\u0026quot;\r],\r\u0026quot;allow_restricted_indices\u0026quot;: false\r}\r],\r\u0026quot;applications\u0026quot;: [\r{\r\u0026quot;application\u0026quot;: \u0026quot;kibana-.kibana\u0026quot;,\r\u0026quot;privileges\u0026quot;: [\r\u0026quot;feature_logs.all\u0026quot;,\r\u0026quot;feature_infrastructure.all\u0026quot;,\r\u0026quot;feature_apm.all\u0026quot;,\r\u0026quot;feature_uptime.all\u0026quot;,\r\u0026quot;feature_observabilityCases.all\u0026quot;,\r\u0026quot;feature_dev_tools.all\u0026quot;,\r\u0026quot;feature_indexPatterns.read\u0026quot;\r],\r\u0026quot;resources\u0026quot;: [\r\u0026quot;space:default\u0026quot;\r]\r}\r],\r\u0026quot;run_as\u0026quot;: [],\r\u0026quot;metadata\u0026quot;: {},\r\u0026quot;transient_metadata\u0026quot;: {\r\u0026quot;enabled\u0026quot;: true\r}\r}\r{\r\u0026quot;role\u0026quot; : {\r\u0026quot;created\u0026quot; : true\r}\r}\rVérifions la configuration du role :\nGET /_security/role/admin_observability\r{\r\u0026quot;admin_observability\u0026quot; : {\r\u0026quot;cluster\u0026quot; : [\r\u0026quot;create_snapshot\u0026quot;,\r\u0026quot;manage_ccr\u0026quot;,\r\u0026quot;manage_ilm\u0026quot;,\r\u0026quot;manage_saml\u0026quot;,\r\u0026quot;manage_watcher\u0026quot;,\r\u0026quot;monitor\u0026quot;,\r\u0026quot;read_ilm\u0026quot;\r],\r\u0026quot;indices\u0026quot; : [\r{\r\u0026quot;names\u0026quot; : [\r\u0026quot;metricbeat-*\u0026quot;,\r\u0026quot;filebeat-*\u0026quot;,\r\u0026quot;uptime-*\u0026quot;,\r\u0026quot;apm-*\u0026quot;,\r\u0026quot;heartbeat-*\u0026quot;\r],\r\u0026quot;privileges\u0026quot; : [\r\u0026quot;read\u0026quot;,\r\u0026quot;monitor\u0026quot;,\r\u0026quot;create\u0026quot;,\r\u0026quot;write\u0026quot;,\r\u0026quot;delete\u0026quot;,\r\u0026quot;delete_index\u0026quot;\r],\r\u0026quot;allow_restricted_indices\u0026quot; : false\r}\r],\r\u0026quot;applications\u0026quot; : [\r{\r\u0026quot;application\u0026quot; : \u0026quot;kibana-.kibana\u0026quot;,\r\u0026quot;privileges\u0026quot; : [\r\u0026quot;feature_logs.all\u0026quot;,\r\u0026quot;feature_infrastructure.all\u0026quot;,\r\u0026quot;feature_apm.all\u0026quot;,\r\u0026quot;feature_uptime.all\u0026quot;,\r\u0026quot;feature_observabilityCases.all\u0026quot;,\r\u0026quot;feature_dev_tools.all\u0026quot;,\r\u0026quot;feature_indexPatterns.read\u0026quot;\r],\r\u0026quot;resources\u0026quot; : [\r\u0026quot;space:default\u0026quot;\r]\r}\r],\r\u0026quot;run_as\u0026quot; : [ ],\r\u0026quot;metadata\u0026quot; : { },\r\u0026quot;transient_metadata\u0026quot; : {\r\u0026quot;enabled\u0026quot; : true\r}\r}\r}\rEnsuite vous allez définir un utilisateur qui aura l\u0026rsquo;habilitation de lire les données d\u0026rsquo;observabilité grace au role précédament crée.\nPOST /_security/user/admin_observability\r{\r\u0026quot;username\u0026quot;: \u0026quot;admin_observability\u0026quot;,\r\u0026quot;roles\u0026quot;: [\r\u0026quot;admin_observability\u0026quot;\r],\r\u0026quot;full_name\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;email\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;metadata\u0026quot;: {},\r\u0026quot;enabled\u0026quot;: true\r}\r{\r\u0026quot;created\u0026quot; : true\r}\rVérifions la configuration du role :\nGET /_security/user/user_observability\r{\r\u0026quot;user_observability\u0026quot; : {\r\u0026quot;username\u0026quot; : \u0026quot;user_observability\u0026quot;,\r\u0026quot;roles\u0026quot; : [\r\u0026quot;read_observability\u0026quot;\r],\r\u0026quot;full_name\u0026quot; : \u0026quot;\u0026quot;,\r\u0026quot;email\u0026quot; : \u0026quot;\u0026quot;,\r\u0026quot;metadata\u0026quot; : { },\r\u0026quot;enabled\u0026quot; : true\r}\r}\rMaintenant ouvrez une page de votre navigateur privé pour vous connectez à Kibana avec cet utilisateur : Accerder à Kibana\nSélectionnez dans le menu Observability\nPuis observer que l\u0026rsquo;utilisateur ne voit pas les données de type APM et Uptime.\nGET apm-*/_search\rGET metricbeat-*/_search\rGET filebeat-*/_search\rGET heartbeat-*/_search\rMaintenant l\u0026rsquo;administrateur souhaite créer un index dans Elasticsearch afin de regrouper les données en un point d\u0026rsquo;accès\nPUT my-index-observability\r{\r\u0026quot;error\u0026quot; : {\r\u0026quot;root_cause\u0026quot; : [\r{\r\u0026quot;type\u0026quot; : \u0026quot;security_exception\u0026quot;,\r\u0026quot;reason\u0026quot; : \u0026quot;action [indices:admin/create] is unauthorized for user [admin_observability] with roles [admin_observability], this action is granted by the index privileges [create_index,manage,all]\u0026quot;\r}\r],\r\u0026quot;type\u0026quot; : \u0026quot;security_exception\u0026quot;,\r\u0026quot;reason\u0026quot; : \u0026quot;action [indices:admin/create] is unauthorized for user [admin_observability] with roles [admin_observability], this action is granted by the index privileges [create_index,manage,all]\u0026quot;\r},\r\u0026quot;status\u0026quot; : 403\r}\rA vous de corriger les habilitations de l\u0026rsquo;administrateur pour la création d\u0026rsquo;un index, voici quelque lien utile pour votre problème :\n https://www.elastic.co/guide/en/elasticsearch/reference/current/security-api-put-role.html https://www.elastic.co/guide/en/kibana/current/kibana-role-management.html https://www.elastic.co/guide/en/elasticsearch/reference/8.0/security-privileges.html#privileges-list-indices  Résumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez créer et mettre à jour des roles pour vos utilisateurs. Vous avez également exploré les différentes habilitations possibles sur Elasticsearch.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_logs/","title":"Lab - Logs","tags":[],"description":"","content":"Objectif : Dans ce laboratoire, vous explorerez la facilité avec laquelle vous pouvez lire les fichiers journaux NGINX avec Filebeat et les indexer dans Elasticsearch. Vous explorerez également les tableaux de bord Kibana et verrez avec quelle facilité vous pouvez surveiller les journaux NGINX.\nDéployer un agent beats mkdir -P beats/conf\rvim beats/beats-docker.yml\rbeats-docker.yml\nversion: '2.2'\rservices:\rfilebeat:\rimage: docker.elastic.co/beats/filebeat:${VERSION}\rcontainer_name: filebeat\rrestart: unless-stopped\rentrypoint: \u0026quot;filebeat -e -strict.perms=false\u0026quot;\ruser: root\rvolumes:\r- \u0026quot;./conf/filebeat.yml:/usr/share/filebeat/filebeat.yml:rw\u0026quot;\r- \u0026quot;/var/lib/docker/containers:/var/lib/docker/containers:ro\u0026quot;\r- \u0026quot;/var/run/docker.sock:/var/run/docker.sock:ro\u0026quot;\r- \u0026quot;/var/log:/tmp:ro\u0026quot;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge\rvim beats/conf/filebeat.yml\r######################## Filebeat Configuration ############################\r#========================== Modules configuration ============================\rfilebeat.modules:\r#------------------------------- System Module -------------------------------\r- module: system\r# Syslog\rsyslog:\renabled: true\r# Authorization logs\rauth:\renabled: true\r#=========================== Filebeat inputs =============================\r# List of inputs to fetch data.\rfilebeat.inputs:\r#------------------------------ Log input --------------------------------\r- type: log\r# Change to true to enable this input configuration.\renabled: true\r# Paths that should be crawled and fetched. Glob based paths.\r# To fetch all \u0026quot;.log\u0026quot; files from a specific level of subdirectories\r# /var/log/*/*.log can be used.\r# For each file found under this path, a harvester is started.\r# Make sure not file is defined twice as this can lead to unexpected behaviour.\rpaths:\r- \u0026quot;/var/lib/docker/containers/*/*-json.log\u0026quot;\r- '/tmp/*.log'\r#========================== Filebeat autodiscover ==============================\r# Autodiscover allows you to detect changes in the system and spawn new modules\r# or inputs as they happen.\rfilebeat.autodiscover:\r# List of enabled autodiscover providers\rproviders:\r- type: docker\rhints.enabled: true\r#================================ Processors ===================================\r#\r# The following example enriches each event with docker metadata, it matches\r# given fields to an existing container id and adds info from that container:\r#\rprocessors:\r- add_docker_metadata: ~\r- add_locale:\rformat: offset\r- add_host_metadata:\rnetinfo.enabled: true\r#================================ Outputs ======================================\r# Configure what output to use when sending the data collected by the beat.\r#-------------------------- Elasticsearch output -------------------------------\routput.elasticsearch:\r# Boolean flag to enable or disable the output module.\renabled: true\r# Array of hosts to connect to.\r# Scheme and port can be left out and will be set to the default (http and 9200)\r# In case you specify and additional path, the scheme is required: http://localhost:9200/path\r# IPv6 addresses should always be defined as: https://[2001:db8::1]:9200\rhosts: [\u0026quot;es01:9200\u0026quot;]\r# Set gzip compression level.\r#compression_level: 0\r# Optional protocol and basic auth credentials.\rprotocol: \u0026quot;https\u0026quot;\rusername: \u0026quot;elastic\u0026quot;\rpassword: \u0026quot;CHANGEME\u0026quot;\r# Use SSL settings for HTTPS.\rssl.enabled: true\r# SSL configuration. By default is off.\r# List of root certificates for HTTPS server verifications\rssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\r#============================== Dashboards =====================================\r# These settings control loading the sample dashboards to the Kibana index. Loading\r# the dashboards are disabled by default and can be enabled either by setting the\r# options here, or by using the `-setup` CLI flag or the `setup` command.\rsetup.dashboards.enabled: true\r#============================== Template =====================================\r# Template name. By default the template name is \u0026quot;filebeat-%{[beat.version]}\u0026quot;\r# The template name and pattern has to be set in case the elasticsearch index pattern is modified.\rsetup.template.name: \u0026quot;logs-%{[beat.version]}\u0026quot;\r# Template pattern. By default the template pattern is \u0026quot;-%{[beat.version]}-*\u0026quot; to apply to the default index settings.\r# The first part is the version of the beat and then -* is used to match all daily indices.\r# The template name and pattern has to be set in case the elasticsearch index pattern is modified.\rsetup.template.pattern: \u0026quot;logs-%{[beat.version]}-*\u0026quot;\r# Path to fields.yml file to generate the template\r#setup.template.fields: \u0026quot;${path.config}/fields.yml\u0026quot;\r# Overwrite existing template\r#setup.template.overwrite: false\r# Elasticsearch template settings\rsetup.template.settings:\r# A dictionary of settings to place into the settings.index dictionary\r# of the Elasticsearch template. For more details, please check\r# https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html\r#index:\rnumber_of_shards: 1\r#codec: best_compression\r#number_of_routing_shards: 30\r# A dictionary of settings for the _source field. For more details, please check\r# https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html\r#_source:\r#enabled: false\r#============================== Kibana =====================================\r# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.\r# This requires a Kibana endpoint configuration.\rsetup.kibana:\r# Kibana Host\r# Scheme and port can be left out and will be set to the default (http and 5601)\r# In case you specify and additional path, the scheme is required: http://localhost:5601/path\r# IPv6 addresses should always be defined as: https://[2001:db8::1]:5601\rhost: \u0026quot;kib01:5601\u0026quot;\r# Optional protocol and basic auth credentials.\rprotocol: \u0026quot;https\u0026quot;\rusername: \u0026quot;elastic\u0026quot;\rpassword: \u0026quot;CHANGEME\u0026quot;\r# Use SSL settings for HTTPS. Default is true.\rssl.enabled: true\rssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\r#================================ Logging ======================================\r# There are four options for the log output: file, stderr, syslog, eventlog\r# The file output is the default.\r# Sets log level. The default log level is info.\r# Available log levels are: error, warning, info, debug\rlogging.level: info\r# Send all logging output to syslog. The default is false.\rlogging.to_syslog: true\r# Send all logging output to Windows Event Logs. The default is false.\rlogging.to_eventlog: true\r# If enabled, filebeat periodically logs its internal metrics that have changed\r# in the last period. For each metric that changed, the delta from the value at\r# the beginning of the period is logged. Also, the total values for\r# all non-zero internal metrics are logged on shutdown. The default is true.\rlogging.metrics.enabled: true\r# The period after which to log the internal metrics. The default is 30s.\rlogging.metrics.period: 30s\r# Logging to rotating files. Set logging.to_files to false to disable logging to\r# files.\rlogging.to_files: true\rlogging.files:\r# Configure the path where the logs are written. The default is the logs directory\r# under the home path (the binary location).\rpath: /var/log/filebeat\r# The name of the files where the logs are written to.\rname: filebeat\rChanger la valeur du champs password avec la valeur du mot de passe générer automatiquement.\ndocker-compose -f beats/beats-docker.yml up -d\rvim app/artificial_load.sh\r#!/bin/bash\rCOUNTER=0\rwhile [ $COUNTER -lt 10000 ] ;\rdo\rcurl -s --header \u0026quot;X-Forwarded-For: 5.198.223.255\u0026quot; localhost \u0026gt; /dev/null\rcurl -s localhost/owners/find \u0026gt; /dev/null\rcurl -s localhost/owners?lastName= \u0026gt; /dev/null\rcurl -s localhost/owners/1 \u0026gt; /dev/null\rcurl -s localhost/owners/4 \u0026gt; /dev/null\rcurl -s localhost/owners/6 \u0026gt; /dev/null\rcurl -s localhost/owners/8 \u0026gt; /dev/null\rcurl -s localhost/vets.html \u0026gt; /dev/null\rcurl -s localhost/oups \u0026gt; /dev/null\rlet COUNTER=COUNTER+1\rdone\rchmod +x app/artificial_load.sh\rMaintenant, ouvrez une nouvelle fenêtre de terminal et exécutez le script suivant pour simuler la charge sur votre serveur NGINX.\n./app/artificial_load.sh\rLancer Kibana pour commencer à explorer les tableaux de bord qui ont été inclus dans le processus de configuration.\nAccédez à Dashboard via le menu principal\nRecherchez nginx et ouvrez le tableau de bord ECS Filebeat Nginx Overview.\nVous verrez quelque chose de similaire à la page ci-dessous.\nFaites défiler vers le bas et vérifiez quel est le navigateur le plus utilisé. Vous remarquerez que ce devrait être curl car il est utilisé par le script de simulation de charge.\nMaintenant, cliquez sur Nginx access and error logs en haut du tableau de bord actuel pour voir le tableau de bord avec les journaux d\u0026rsquo;accès et d\u0026rsquo;erreurs que Filebeat a collecté de NGINX.\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez lire les fichiers journaux NGINX avec Filebeat et les indexer dans Elasticsearch. Vous avez également exploré les tableaux de bord Kibana et vu comment vous pouvez facilement surveiller les journaux NGINX.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/ilm/","title":"Lab - Index Lifecycle Policy","tags":[],"description":"","content":"Vous pouvez configurer des politiques de gestion du cycle de vie des index (ILM) pour gérer automatiquement les index en fonction de vos exigences en matière de performances, de résilience et de rétention. Par exemple, vous pouvez utiliser ILM pour :\n Faire tourner un nouvel index lorsqu\u0026rsquo;un index atteint une certaine taille ou un certain nombre de documents. créer un nouvel index chaque jour, semaine ou mois et archiver les précédents supprimer les index périmés pour appliquer les normes de conservation des données.  Vous pouvez créer et gérer les politiques de cycle de vie des index via Kibana Management ou les API ILM. Lorsque vous activez la gestion du cycle de vie des index pour Beats ou le plugin de sortie Logstash Elasticsearch, des politiques par défaut sont configurées automatiquement.\nLa mise en place de règle de gestion permet :\n Augmenter les performances de recherche et/ou de visualisation Obtenir une meilleure résilience de ses données De définir des standards de rétention.  L\u0026rsquo;avantage de la fonctionnalité ILM est d\u0026rsquo;automatiser cette gestion avec des règles simple d\u0026rsquo;usage.\nILM Settings Par défaut sur votre cluster la fonctionnalité ILM est configuré à un interval de vérification de 10 minutes.\nCe paramètre peut être modifié dans des contexts hors prod.\nGET _cluster/settings\rPUT _cluster/settings\r{\r\u0026quot;persistent\u0026quot;:{\r\u0026quot;indices.lifecycle.poll_interval\u0026quot;: \u0026quot;1s\u0026quot;\r}\r}\r{\r\u0026quot;acknowledged\u0026quot; : true,\r\u0026quot;persistent\u0026quot; : {\r\u0026quot;indices\u0026quot; : {\r\u0026quot;lifecycle\u0026quot; : {\r\u0026quot;poll_interval\u0026quot; : \u0026quot;1s\u0026quot;\r}\r}\r},\r\u0026quot;transient\u0026quot; : { }\r}\rILM Policy La définition d\u0026rsquo;une règle intègre plusieurs paramètres :\n Phase : Il existe plusieurs type de phase hot, warm et cold. Rollover : Le roulement d\u0026rsquo;un index s\u0026rsquo;applique avec au moins un de ces paramètres : max_age, max_size, max_docs. Delete : La rétention d\u0026rsquo;un index avec la fonction de suppression.  Il est recommander d\u0026rsquo;effectuer dans la phase hot une rotation d\u0026rsquo;index sur les paramètres suivant :\n Logs :  max_age : 15d max_size : 45gb   Metric :  max_age : 15d max_size : 40gb    Et une deuxième recommandation est d\u0026rsquo;effectuer une retention d\u0026rsquo;index égale à 90 jours.\nCela permet d\u0026rsquo;augmenter les performances de l\u0026rsquo;index et d\u0026rsquo;optimiser les recherches.\nPour notre besoin d\u0026rsquo;aujourd\u0026rsquo;hui, nous allons préparer une ILM avec une phase très courte. Ouvrez dans le menu Kibana le DevTool.\nPUT _ilm/policy/observability-policy\r{\r\u0026quot;policy\u0026quot;: {\r\u0026quot;phases\u0026quot;: {\r\u0026quot;hot\u0026quot;: {\r\u0026quot;actions\u0026quot;: {\r\u0026quot;rollover\u0026quot;: {\r\u0026quot;max_docs\u0026quot;: 10\r},\r\u0026quot;set_priority\u0026quot;: {\r\u0026quot;priority\u0026quot;: 50\r}\r}\r},\r\u0026quot;delete\u0026quot;: {\r\u0026quot;min_age\u0026quot;: \u0026quot;60d\u0026quot;,\r\u0026quot;actions\u0026quot;: {\r\u0026quot;delete\u0026quot;: {}\r}\r}\r}\r}\r}\r{\r\u0026quot;acknowledged\u0026quot; : true\r}\rComponents Template Settings Nous allons configurer des paramètres par défaut pour tous les index ELasticsearch qui seront créé.\nIl est recommandé d\u0026rsquo;avoir les paramètres de réplications suivant :\n shard : 1 replicas : 1  PUT _component_template/observability-settings\r{\r\u0026quot;template\u0026quot;: {\r\u0026quot;settings\u0026quot;: {\r\u0026quot;number_of_shards\u0026quot;: 1,\r\u0026quot;number_of_replicas\u0026quot;: 10,\r\u0026quot;index.lifecycle.name\u0026quot;: \u0026quot;observability-policy\u0026quot;\r}\r},\r\u0026quot;_meta\u0026quot;: {\r\u0026quot;description\u0026quot;: \u0026quot;Settings for Observability data\u0026quot;\r}\r}\r{\r\u0026quot;acknowledged\u0026quot; : true\r}\rMapping NOus allons configurer un mapping des champs par défaut pour toutes les données d\u0026rsquo;observabilité.\nPUT _component_template/observability-mappings\r{\r\u0026quot;template\u0026quot;: {\r\u0026quot;mappings\u0026quot;: {\r\u0026quot;properties\u0026quot;: {\r\u0026quot;@timestamp\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\r\u0026quot;format\u0026quot;: \u0026quot;date_optional_time||epoch_millis\u0026quot;\r},\r\u0026quot;message\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;wildcard\u0026quot;\r}\r}\r}\r},\r\u0026quot;_meta\u0026quot;: {\r\u0026quot;description\u0026quot;: \u0026quot;Mappings for @timestamp and message fields\u0026quot;\r}\r}\r{\r\u0026quot;acknowledged\u0026quot; : true\r}\rIndex Template L\u0026rsquo;index template est une fonctionnalité permettant de définir des paramètres par défaut à vos index. Cela permet d\u0026rsquo;automatiser la gestion des index en appliquant des configurations de réplications, de règles de gestion automatiquement.\nPUT _index_template/observability-template\r{\r\u0026quot;index_patterns\u0026quot;: [\u0026quot;observability-*\u0026quot;],\r\u0026quot;data_stream\u0026quot;: { },\r\u0026quot;composed_of\u0026quot;: [ \u0026quot;observability-mappings\u0026quot;, \u0026quot;observability-settings\u0026quot; ],\r\u0026quot;priority\u0026quot;: 500,\r\u0026quot;_meta\u0026quot;: {\r\u0026quot;description\u0026quot;: \u0026quot;Template for my time series data\u0026quot;\r}\r}\r{\r\u0026quot;acknowledged\u0026quot; : true\r}\rCréer votre Data Stream PUT _data_stream/observability-time-series\r{\r\u0026quot;acknowledged\u0026quot; : true\r}\rAjouter des données dans le Data Stream PUT observability-time-series/_bulk\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:21:15.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026quot;GET /images/bg.jpg HTTP/1.0\\\u0026quot; 200 24736\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:25:42.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026quot;GET /favicon.ico HTTP/1.0\\\u0026quot; 200 3638\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:21:15.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026quot;GET /images/bg.jpg HTTP/1.0\\\u0026quot; 200 24736\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:25:42.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026quot;GET /favicon.ico HTTP/1.0\\\u0026quot; 200 3638\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:21:15.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026quot;GET /images/bg.jpg HTTP/1.0\\\u0026quot; 200 24736\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:25:42.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026quot;GET /favicon.ico HTTP/1.0\\\u0026quot; 200 3638\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:21:15.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026quot;GET /images/bg.jpg HTTP/1.0\\\u0026quot; 200 24736\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:25:42.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026quot;GET /favicon.ico HTTP/1.0\\\u0026quot; 200 3638\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:21:15.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026quot;GET /images/bg.jpg HTTP/1.0\\\u0026quot; 200 24736\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:25:42.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026quot;GET /favicon.ico HTTP/1.0\\\u0026quot; 200 3638\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:21:15.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026quot;GET /images/bg.jpg HTTP/1.0\\\u0026quot; 200 24736\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:25:42.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026quot;GET /favicon.ico HTTP/1.0\\\u0026quot; 200 3638\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:21:15.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026quot;GET /images/bg.jpg HTTP/1.0\\\u0026quot; 200 24736\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:25:42.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026quot;GET /favicon.ico HTTP/1.0\\\u0026quot; 200 3638\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:21:15.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026quot;GET /images/bg.jpg HTTP/1.0\\\u0026quot; 200 24736\u0026quot;}\r{\u0026quot;create\u0026quot;:{}}\r{\u0026quot;@timestamp\u0026quot;:\u0026quot;2099-05-06T16:25:42.000Z\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026quot;GET /favicon.ico HTTP/1.0\\\u0026quot; 200 3638\u0026quot;}\r{\r\u0026quot;took\u0026quot; : 12,\r\u0026quot;errors\u0026quot; : false,\r\u0026quot;items\u0026quot; : [\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;HggBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 0,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;HwgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 1,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;IAgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 2,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;IQgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 3,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;IggBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 4,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;IwgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 5,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;JAgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 6,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;JQgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 7,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;JggBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 8,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;JwgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 9,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;KAgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 10,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;KQgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 11,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;KggBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 12,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;KwgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 13,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;LAgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 14,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r},\r{\r\u0026quot;create\u0026quot; : {\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;LQgBHn8BzEvhAp6LaS34\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 15,\r\u0026quot;_primary_term\u0026quot; : 1,\r\u0026quot;status\u0026quot; : 201\r}\r}\r]\r}\rMettre à jours les données Data Stream POST observability-time-series/_doc\r{\r\u0026quot;@timestamp\u0026quot;: \u0026quot;2099-05-06T16:21:15.000Z\u0026quot;,\r\u0026quot;message\u0026quot;: \u0026quot;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026quot;GET /images/bg.jpg HTTP/1.0\\\u0026quot; 200 24736\u0026quot;\r}\r{\r\u0026quot;_index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000002\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;ZQgCHn8BzEvhAp6LozUb\u0026quot;,\r\u0026quot;_version\u0026quot; : 1,\r\u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 2,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 0,\r\u0026quot;_primary_term\u0026quot; : 1\r}\rOn constate que le nom de l\u0026rsquo;index est différent .ds-observability-time-series-2022.02.21-000002, il y a eu une rotation automatique de l\u0026rsquo;index. On constate alors que la politique de rotation est bien appliquée.\nILM Check GET _ilm/status\r{\r\u0026quot;operation_mode\u0026quot; : \u0026quot;RUNNING\u0026quot;\r}\rGET _ilm/policy/observability-policy\r{\r\u0026quot;observability-policy\u0026quot; : {\r\u0026quot;version\u0026quot; : 1,\r\u0026quot;modified_date\u0026quot; : \u0026quot;2022-02-21T20:35:02.304Z\u0026quot;,\r\u0026quot;policy\u0026quot; : {\r\u0026quot;phases\u0026quot; : {\r\u0026quot;hot\u0026quot; : {\r\u0026quot;min_age\u0026quot; : \u0026quot;0ms\u0026quot;,\r\u0026quot;actions\u0026quot; : {\r\u0026quot;rollover\u0026quot; : {\r\u0026quot;max_docs\u0026quot; : 10\r},\r\u0026quot;set_priority\u0026quot; : {\r\u0026quot;priority\u0026quot; : 50\r}\r}\r},\r\u0026quot;delete\u0026quot; : {\r\u0026quot;min_age\u0026quot; : \u0026quot;60d\u0026quot;,\r\u0026quot;actions\u0026quot; : {\r\u0026quot;delete\u0026quot; : {\r\u0026quot;delete_searchable_snapshot\u0026quot; : true\r}\r}\r}\r}\r},\r\u0026quot;in_use_by\u0026quot; : {\r\u0026quot;indices\u0026quot; : [\r\u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;.ds-observability-time-series-2022.02.21-000002\u0026quot;\r],\r\u0026quot;data_streams\u0026quot; : [\r\u0026quot;observability-time-series\u0026quot;\r],\r\u0026quot;composable_templates\u0026quot; : [\r\u0026quot;observability-template\u0026quot;\r]\r}\r}\r}\rOn retrouve la configuration de notre ILM ainsi que les index rattachés.\nGET observability-time-series/_ilm/explain\r{\r\u0026quot;indices\u0026quot; : {\r\u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot; : {\r\u0026quot;index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000001\u0026quot;,\r\u0026quot;managed\u0026quot; : true,\r\u0026quot;policy\u0026quot; : \u0026quot;observability-policy\u0026quot;,\r\u0026quot;lifecycle_date_millis\u0026quot; : 1645475884407,\r\u0026quot;age\u0026quot; : \u0026quot;4.91m\u0026quot;,\r\u0026quot;phase\u0026quot; : \u0026quot;hot\u0026quot;,\r\u0026quot;phase_time_millis\u0026quot; : 1645475859767,\r\u0026quot;action\u0026quot; : \u0026quot;complete\u0026quot;,\r\u0026quot;action_time_millis\u0026quot; : 1645475885210,\r\u0026quot;step\u0026quot; : \u0026quot;complete\u0026quot;,\r\u0026quot;step_time_millis\u0026quot; : 1645475885210,\r\u0026quot;phase_execution\u0026quot; : {\r\u0026quot;policy\u0026quot; : \u0026quot;observability-policy\u0026quot;,\r\u0026quot;phase_definition\u0026quot; : {\r\u0026quot;min_age\u0026quot; : \u0026quot;0ms\u0026quot;,\r\u0026quot;actions\u0026quot; : {\r\u0026quot;rollover\u0026quot; : {\r\u0026quot;max_docs\u0026quot; : 10\r},\r\u0026quot;set_priority\u0026quot; : {\r\u0026quot;priority\u0026quot; : 50\r}\r}\r},\r\u0026quot;version\u0026quot; : 1,\r\u0026quot;modified_date_in_millis\u0026quot; : 1645475702304\r}\r},\r\u0026quot;.ds-observability-time-series-2022.02.21-000002\u0026quot; : {\r\u0026quot;index\u0026quot; : \u0026quot;.ds-observability-time-series-2022.02.21-000002\u0026quot;,\r\u0026quot;managed\u0026quot; : true,\r\u0026quot;policy\u0026quot; : \u0026quot;observability-policy\u0026quot;,\r\u0026quot;lifecycle_date_millis\u0026quot; : 1645475884525,\r\u0026quot;age\u0026quot; : \u0026quot;4.91m\u0026quot;,\r\u0026quot;phase\u0026quot; : \u0026quot;hot\u0026quot;,\r\u0026quot;phase_time_millis\u0026quot; : 1645475884809,\r\u0026quot;action\u0026quot; : \u0026quot;rollover\u0026quot;,\r\u0026quot;action_time_millis\u0026quot; : 1645475885210,\r\u0026quot;step\u0026quot; : \u0026quot;check-rollover-ready\u0026quot;,\r\u0026quot;step_time_millis\u0026quot; : 1645475885210,\r\u0026quot;phase_execution\u0026quot; : {\r\u0026quot;policy\u0026quot; : \u0026quot;observability-policy\u0026quot;,\r\u0026quot;phase_definition\u0026quot; : {\r\u0026quot;min_age\u0026quot; : \u0026quot;0ms\u0026quot;,\r\u0026quot;actions\u0026quot; : {\r\u0026quot;rollover\u0026quot; : {\r\u0026quot;max_docs\u0026quot; : 10\r},\r\u0026quot;set_priority\u0026quot; : {\r\u0026quot;priority\u0026quot; : 50\r}\r}\r},\r\u0026quot;version\u0026quot; : 1,\r\u0026quot;modified_date_in_millis\u0026quot; : 1645475702304\r}\r}\r}\r}\rOn peut observer les différentes informations de nos index concernant ILM appliquée deçu.\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez mettre en place une politique de gestion du cylce de vie de vos index. Vous avez également exploré les différentes composants d\u0026rsquo;une politique de gestion d\u0026rsquo;index au travers des settings, mappings, template et data stream.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_metrics/","title":"Lab - Metrics","tags":[],"description":"","content":"Objectif : Dans ce laboratoire, vous explorerez la facilité avec laquelle vous pouvez obtenir des métriques système et NGINX avec Metricbeat et les indexer dans Elasticsearch. Vous explorerez également les tableaux de bord Kibana et verrez avec quelle facilité vous pouvez surveiller ces métriques.\nDéployer un agent beats Ajoutez le service Metricbeat à la suite du service Beats\nvim beats/beats-docker.yml\rbeats-docker.yml\nversion: '2.2'\rservices:\rfilebeat:\rimage: docker.elastic.co/beats/filebeat:${VERSION}\rcontainer_name: filebeat\rrestart: unless-stopped\rentrypoint: \u0026quot;filebeat -e -strict.perms=false\u0026quot;\ruser: root\rvolumes:\r- \u0026quot;./conf/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\u0026quot;\r- \u0026quot;/var/lib/docker/containers:/var/lib/docker/containers:ro\u0026quot;\r- \u0026quot;/var/run/docker.sock:/var/run/docker.sock:ro\u0026quot;\r- \u0026quot;/var/log:/tmp:ro\u0026quot;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rmetricbeat:\rimage: docker.elastic.co/beats/metricbeat:${VERSION}\rcontainer_name: metricbeat\rrestart: unless-stopped\rentrypoint: \u0026quot;metricbeat -e -strict.perms=false\u0026quot;\ruser: root\rvolumes:\r- \u0026quot;./conf/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro\u0026quot;\r- \u0026quot;/proc:/hostfs/proc:ro\u0026quot;\r- \u0026quot;/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\u0026quot;\r- \u0026quot;/:/hostfs:ro\u0026quot;\r- \u0026quot;/var/run/docker.sock:/var/run/docker.sock:ro\u0026quot;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge\rvim beats/conf/metricbeat.yml\r#-------------------------------- Autodiscovery -------------------------------\r# Autodiscover allows you to detect changes in the system and spawn new modules as they happen.\rmetricbeat.autodiscover:\rproviders:\r- type: docker\r# https://www.elastic.co/guide/en/beats/metricbeat/current/configuration-autodiscover-hints.html\rhints.enabled: true\rmetricbeat.modules:\r#------------------------------- System Module -------------------------------\r- module: system\rmetricsets: [\u0026quot;cpu\u0026quot;, \u0026quot;load\u0026quot;, \u0026quot;memory\u0026quot;, \u0026quot;network\u0026quot;, \u0026quot;process\u0026quot;, \u0026quot;process_summary\u0026quot;, \u0026quot;core\u0026quot;, \u0026quot;diskio\u0026quot;, \u0026quot;socket\u0026quot;]\rprocesses: ['.*']\rprocess.include_top_n:\rby_cpu: 5\rby_memory: 5\rperiod: 10s\rcpu.metrics: [\u0026quot;percentages\u0026quot;]\rcore.metrics: [\u0026quot;percentages\u0026quot;]\r- module: system\rperiod: 1m\rmetricsets:\r- filesystem\r- fsstat\rprocessors:\r- drop_event.when.regexp:\rsystem.filesystem.mount_point: '^/(sys|cgroup|proc|dev|etc|host|lib)($|/)'\r- module: system\rperiod: 15m\rmetricsets:\r- uptime\r#------------------------------- Docker Module -------------------------------\r- module: docker\rmetricsets: [\u0026quot;container\u0026quot;, \u0026quot;cpu\u0026quot;, \u0026quot;diskio\u0026quot;, \u0026quot;healthcheck\u0026quot;, \u0026quot;info\u0026quot;, \u0026quot;memory\u0026quot;, \u0026quot;network\u0026quot;]\rhosts: [\u0026quot;unix:///var/run/docker.sock\u0026quot;]\rperiod: 10s\r#================================ Processors ===================================\rprocessors:\r- add_docker_metadata: ~\r- add_locale:\rformat: offset\r- add_host_metadata:\rnetinfo.enabled: true\r#========================== Elasticsearch output ===============================\routput.elasticsearch:\rhosts: [\u0026quot;https://es01:9200\u0026quot;]\rusername: \u0026quot;beats_system\u0026quot;\rpassword: \u0026quot;CHANGEME\u0026quot;\rssl.enabled: true\rssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\r#============================== Dashboards =====================================\rsetup.dashboards:\renabled: true\r#============================== Kibana =========================================\rsetup.kibana:\rhost: \u0026quot;https://kib01:5601\u0026quot;\rusername: \u0026quot;elastic\u0026quot;\rpassword: \u0026quot;CHANGEME\u0026quot;\rssl.enabled: true\rssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\rChanger la valeur du champs password avec la valeur du mot de passe générer automatiquement.\ndocker-compose -f beats/beats-docker.yml up -d\rvim app/artificial_load.sh\r#!/bin/bash\rCOUNTER=0\rwhile [ $COUNTER -lt 10000 ] ;\rdo\rcurl -s --header \u0026quot;X-Forwarded-For: 5.198.223.255\u0026quot; localhost \u0026gt; /dev/null\rcurl -s localhost/owners/find \u0026gt; /dev/null\rcurl -s localhost/owners?lastName= \u0026gt; /dev/null\rcurl -s localhost/owners/1 \u0026gt; /dev/null\rcurl -s localhost/owners/4 \u0026gt; /dev/null\rcurl -s localhost/owners/6 \u0026gt; /dev/null\rcurl -s localhost/owners/8 \u0026gt; /dev/null\rcurl -s localhost/vets.html \u0026gt; /dev/null\rcurl -s localhost/oups \u0026gt; /dev/null\rlet COUNTER=COUNTER+1\rdone\rchmod +x app/artificial_load.sh\rMaintenant, ouvrez une nouvelle fenêtre de terminal et exécutez le script suivant pour simuler la charge sur votre serveur NGINX.\n./app/artificial_load.sh\rLancez Kibana pour commencer à explorer les tableaux de bord qui ont été inclus dans le processus de configuration.\nEnsuite, accédez à Dashboard via le menu principal.\nRecherchez le système et ouvrez la vue d\u0026rsquo;ensemble de Metricbeat System ECS.\nVous verrez quelque chose de similaire à la page ci-dessous.\nCliquez sur Vue d\u0026rsquo;ensemble de l\u0026rsquo;hôte en haut du tableau de bord actuel pour voir un tableau de bord avec plus d\u0026rsquo;informations que Metricbeat a collectées à partir de l\u0026rsquo;hôte de votre environnement de laboratoire.\nRetournez sur la page des tableaux de bord Kibana, recherchez nginx et ouvrez le tableau de bord ECS [Metricbeat Nginx] Overview.\nVous verrez quelque chose de similaire à la page ci-dessous.\nRetournez dans les tableaux de bord Kibana et cliquez sur Créer un nouveau tableau de bord pour comparer les données NGINX collectées à partir de Filebeat et Metricbeat.\nCliquez sur Ajouter depuis la bibliothèque pour commencer à ajouter des visualisations à votre tableau de bord.\nUtilisez la barre de requête pour filtrer par visualisations filebeat nginx et ajoutez les visualisations Filebeat suivantes : Journaux d\u0026rsquo;accès dans le temps et Codes de réponse dans le temps.\nMaintenant, filtrez par visualisations metricbeat nginx pour ajouter les visualisations Metricbeat suivantes : Taux de requêtes et Taux de lecture/écriture/attente.\nFermez la boîte de dialogue Ajouter à partir de la bibliothèque et enregistrez votre tableau de bord sous le nom de Filebeat x Metricbeat.\nVérifiez les différentes informations que vous pouvez obtenir à partir des journaux et des métriques de NGINX dans le tableau de bord que vous venez de créer.\nNotez que vous pouvez utiliser les données de Filebeat et de Metricbeat pour vérifier le nombre de requêtes par seconde, comme le montrent les visualisations Access logs over time et Request Rate. La version open source de NGINX ne fournit pas de métriques sur les codes de réponse, mais vous pouvez utiliser Filebeat pour obtenir ces informations à partir des journaux NGINX, comme vous pouvez le voir dans la visualisation des codes de réponse dans le temps. Avec les journaux NGINX, vous pouvez également vérifier l\u0026rsquo;emplacement, le système d\u0026rsquo;exploitation, le navigateur, la durée et de nombreuses autres informations sur les demandes. Cependant, les journaux NGINX ne vous disent pas combien de connexions ont été acceptées, traitées et abandonnées. Dans ce cas, vous pouvez utiliser Metricbeat pour collecter ces informations ainsi que le nombre de connexions actives et le nombre de connexions en lecture, écriture et attente, comme vous pouvez le voir dans la visualisation du taux de lecture / écriture / attente.\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez obtenir des mesures du système et de NGINX avec Metricbeat et les indexer dans Elasticsearch. Vous avez également exploré les tableaux de bord Kibana et vu avec quelle facilité vous pouvez surveiller ces mesures.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/","title":"Débutant","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_apm/","title":"Lab - APM","tags":[],"description":"","content":"Serveur APM Objectif : Dans ce laboratoire, vous apprendrez comment il est facile d\u0026rsquo;utiliser APM pour instrumenter les applications afin de collecter des informations détaillées sur les performances ainsi que les erreurs et les envoyer à votre déploiement Elasticsearch. Vous explorerez également l\u0026rsquo;application APM Kibana et verrez avec quelle facilité vous pouvez surveiller les performances des applications.\nAjoutez le service APM ci-dessous dans le fichier elastic-docker-tls.yml :\n apm-server:\rimage: docker.elastic.co/apm/apm-server:${VERSION}\rcontainer_name: apm-server\rdepends_on:\res01: { condition: service_healthy }\rkib01: { condition: service_healthy }\rcap_add: [\u0026quot;CHOWN\u0026quot;, \u0026quot;DAC_OVERRIDE\u0026quot;, \u0026quot;SETGID\u0026quot;, \u0026quot;SETUID\u0026quot;]\rcap_drop: [\u0026quot;ALL\u0026quot;]\rports:\r- 8200:8200\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rcommand: \u0026gt;\rapm-server -e\r-E apm-server.rum.enabled=true\r-E setup.kibana.host=kib01:5601\r-E setup.template.settings.index.number_of_replicas=1\r-E apm-server.kibana.enabled=true\r-E apm-server.kibana.host=kib01:5601\r-E apm-server.kibana.protocol=https\r-E apm-server.kibana.username=$USER_ELASTIC\r-E apm-server.kibana.password=$PASSWORD_ELASTIC\r-E apm-server.kibana.ssl.enabled=true\r-E apm-server.kibana.ssl.certificate_authorities=[\u0026quot;$CERTS_DIR/ca/ca.crt\u0026quot;]\r-E output.elasticsearch.hosts=[\u0026quot;https://es01:9200\u0026quot;]\r-E output.elasticsearch.username=$USER_ELASTIC\r-E output.elasticsearch.password=$PASSWORD_ELASTIC\r-E output.elasticsearch.ssl.certificate_authorities=[\u0026quot;$CERTS_DIR/ca/ca.crt\u0026quot;]\rhealthcheck:\rinterval: 10s\rretries: 12\rtest: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/\rdocker-compose -f elastic-docker-tls.yml up -d\rL\u0026rsquo;application Petclinic contient des variables d\u0026rsquo;environnement pour contacter le serveur APM :\n petclinic:\rimage: docker.io/michaelhyatt/elastic-k8s-o11y-workshop-petclinic:1.25.0\rcontainer_name: petclinic\rlabels:\r\u0026quot;co.elastic.metrics/module\u0026quot;: \u0026quot;prometheus\u0026quot;\r\u0026quot;co.elastic.metrics/hosts\u0026quot;: \u0026quot;$${data.host}:$${data.port}\u0026quot;\r\u0026quot;co.elastic.metrics/metrics_path\u0026quot;: \u0026quot;/metrics/prometheus\u0026quot;\r\u0026quot;co.elastic.metrics/period\u0026quot;: \u0026quot;1m\u0026quot;\renvironment:\rELASTIC_APM_SERVER_URLS: \u0026quot;http://apm-server:8200\u0026quot;\rELASTIC_APM_SERVER_URLS_FOR_RUM: \u0026quot;http://localhost:8200\u0026quot;\rELASTIC_APM_SECRET_TOKEN: \u0026quot;\u0026quot;\rELASTIC_APM_SERVICE_NAME: \u0026quot;spring-petclinic-monolith\u0026quot;\rELASTIC_APM_APPLICATION_PACKAGES: \u0026quot;org.springframework.samples\u0026quot;\rELASTIC_APM_ENABLE_LOG_CORRELATION: \u0026quot;true\u0026quot;\rELASTIC_APM_CAPTURE_JMX_METRICS: \u0026gt;\robject_name[java.lang:type=GarbageCollector,name=*] attribute[CollectionCount:metric_name=collection_count] attribute[CollectionTime:metric_name=collection_time],\robject_name[java.lang:type=Memory] attribute[HeapMemoryUsage:metric_name=heap]\rCes variables d\u0026rsquo;environnent font des références aux agents APM installés dans le code de l\u0026rsquo;application.\nMaintenant que les trois microservices sont en cours d\u0026rsquo;exécution, accédez à la page Web de Petclinic et vous devriez voir la page d\u0026rsquo;accueil suivante :\nCliquez sur FIND OWNERS et VETERINARIANS pour générer des données de performance à envoyer au serveur APM.\nCliquez sur ERROR pour générer des erreurs qui seront envoyées au serveur APM. Assurez-vous que vous obtenez le statut 404 et le message d\u0026rsquo;erreur No message available comme suit :\nSi vous n\u0026rsquo;obtenez pas cette erreur, cliquez sur HOME et cliquez à nouveau sur ERROR jusqu\u0026rsquo;à ce que vous obteniez cette erreur.\nLancez l\u0026rsquo;application APM pour commencer à explorer les données collectées.\nAprès avoir lancé l\u0026rsquo;application APM, vous accédez à l\u0026rsquo;aperçu des services.\nCliquez sur Détails du service pour explorer la santé globale du front-end en vérifiant les métriques sur les transactions, les erreurs et l\u0026rsquo;infrastructure.\nEnsuite, cliquez sur l\u0026rsquo;aperçu des transactions et sélectionnez le type de transaction http-request pour explorer les requêtes du frontend.\nEnsuite, cliquez sur GET /api/vets pour explorer le traçage distribué et voir comment les applications et les services interagissent entre eux.\nEnsuite, cliquez sur l\u0026rsquo;aperçu des erreurs pour explorer les erreurs de l\u0026rsquo;application.\nEnsuite, cliquez sur l\u0026rsquo;erreur \u0026ldquo;Aucun message disponible\u0026rdquo; pour voir la trace de la pile qui indique l\u0026rsquo;origine de l\u0026rsquo;erreur.\nEnfin, cliquez sur la transaction GET /api/error pour voir les erreurs associées et comment elles se sont propagées parmi les services.\nRésumé : Dans ce laboratoire, vous avez appris comment il est facile de configurer des agents APM pour collecter des informations de trace et des erreurs afin de les indexer dans Elasticsearch. Vous avez également exploré l\u0026rsquo;application APM Kibana et vu avec quelle facilité vous pouvez surveiller les performances des applications.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/backup/","title":"Lab - Backup &amp; Restore","tags":[],"description":"","content":"La haute disponibilité et la redondance d\u0026rsquo;Elasticsearch en font une plateforme stable et fiable pour le stockage de quantités massives de données. Toutefois, pour vous protéger contre les erreurs humaines et les catastrophes naturelles, vous devez toujours sauvegarder vos données Elasticsearch. L\u0026rsquo;endroit où vous stockez vos sauvegardes de données Elasticsearch est entièrement à votre discrétion. Dans ce laboratoire pratique, nous utiliserons le système de fichiers local pour démontrer comment :\n Créer des dépôts instantanés Sauvegarder des index spécifiques Restaurer des données à partir d\u0026rsquo;un instantané  Créer et configurer le répertoire d\u0026rsquo;instantanés Modifier la configuration des noeuds Elasticsearch présent dans le fichier elastic-docker-tls.yml\nes01:\r...\renvironment:\r- path.repo=/usr/share/elasticsearch/snapshots/\r...\res02:\r...\renvironment:\r- path.repo=/usr/share/elasticsearch/snapshots/\r...\res03:\r...\renvironment:\r- path.repo=/usr/share/elasticsearch/snapshots/\r...\rRedémarrer vos intances Elasticsearch\ndocker-compose -f elastic-docker-tls.yml\rCréez le référentiel \u0026ldquo;observability_repo\u0026rdquo;. Utilisez l\u0026rsquo;outil DevTool Kibana pour exécuter ce qui suit :\nPUT _snapshot/observability_repo?verify=false\r{\r\u0026quot;type\u0026quot;: \u0026quot;fs\u0026quot;,\r\u0026quot;settings\u0026quot;: {\r\u0026quot;location\u0026quot;: \u0026quot;/usr/share/elasticsearch/snapshots/\u0026quot;\r}\r}\rSauvegarde de l\u0026rsquo;index \u0026ldquo;observability-time-series\u0026rdquo; Utilisez l\u0026rsquo;outil de console Kibana pour exécuter ce qui suit :\nPUT _snapshot/observability_repo/observability?wait_for_completion=true\r{\r\u0026quot;indices\u0026quot;: \u0026quot;observability-time-series\u0026quot;,\r\u0026quot;include_global_state\u0026quot;: false\r}\rRestaurez l\u0026rsquo;index \u0026ldquo;observability-time-series\u0026rdquo; en tant que \u0026ldquo;observability-time-series_restored\u0026rdquo; Utilisez l\u0026rsquo;outil de console Kibana pour exécuter ce qui suit :\nPOST _snapshot/observability-time-series_repo/observability-time-series/_restore\r{\r\u0026quot;indices\u0026quot;: \u0026quot;observability-time-series\u0026quot;,\r\u0026quot;rename_pattern\u0026quot;: \u0026quot;(.+)\u0026quot;,\r\u0026quot;rename_replacement\u0026quot;: \u0026quot;$1_restored\u0026quot;\r}\r{\r\u0026quot;accepted\u0026quot; : true\r}\rGET _cat/indices\rgreen open metricbeat-7.17.0-2022.02.22-000001 WBLcTqYORtS5LJyFttVBXQ 1 1 22122 0 67.6mb 34.8mb\rgreen open apm-7.17.0-error-000001 TuCoez2IQP6xmRJl70TKvw 1 1 1842 0 4.7mb 2.3mb\ryellow open .ds-observability-time-series-2022.02.22-000002 xKbIQkulR0mMwv8aCbR5Og 1 10 1 0 12.3kb 4.1kb\ryellow open .ds-observability-time-series-2022.02.22-000001 i_sIi8P2SUu6mNmlsMjv3Q 1 10 16 0 19.4kb 6.5kb\rgreen open apm-7.17.0-transaction-000001 O14qvTcvQyOOIp8kIGGpKg 1 1 17027 0 25mb 11.1mb\rgreen open .apm-agent-configuration jkaqvfq0Sy25CHaLDswUUA 1 1 0 0 452b 226b\rgreen open apm-7.17.0-metric-000001 mXYNU6V9SU2tlAmODIjPHQ 1 1 4497 0 4.7mb 2.3mb\rgreen open apm-7.17.0-span-000001 iOVtWj8iRL6b-YbxROQ9ig 1 1 75766 0 44.5mb 19.8mb\rgreen open apm-7.17.0-onboarding-2022.02.22 dJ8FT0LvSn2HTUynoxWtbQ 1 1 1 0 16.1kb 8kb\rgreen open apm-7.17.0-profile-000001 dQEJ37KkSzmQr4DVKLQnAw 1 1 0 0 452b 226b\rgreen open filebeat-7.17.0-2022.02.22-000001 hN3UWBgXRYm9KA66iHfayQ 1 1 236916 0 279.3mb 138.5mb\rgreen open .ds-observability-time-series-2022.02.22-000001_restored _WQSy8o3QTi6l4inCqpA8Q 1 1 16 0 13.1kb 6.5kb\rgreen open .security-7 o2VUY0seRxSefLHyOge4rQ 1 1 60 0 531.1kb 295.6kb\rgreen open .kibana_7.17.0_001 J_lf9M3zRjmHgMdRhwcqLw 1 1 4424 328 8.1mb 4mb\rgreen open .apm-custom-link fnAtCfqXSsOCN7dqyGQT8A 1 1 0 0 452b 226b\rgreen open .ds-observability-time-series-2022.02.22-000002_restored SUVTggxqRMODlSz4pE3gEw 1 1 1 0 8.3kb 4.1kb\rgreen open heartbeat-7.17.0-2022.02.22-000001 U50p8dOMSz2jhWz7kHRDnw 1 1 648 0 2.6mb 1.3mb\rgreen open .async-search JjeGtgVgTYKlJ8PsvmwL7Q 1 1 0 0 6.9kb 3.4kb\rgreen open .kibana_task_manager_7.17.0_001 x63yGuhDSaudkMeqtmxANA 1 1 18 1122 753.7kb 368.6kb\rSLM Policy La gestion du cycle de vie des instantanés (SLM) est le moyen le plus simple de sauvegarder régulièrement un cluster. Une politique SLM prend automatiquement des instantanés selon une planification prédéfinie. La politique peut également supprimer les instantanés en fonction des règles de rétention que vous définissez.\nPUT _slm/policy/daily-observability-snpashots\r{\r\u0026quot;name\u0026quot;: \u0026quot;\u0026lt;observability-{now/d}\u0026gt;\u0026quot;,\r\u0026quot;schedule\u0026quot;: \u0026quot;0 30 1 * * ?\u0026quot;,\r\u0026quot;repository\u0026quot;: \u0026quot;observability_repo\u0026quot;,\r\u0026quot;config\u0026quot;: {\r\u0026quot;indices\u0026quot;: [\r\u0026quot;observability-time-series\u0026quot;\r]\r},\r\u0026quot;retention\u0026quot;: {\r\u0026quot;expire_after\u0026quot;: \u0026quot;30d\u0026quot;,\r\u0026quot;min_count\u0026quot;: 15,\r\u0026quot;max_count\u0026quot;: 30\r}\r}\rGET _slm/policy/daily-observability-snpashots\r{\r\u0026quot;daily-observability-snpashots\u0026quot; : {\r\u0026quot;version\u0026quot; : 1,\r\u0026quot;modified_date_millis\u0026quot; : 1645547161680,\r\u0026quot;policy\u0026quot; : {\r\u0026quot;name\u0026quot; : \u0026quot;\u0026lt;observability-{now/d}\u0026gt;\u0026quot;,\r\u0026quot;schedule\u0026quot; : \u0026quot;0 30 1 * * ?\u0026quot;,\r\u0026quot;repository\u0026quot; : \u0026quot;observability_repo\u0026quot;,\r\u0026quot;config\u0026quot; : {\r\u0026quot;indices\u0026quot; : [\r\u0026quot;observability-time-series\u0026quot;\r]\r},\r\u0026quot;retention\u0026quot; : {\r\u0026quot;expire_after\u0026quot; : \u0026quot;30d\u0026quot;,\r\u0026quot;min_count\u0026quot; : 15,\r\u0026quot;max_count\u0026quot; : 30\r}\r},\r\u0026quot;next_execution_millis\u0026quot; : 1645579800000,\r\u0026quot;stats\u0026quot; : {\r\u0026quot;policy\u0026quot; : \u0026quot;daily-observability-snpashots\u0026quot;,\r\u0026quot;snapshots_taken\u0026quot; : 0,\r\u0026quot;snapshots_failed\u0026quot; : 0,\r\u0026quot;snapshots_deleted\u0026quot; : 0,\r\u0026quot;snapshot_deletion_failures\u0026quot; : 0\r}\r}\r}\r"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_uptime/","title":"Lab - Uptime","tags":[],"description":"","content":"Objectif : Dans ce laboratoire, vous explorerez la facilité avec laquelle vous pouvez obtenir des métriques des disponibilités des services avec Heratbeat et les indexer dans Elasticsearch. Vous explorerez également les tableaux de bord Kibana et verrez avec quelle facilité vous pouvez surveiller ces métriques.\nDéployer un agent beats Ajoutez le service Heartbeat à la suite du service Beats\nvim beats/beats-docker.yml\rbeats-docker.yml\nversion: '2.2'\rservices:\rfilebeat:\rimage: docker.elastic.co/beats/filebeat:${VERSION}\rcontainer_name: filebeat\rrestart: unless-stopped\rentrypoint: \u0026quot;filebeat -e -strict.perms=false\u0026quot;\ruser: root\rvolumes:\r- \u0026quot;./conf/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\u0026quot;\r- \u0026quot;/var/lib/docker/containers:/var/lib/docker/containers:ro\u0026quot;\r- \u0026quot;/var/run/docker.sock:/var/run/docker.sock:ro\u0026quot;\r- \u0026quot;/var/log:/tmp:ro\u0026quot;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rmetricbeat:\rimage: docker.elastic.co/beats/metricbeat:${VERSION}\rcontainer_name: metricbeat\rrestart: unless-stopped\rentrypoint: \u0026quot;metricbeat -e -strict.perms=false\u0026quot;\ruser: root\rvolumes:\r- \u0026quot;./conf/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro\u0026quot;\r- \u0026quot;/proc:/hostfs/proc:ro\u0026quot;\r- \u0026quot;/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\u0026quot;\r- \u0026quot;/:/hostfs:ro\u0026quot;\r- \u0026quot;/var/run/docker.sock:/var/run/docker.sock:ro\u0026quot;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rheartbeat:\rimage: docker.elastic.co/beats/heartbeat:${VERSION}\rcontainer_name: heartbeat\rrestart: unless-stopped\rentrypoint: \u0026quot;heartbeat -e -strict.perms=false\u0026quot;\ruser: root\rvolumes:\r- \u0026quot;./conf/heartbeat.yml:/usr/share/heartbeat/heartbeat.yml:ro\u0026quot;\r- \u0026quot;/var/run/docker.sock:/var/run/docker.socki:ro\u0026quot;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge\rvim beats/conf/heartbeat.yml\rheartbeat.monitors:\r- type: http\rid: nginx-service-status\rname: Nginx Status\rschedule: '@every 10s'\rurls:\r- http://nginx\rtimeout: 30s\rcheck.response:\rstatus: 200\rbody:\r- \u0026quot;Welcome\u0026quot;\r- type: http\rid: petclinic-service-status\rname: Petclinic Status\rschedule: '@every 10s'\rurls:\r- http://petclinic:8080/metrics/prometheus\rtimeout: 30s\rcheck.response:\rstatus: 200\rbody:\r- \u0026quot;jvm_memory_committed_bytes\u0026quot;\r- type: tcp\rid: mysql-service-status\rname: MySQL Status\rschedule: '@every 10s'\rhosts: [\u0026quot;tcp://mysql:3306\u0026quot;]\rprocessors:\r- add_cloud_metadata: ~\r- add_docker_metadata: ~\routput.elasticsearch:\rhosts: 'https://es01:9200'\rusername: \u0026quot;elastic\u0026quot;\rpassword: \u0026quot;CHANGEME\u0026quot;\rssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\rChanger la valeur du champs password avec la valeur du mot de passe générer automatiquement.\ndocker-compose -f beats/beats-docker.yml up -d\rvim app/artificial_load.sh\r#!/bin/bash\rCOUNTER=0\rwhile [ $COUNTER -lt 10000 ] ;\rdo\rcurl -s --header \u0026quot;X-Forwarded-For: 5.198.223.255\u0026quot; localhost \u0026gt; /dev/null\rcurl -s localhost/owners/find \u0026gt; /dev/null\rcurl -s localhost/owners?lastName= \u0026gt; /dev/null\rcurl -s localhost/owners/1 \u0026gt; /dev/null\rcurl -s localhost/owners/4 \u0026gt; /dev/null\rcurl -s localhost/owners/6 \u0026gt; /dev/null\rcurl -s localhost/owners/8 \u0026gt; /dev/null\rcurl -s localhost/vets.html \u0026gt; /dev/null\rcurl -s localhost/oups \u0026gt; /dev/null\rlet COUNTER=COUNTER+1\rdone\rchmod +x app/artificial_load.sh\rMaintenant, ouvrez une nouvelle fenêtre de terminal et exécutez le script suivant pour simuler la charge sur votre serveur NGINX.\n./app/artificial_load.sh\rNaviguer dans l\u0026rsquo;application Petclinic quelque instant pour générer un traffic utilisateur sur un navigateur web.\nLancez Kibana pour commencer à explorer les tableaux de bord qui ont été inclus dans le menu Observability\nCliquez sur le bouton View app\nVous pouvez observer que l\u0026rsquo;agent beat réalise 3 vérification de disponibilité. Un pour chaque service de l\u0026rsquo;application.\nCliquez sur le monitor Nginx Status\nVous avez maintenant un vue détaillée du service nginx comme les temps de réponses, la disponibilité, etc\u0026hellip;\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez obtenir des mesures des vos services liée à l\u0026rsquo;application Petclinic avec Heartbeat et les indexer dans Elasticsearch. Vous avez également exploré les tableaux de bord Kibana et vu avec quelle facilité vous pouvez surveiller ces mesures.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/","title":"Elementaire","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/","title":"Intermediare","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/avance/","title":"Avancé","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/","title":"Elastic Tutoriel","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/","title":"Elastic","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/tags/","title":"Tags","tags":[],"description":"","content":""}]