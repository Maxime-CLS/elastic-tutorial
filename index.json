[{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/prerequis/","title":"Prérequis","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/apm/","title":"APM","tags":[],"description":"","content":"Serveur APM Ajoutez le service APM ci-dessous dans le fichier elastic-docker-tls.yml :\n apm-server:\rimage: docker.elastic.co/apm/apm-server:${VERSION}\rcontainer_name: apm-server\rdepends_on:\res01: { condition: service_healthy }\rkib01: { condition: service_healthy }\rcap_add: [\u0026quot;CHOWN\u0026quot;, \u0026quot;DAC_OVERRIDE\u0026quot;, \u0026quot;SETGID\u0026quot;, \u0026quot;SETUID\u0026quot;]\rcap_drop: [\u0026quot;ALL\u0026quot;]\rports:\r- 8200:8200\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rcommand: \u0026gt;\rapm-server -e\r-E apm-server.rum.enabled=true\r-E setup.kibana.host=kib01:5601\r-E setup.template.settings.index.number_of_replicas=1\r-E apm-server.kibana.enabled=true\r-E apm-server.kibana.host=kib01:5601\r-E apm-server.kibana.protocol=https\r-E apm-server.kibana.username=$USER_ELASTIC\r-E apm-server.kibana.password=$PASSWORD_ELASTIC\r-E apm-server.kibana.ssl.enabled=true\r-E apm-server.kibana.ssl.certificate_authorities=[\u0026quot;$CERTS_DIR/ca/ca.crt\u0026quot;]\r-E output.elasticsearch.hosts=[\u0026quot;https://es01:9200\u0026quot;]\r-E output.elasticsearch.username=$USER_ELASTIC\r-E output.elasticsearch.password=$PASSWORD_ELASTIC\r-E output.elasticsearch.ssl.certificate_authorities=[\u0026quot;$CERTS_DIR/ca/ca.crt\u0026quot;]\rhealthcheck:\rinterval: 10s\rretries: 12\rtest: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/\rdocker-compose -f elastic-docker-tls.yml up -d\r"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/fleet/","title":"APM","tags":[],"description":"","content":"Serveur Fleet Ajoutez les deux services ci-dessous dans le fichier elastic-docker-tls.yml :\n package-registry:\rimage: docker.elastic.co/package-registry/distribution:${VERSION}\rcontainer_name: package-registry\rports:\r- 443\renvironment:\r- EPR_ADDRESS=0.0.0.0:443\r- EPR_TLS_KEY=$CERTS_DIR/package-registry/package-registry.key\r- EPR_TLS_CERT=$CERTS_DIR/package-registry/package-registry.crt\rhealthcheck:\rtest: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost/health \u0026gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi\rretries: 100\rinterval: 5s\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rfleet-server:\rimage: docker.elastic.co/beats/elastic-agent:${VERSION}\rcontainer_name: fleet-server\rports:\r- 8220:8220\rhealthcheck:\rtest: [\u0026quot;CMD-SHELL\u0026quot;, \u0026quot;curl -s -k https://localhost:8220/api/status | grep -q 'HEALTHY'\u0026quot;]\rretries: 300\rinterval: 1s\renvironment:\rFLEET_SERVER_ENABLE: \u0026quot;1\u0026quot;\rELASTICSEARCH_HOST: \u0026quot;https://es01:9200\u0026quot;\rELASTICSEARCH_CA: $CERTS_DIR/ca/ca.crt\rELASTICSEARCH_USERNAME: elastic\rELASTICSEARCH_PASSWORD: CHANGEME\rFLEET_URL: \u0026quot;https://fleet-server:8220\u0026quot;\rFLEET_SERVER_CERT: $CERTS_DIR/fleet-server/fleet-server.crt\rFLEET_SERVER_CERT_KEY: $CERTS_DIR/fleet-server/fleet-server.key\rKIBANA_FLEET_SETUP: \u0026quot;true\u0026quot;\rKIBANA_HOST: \u0026quot;https://kib01:5601\u0026quot;\rKIBANA_USERNAME: elastic\rKIBANA_PASSWORD: CHANGEME\rKIBANA_CA: $CERTS_DIR/ca/ca.crt\rdepends_on:\res01: { condition: service_healthy }\rkib01: { condition: service_healthy }\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rDéfinissez ELASTICSEARCH_PASSWORD et KIBANA_PASSWORD dans le fichier elastic-docker-tls.yml avec le mot de passe généré pour l\u0026rsquo;utilisateur elastic.\nfleet-server:\rimage: docker.elastic.co/beats/elastic-agent:${VERSION}\rcontainer_name: fleet-server\rports:\r- 8220:8220\rhealthcheck:\rtest: [\u0026quot;CMD-SHELL\u0026quot;, \u0026quot;curl -s -k https://localhost:8220/api/status | grep -q 'HEALTHY'\u0026quot;]\rretries: 300\rinterval: 1s\renvironment:\rFLEET_SERVER_ENABLE: \u0026quot;1\u0026quot;\rELASTICSEARCH_HOST: \u0026quot;https://es01:9200\u0026quot;\rELASTICSEARCH_CA: $CERTS_DIR/ca/ca.crt\rELASTICSEARCH_USERNAME: elastic\rELASTICSEARCH_PASSWORD: CHANGEME\rFLEET_URL: \u0026quot;https://fleet-server:8220\u0026quot;\rFLEET_SERVER_CERT: $CERTS_DIR/fleet-server/fleet-server.crt\rFLEET_SERVER_CERT_KEY: $CERTS_DIR/fleet-server/fleet-server.key\rKIBANA_FLEET_SETUP: \u0026quot;true\u0026quot;\rKIBANA_HOST: \u0026quot;https://kib01:5601\u0026quot;\rKIBANA_USERNAME: elastic\rKIBANA_PASSWORD: CHANGEME\rKIBANA_CA: $CERTS_DIR/ca/ca.crt\rdocker-compose -f elastic-docker-tls.yml up -d\rVérifiez la connexion entre le serveur Fleet et Kibana :\nManagement -\u0026gt; Fleet\nServeur APM Ajoutez le service ELastic Agent dans le fichier elastic-docker-tls.yml : :\n elastic-agent:\rimage: docker.elastic.co/beats/elastic-agent-complete:${VERSION}\rcontainer_name: elastic-agent\rrestart: always\ruser: root # note, synthetic browser monitors require this set to `elastic-agent`\renvironment:\rFLEET_ENROLL: 1\rFLEET_URL: \u0026quot;https://fleet-server:8220\u0026quot;\rFLEET_TOKEN_POLICY_NAME: \u0026quot;Default policy\u0026quot;\rFLEET_CA: $CERTS_DIR/ca/ca.crt\rKIBANA_FLEET_HOST: https://kib01:5601\rKIBANA_FLEET_USERNAME: elastic\rKIBANA_FLEET_PASSWORD: CHANGEME\rKIBANA_FLEET_CA: $CERTS_DIR/ca/ca.crt\rdepends_on:\res01: { condition: service_healthy }\rfleet-server: { condition: service_healthy }\rvolumes:\r- certs:$CERTS_DIR\r- /var/run/docker.sock:/var/run/docker.sock:ro\r- /var/log:/var/log:ro\r- /var/lib/docker/containers:/var/lib/docker/containers:ro\r- /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\r- /proc:/hostfs/proc:ro\r- /:/hostfs:ro\rnetworks:\r- elastic\rModifier la configuration par défaut des agents elastic via le serveur fleet sur l\u0026rsquo;interface Kibana :\nManagement -\u0026gt; Fleet\nCliquez sur Fleet settings\nFleet Server Hosts\nhttps://fleet-server:8220\rElasticsearch Output Configuration (YAML)\nssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\rDéfinissez KIBANA_FLEET_PASSWORD dans le fichier elastic-docker-tls.yml avec le mot de passe généré pour l\u0026rsquo;utilisateur elastic.\n elastic-agent:\rimage: docker.elastic.co/beats/elastic-agent-complete:${VERSION}\rcontainer_name: elastic-agent\rrestart: always\ruser: root # note, synthetic browser monitors require this set to `elastic-agent`\renvironment:\rFLEET_ENROLL: 1\rFLEET_URL: \u0026quot;https://fleet-server:8220\u0026quot;\rFLEET_TOKEN_POLICY_NAME: \u0026quot;Default policy\u0026quot;\rFLEET_CA: $CERTS_DIR/ca/ca.crt\rKIBANA_FLEET_HOST: https://kib01:5601\rKIBANA_FLEET_USERNAME: elastic\rKIBANA_FLEET_PASSWORD: CHANGEME\rKIBANA_FLEET_CA: $CERTS_DIR/ca/ca.crt\rdepends_on:\res01: { condition: service_healthy }\rfleet-server: { condition: service_healthy }\rvolumes:\r- certs:$CERTS_DIR\r- /var/run/docker.sock:/var/run/docker.sock:ro\r- /var/log:/var/log:ro\r- /var/lib/docker/containers:/var/lib/docker/containers:ro\r- /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\r- /proc:/hostfs/proc:ro\r- /:/hostfs:ro\rnetworks:\r- elastic\rAprès quelques minutes vous devez voir apparaitre l\u0026rsquo;agent elastic sur l\u0026rsquo;interface Kibana.\nIntégration du module APM "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/prerequis/installation/","title":"Installation","tags":[],"description":"","content":"Prérequis  Ubuntu ou Debian Docker Exécuter la commande ci-dessous  sudo sysctl -w vm.max_map_count=262144\rDéployer la stack Elasticsearch Kibana dans Docker avec TLS activé Si les fonctions de sécurité sont activées, vous devez configurer le chiffrement TLS (Transport Layer Security) pour la couche de transport d\u0026rsquo;Elasticsearch. Bien qu\u0026rsquo;il soit possible d\u0026rsquo;utiliser une licence d\u0026rsquo;essai sans configurer TLS, nous vous conseillons de sécuriser votre pile dès le départ.\nPour obtenir un cluster Elasticsearch et Kibana opérationnel dans Docker avec la sécurité activée, vous pouvez utiliser Docker Compose :\nCréez les fichiers de composition et de configuration suivants. Ces fichiers sont également disponibles dans le dépôt elastic/stack-docs sur GitHub.\ninstances.yml identifie les instances pour lesquelles vous devez créer des certificats. .env définit des variables d\u0026rsquo;environnement pour spécifier la version d\u0026rsquo;Elasticsearch et l\u0026rsquo;emplacement où les certificats Elasticsearch seront créés. create-certs.yml est un fichier Docker Compose qui lance un conteneur pour générer les certificats pour Elasticsearch et Kibana. elastic-docker-tls.yml est un fichier Docker Compose qui met en place un cluster Elasticsearch à trois nœuds et une instance Kibana avec TLS activé afin que vous puissiez voir comment les choses fonctionnent. Cette configuration tout-en-un est un moyen pratique de mettre en place votre premier cluster de développement avant de construire un déploiement distribué avec plusieurs hôtes.\ninstances.yml :\ninstances:\r- name: es01\rdns:\r- es01\r- localhost\rip:\r- 127.0.0.1\r- name: es02\rdns:\r- es02\r- localhost\rip:\r- 127.0.0.1\r- name: es03\rdns:\r- es03\r- localhost\rip:\r- 127.0.0.1\r- name: 'kib01'\rdns:\r- kib01\r- localhost\r- name: 'package-registry'\rdns:\r- package-registry\r- localhost\r- name: 'fleet-server'\rdns:\r- fleet-server\r- localhost\r.env:\nCOMPOSE_PROJECT_NAME=es\rCERTS_DIR=/usr/share/elasticsearch/config/certificates\rVERSION=7.17.0\rcreate-certs.yml:\nversion: '2.2'\rservices:\rcreate_certs:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: create_certs\rcommand: \u0026gt;\rbash -c '\ryum install -y -q -e 0 unzip;\rif [[ ! -f /certs/bundle.zip ]]; then\rbin/elasticsearch-certutil cert --silent --pem --in config/certificates/instances.yml -out /certs/bundle.zip;\runzip /certs/bundle.zip -d /certs;\rfi;\rchown -R 1000:0 /certs\r'\rworking_dir: /usr/share/elasticsearch\rvolumes:\r- certs:/certs\r- .:/usr/share/elasticsearch/config/certificates\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge\relastic-docker-tls.yml:\nversion: '2.2'\rservices:\res01:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: es01\renvironment:\r- node.name=es01\r- cluster.name=es-docker-cluster\r- discovery.seed_hosts=es02,es03\r- cluster.initial_master_nodes=es01,es02,es03\r- bootstrap.memory_lock=true\r- \u0026quot;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026quot;\r- xpack.license.self_generated.type=trial\r- xpack.security.enabled=true\r- xpack.security.http.ssl.enabled=true\r- xpack.security.http.ssl.key=$CERTS_DIR/es01/es01.key\r- xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.http.ssl.certificate=$CERTS_DIR/es01/es01.crt\r- xpack.security.transport.ssl.enabled=true\r- xpack.security.transport.ssl.verification_mode=certificate\r- xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.transport.ssl.certificate=$CERTS_DIR/es01/es01.crt\r- xpack.security.transport.ssl.key=$CERTS_DIR/es01/es01.key\r- xpack.security.authc.api_key.enabled=true\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- data01:/usr/share/elasticsearch/data\r- certs:$CERTS_DIR\rports:\r- 9200:9200\rnetworks:\r- elastic\rhealthcheck:\rtest: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost:9200 \u0026gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi\rinterval: 30s\rtimeout: 10s\rretries: 5\res02:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: es02\renvironment:\r- node.name=es02\r- cluster.name=es-docker-cluster\r- discovery.seed_hosts=es01,es03\r- cluster.initial_master_nodes=es01,es02,es03\r- bootstrap.memory_lock=true\r- \u0026quot;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026quot;\r- xpack.license.self_generated.type=trial\r- xpack.security.enabled=true\r- xpack.security.http.ssl.enabled=true\r- xpack.security.http.ssl.key=$CERTS_DIR/es02/es02.key\r- xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.http.ssl.certificate=$CERTS_DIR/es02/es02.crt\r- xpack.security.transport.ssl.enabled=true\r- xpack.security.transport.ssl.verification_mode=certificate\r- xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.transport.ssl.certificate=$CERTS_DIR/es02/es02.crt\r- xpack.security.transport.ssl.key=$CERTS_DIR/es02/es02.key\r- xpack.security.authc.api_key.enabled=true\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- data02:/usr/share/elasticsearch/data\r- certs:$CERTS_DIR\rnetworks:\r- elastic\res03:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: es03\renvironment:\r- node.name=es03\r- cluster.name=es-docker-cluster\r- discovery.seed_hosts=es01,es02\r- cluster.initial_master_nodes=es01,es02,es03\r- bootstrap.memory_lock=true\r- \u0026quot;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026quot;\r- xpack.license.self_generated.type=trial\r- xpack.security.enabled=true\r- xpack.security.http.ssl.enabled=true\r- xpack.security.http.ssl.key=$CERTS_DIR/es03/es03.key\r- xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.http.ssl.certificate=$CERTS_DIR/es03/es03.crt\r- xpack.security.transport.ssl.enabled=true\r- xpack.security.transport.ssl.verification_mode=certificate\r- xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.transport.ssl.certificate=$CERTS_DIR/es03/es03.crt\r- xpack.security.transport.ssl.key=$CERTS_DIR/es03/es03.key\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- data03:/usr/share/elasticsearch/data\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rkib01:\rimage: docker.elastic.co/kibana/kibana:${VERSION}\rcontainer_name: kib01\rdepends_on:\res01: { condition: service_healthy}\rpackage-registry: { condition: service_healthy }\rports:\r- 5601:5601\renvironment:\rSERVERNAME: localhost\rELASTICSEARCH_URL: https://es01:9200\rELASTICSEARCH_HOSTS: https://es01:9200\rELASTICSEARCH_USERNAME: kibana_system\rELASTICSEARCH_PASSWORD: UZuuB5ABGjTBZPez4aDl\rELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES: $CERTS_DIR/ca/ca.crt\rSERVER_SSL_ENABLED: \u0026quot;true\u0026quot;\rSERVER_SSL_KEY: $CERTS_DIR/kib01/kib01.key\rSERVER_SSL_CERTIFICATE: $CERTS_DIR/kib01/kib01.crt\rSERVER_SSL_CERTIFICATEAUTHORITIES: $CERTS_DIR/ca/ca.crt\rXPACK_SECURITY_ENCRYPTIONKEY: \u0026quot;fhjskloppd678ehkdfdlliverpoolfcr\u0026quot;\rXPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: \u0026quot;fhjskloppd678ehkdfdlliverpoolfcr\u0026quot;\rXPACK_FLEET_AGENTS_ELASTICSEARCH_HOST: \u0026quot;https://es01:9200\u0026quot;\rXPACK_FLEET_REGISTRYURL: \u0026quot;https://package-registry\u0026quot;\rNODE_EXTRA_CA_CERTS: $CERTS_DIR/ca/ca.crt\rhealthcheck:\rtest: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost/api/status | grep -q 'Looking good' \u0026gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi\rretries: 100\rinterval: 5s\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rdata01:\rdriver: local\rdata02:\rdriver: local\rdata03:\rdriver: local\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge\r1- Générez et appliquez une licence d\u0026rsquo;essai qui prend en charge Transport Layer Security.\n2- Activez Transport Layer Security pour crypter les communications des clients.\n3- Activez Transport Layer Security pour crypter les communications internodales.\n4- Autorisez l\u0026rsquo;utilisation de certificats auto-signés en ne demandant pas de vérification du nom d\u0026rsquo;hôte.\nGénérez des certificats pour Elasticsearch en faisant apparaître le conteneur create-certs :\ndocker-compose -f create-certs.yml run --rm create_certs\rVérifiez a présence des volumes\ndocker volume ls\rDRIVER VOLUME NAME\rlocal es_certs\rVérifiez la présence des certificats\nsudo ls -R /var/lib/docker/volumes/es_certs/_data/\r/var/lib/docker/volumes/es_certs/_data/:\rbundle.zip ca\tes01 es02 es03 fleet-server\tkib01 package-registry\r/var/lib/docker/volumes/es_certs/_data/ca:\rca.crt\r/var/lib/docker/volumes/es_certs/_data/es01:\res01.crt es01.key\r/var/lib/docker/volumes/es_certs/_data/es02:\res02.crt es02.key\r/var/lib/docker/volumes/es_certs/_data/es03:\res03.crt es03.key\r/var/lib/docker/volumes/es_certs/_data/fleet-server:\rfleet-server.crt fleet-server.key\r/var/lib/docker/volumes/es_certs/_data/kib01:\rkib01.crt kib01.key\r/var/lib/docker/volumes/es_certs/_data/package-registry:\rpackage-registry.crt package-registry.key\rMettez en place le cluster Elasticsearch à trois nœuds :\ndocker-compose -f elastic-docker-tls.yml up -d\rÀ ce stade, Kibana ne peut pas se connecter au cluster Elasticsearch. Vous devez générer un mot de passe pour l\u0026rsquo;utilisateur intégré kibana_system, mettre à jour le mot de passe ELASTICSEARCH_PASSWORD dans le fichier compose, et redémarrer pour permettre à Kibana de communiquer avec le cluster sécurisé.\nExécutez l\u0026rsquo;outil elasticsearch-setup-passwords pour générer des mots de passe pour tous les utilisateurs intégrés, y compris l\u0026rsquo;utilisateur kibana_system. Si vous n\u0026rsquo;utilisez pas PowerShell sous Windows, supprimez les caractères \\de fin de ligne et joignez les lignes avant d\u0026rsquo;exécuter cette commande.\ndocker exec es01 /bin/bash -c \u0026quot;bin/elasticsearch-setup-passwords \\\rauto --batch --url https://es01:9200\u0026quot;\rSi la commande tombe en erreur, veuillez relancer la commande quand le noeud Elasticsearch est pret.\nChanged password for user apm_system\rPASSWORD apm_system = cFupG97Ha1vh8Ntdmi8V\rChanged password for user kibana_system\rPASSWORD kibana_system = im0I9MGIDXHSy5gpUgmm\rChanged password for user kibana\rPASSWORD kibana = im0I9MGIDXHSy5gpUgmm\rChanged password for user logstash_system\rPASSWORD logstash_system = 3ZunAd3WpUcp1tKnb3Rq\rChanged password for user beats_system\rPASSWORD beats_system = yn88diKHJhU5wF7h9Rh9\rChanged password for user remote_monitoring_user\rPASSWORD remote_monitoring_user = wfliiMix1pep0Gnm6Ah8\rChanged password for user elastic\rPASSWORD elastic = fLzlyoIb8RsCT639v7HH\rPrenez note des mots de passe générés. Vous devez configurer le mot de passe de l\u0026rsquo;utilisateur kibana_system dans le fichier compose pour permettre à Kibana de se connecter à Elasticsearch, et vous aurez besoin du mot de passe du superutilisateur elastic pour vous connecter à Kibana et soumettre des requêtes à Elasticsearch.\nDéfinissez les variables d\u0026rsquo;authentification dans le fichier .env.\nCOMPOSE_PROJECT_NAME=es\rCERTS_DIR=/usr/share/elasticsearch/config/certificates\rVERSION=7.17.0\r### Credentials\rUSER_APM_SYSTEM=apm_system\rPASSWORD_APM_SYSTEM=tE7F2LePRNPgUC4SN0nT\rUSER_KIBANA_SYSTEM=kibana_system\rPASSWORD_KIBANA_SYSTEM=zJE8y8KlV79dv6OCmfpF\rUSER_KIBANA=kibana\rPASSWORD_KIBANA=zJE8y8KlV79dv6OCmfpF\rUSER_BEATS_SYSTEM=beats_system\rPASSWORD_BEATS_SYSTEM=ITklPCO1oTCWQIMdpWFT\rUSER_ELASTIC=elastic\rPASSWORD_ELASTIC=ASf3lYu7xoKMeesYuMPc\rUtilisez docker-compose pour redémarrer le cluster et Kibana :\ndocker-compose stop\rdocker-compose -f elastic-docker-tls.yml up -d\rOuvrez Kibana pour charger les données de l\u0026rsquo;échantillon et interagir avec le cluster : Kibana\nComme SSL est également activé pour les communications entre Kibana et les navigateurs clients, vous devez accéder à Kibana via le protocole HTTPS.\nOuvrez le menu de droit et cliquez sur \u0026ldquo;Stack Monitorng\u0026rdquo;\nCliquez sur l\u0026rsquo;option \u0026ldquo;Or, set up with self monitoring\u0026rdquo;\nDéloyer une application blanche mkdir -P app/conf\rvim app/petclinic.yml\rpetclinic.yml\nversion: '2.2'\rservices:\rnginx:\rimage: nginx:1.17.3\rcontainer_name: nginx\rlabels:\r\u0026quot;co.elastic.logs/module\u0026quot;: \u0026quot;nginx\u0026quot;\r\u0026quot;co.elastic.logs/fileset.stdout\u0026quot;: \u0026quot;access\u0026quot;\r\u0026quot;co.elastic.logs/fileset.stderr\u0026quot;: \u0026quot;error\u0026quot;\r\u0026quot;co.elastic.metrics/module\u0026quot;: \u0026quot;nginx\u0026quot;\r\u0026quot;co.elastic.metrics/hosts\u0026quot;: \u0026quot;nginx:80\u0026quot;\r\u0026quot;co.elastic.metrics/metricsets\u0026quot;: \u0026quot;stubstatus\u0026quot;\rports:\r- 80:80\rvolumes:\r- ./conf/default.conf:/etc/nginx/conf.d/default.conf:ro\rnetworks:\r- elastic\rpetclinic:\rimage: docker.io/michaelhyatt/elastic-k8s-o11y-workshop-petclinic:1.25.0\rcontainer_name: petclinic\rlabels:\r\u0026quot;co.elastic.metrics/module\u0026quot;: \u0026quot;prometheus\u0026quot;\r\u0026quot;co.elastic.metrics/hosts\u0026quot;: \u0026quot;$${data.host}:$${data.port}\u0026quot;\r\u0026quot;co.elastic.metrics/metrics_path\u0026quot;: \u0026quot;/metrics/prometheus\u0026quot;\r\u0026quot;co.elastic.metrics/period\u0026quot;: \u0026quot;1m\u0026quot;\renvironment:\rELASTIC_APM_SERVER_URLS: \u0026quot;http://apm-server:8200\u0026quot;\rELASTIC_APM_SERVER_URLS_FOR_RUM: \u0026quot;http://localhost:8200\u0026quot;\rELASTIC_APM_SECRET_TOKEN: \u0026quot;\u0026quot;\rELASTIC_APM_SERVICE_NAME: \u0026quot;spring-petclinic-monolith\u0026quot;\rELASTIC_APM_APPLICATION_PACKAGES: \u0026quot;org.springframework.samples\u0026quot;\rELASTIC_APM_ENABLE_LOG_CORRELATION: \u0026quot;true\u0026quot;\rELASTIC_APM_CAPTURE_JMX_METRICS: \u0026gt;\robject_name[java.lang:type=GarbageCollector,name=*] attribute[CollectionCount:metric_name=collection_count] attribute[CollectionTime:metric_name=collection_time],\robject_name[java.lang:type=Memory] attribute[HeapMemoryUsage:metric_name=heap]\rJAVA_OPTS: \u0026gt;\r-Xms100m\r-Xmx256m\r-Dspring.profiles.active=mysql\r-Ddatabase=mysql\r-Dspring.datasource.username=root\r-Dspring.datasource.password=petclinic\r-Dspring.datasource.initialization-mode=always\r-Dspring.datasource.url=jdbc:mysql://mysql:3306/petclinic?autoReconnect=true\u0026amp;useSSL=false\r-XX:+StartAttachListener\rports:\r- 8080:8080\rnetworks:\r- elastic\rmysql:\rimage: mysql:5.7.27\rcontainer_name: mysql\rlabels:\r\u0026quot;co.elastic.logs/module\u0026quot;: \u0026quot;mysql\u0026quot;\r\u0026quot;co.elastic.metrics/module\u0026quot;: \u0026quot;mysql\u0026quot;\r\u0026quot;co.elastic.metrics/hosts\u0026quot;: \u0026quot;root:petclinic@tcp($${data.host}:3306)/\u0026quot;\renvironment:\rMYSQL_ROOT_PASSWORD: petclinic\rMYSQL_DATABASE: petclinic\rports:\r- 3306\rnetworks:\r- elastic\rnetworks:\relastic:\rdriver: bridge\rvim app/conf/default.conf\rdefault.conf\nserver {\rlisten 80;\rserver_name localhost;\rlocation /intake {\rif ($request_method = 'OPTIONS') {\r# This is a bit too wide, would be enough to replace it with only APM server url for CORS support.\radd_header 'Access-Control-Allow-Origin' '*';\radd_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';\radd_header 'Access-Control-Allow-Headers' 'Accept:,Accept-Encoding,Accept-Language:,Cache-Control,Connection,DNT,Pragma,Host,Referer,Upgrade-Insecure-Requests,User-Agent,elastic-apm-traceparent';\radd_header 'Access-Control-Max-Age' 1728000;\radd_header 'Access-Control-Allow-Credentials' 'true';\radd_header 'Content-Type' 'text/plain; charset=utf-8';\radd_header 'Content-Length' 0;\rreturn 200;\r}\r}\rlocation / {\rproxy_pass http://petclinic:8080/;\r}\rlocation /server-status {\rstub_status;\rallow all; # A bit too wide\r# deny all;\r}\rerror_page 500 502 503 504 /50x.html;\rlocation = /50x.html {\rroot /usr/share/nginx/html;\r}\r}\rdocker-compose -f app/petclinic.yml up -d\rAccédez à la application blanche en cliquant ici\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_logs/","title":"Lab - Logs","tags":[],"description":"","content":"Objectif : Dans ce laboratoire, vous explorerez la facilité avec laquelle vous pouvez lire les fichiers journaux NGINX avec Filebeat et les indexer dans Elasticsearch. Vous explorerez également les tableaux de bord Kibana et verrez avec quelle facilité vous pouvez surveiller les journaux NGINX.\nDéployer un agent beats mkdir -P beats/conf\rvim beats/beats-docker.yml\rbeats-docker.yml\nversion: '2.2'\rservices:\rfilebeat:\rimage: docker.elastic.co/beats/filebeat:${VERSION}\rcontainer_name: filebeat\rrestart: unless-stopped\rentrypoint: \u0026quot;filebeat -e -strict.perms=false\u0026quot;\ruser: root\rvolumes:\r- \u0026quot;./conf/filebeat.yml:/usr/share/filebeat/filebeat.yml:rw\u0026quot;\r- \u0026quot;/var/lib/docker/containers:/var/lib/docker/containers:ro\u0026quot;\r- \u0026quot;/var/run/docker.sock:/var/run/docker.sock:ro\u0026quot;\r- \u0026quot;/var/log:/tmp:ro\u0026quot;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge\rvim beats/conf/filebeat.yml\r######################## Filebeat Configuration ############################\r# This file is a full configuration example documenting all non-deprecated\r# options in comments. For a shorter configuration example, that contains only\r# the most common options, please see filebeat.yml in the same directory.\r#\r# You can find the full configuration reference here:\r# https://www.elastic.co/guide/en/beats/filebeat/index.html\r#========================== Modules configuration ============================\rfilebeat.modules:\r#------------------------------- System Module -------------------------------\r- module: system\r# Syslog\rsyslog:\renabled: true\r# Set custom paths for the log files. If left empty,\r# Filebeat will choose the paths depending on your OS.\r#var.paths:\r# Convert the timestamp to UTC. Requires Elasticsearch \u0026gt;= 6.1.\r#var.convert_timezone: false\r# Input configuration (advanced). Any input configuration option\r# can be added under this section.\r#input:\r# Authorization logs\rauth:\renabled: true\r# Set custom paths for the log files. If left empty,\r# Filebeat will choose the paths depending on your OS.\r#var.paths:\r# Convert the timestamp to UTC. Requires Elasticsearch \u0026gt;= 6.1.\r#var.convert_timezone: false\r# Input configuration (advanced). Any input configuration option\r# can be added under this section.\r#input:\r#=========================== Filebeat inputs =============================\r# List of inputs to fetch data.\rfilebeat.inputs:\r# Each - is an input. Most options can be set at the input level, so\r# you can use different inputs for various configurations.\r# Below are the input specific configurations.\r# Type of the files. Based on this the way the file is read is decided.\r# The different types cannot be mixed in one input\r#\r# Possible options are:\r# * log: Reads every line of the log file (default)\r# * stdin: Reads the standard in\r#------------------------------ Log input --------------------------------\r- type: log\r# Change to true to enable this input configuration.\renabled: true\r# Paths that should be crawled and fetched. Glob based paths.\r# To fetch all \u0026quot;.log\u0026quot; files from a specific level of subdirectories\r# /var/log/*/*.log can be used.\r# For each file found under this path, a harvester is started.\r# Make sure not file is defined twice as this can lead to unexpected behaviour.\rpaths:\r- \u0026quot;/var/lib/docker/containers/*/*-json.log\u0026quot;\r- '/tmp/*.log'\r#========================== Filebeat autodiscover ==============================\r# Autodiscover allows you to detect changes in the system and spawn new modules\r# or inputs as they happen.\rfilebeat.autodiscover:\r# List of enabled autodiscover providers\rproviders:\r- type: docker\rhints.enabled: true\r#================================ Processors ===================================\r#\r# The following example enriches each event with docker metadata, it matches\r# given fields to an existing container id and adds info from that container:\r#\rprocessors:\r- add_docker_metadata: ~\r- add_locale:\rformat: offset\r- add_host_metadata:\rnetinfo.enabled: true\r# host: \u0026quot;unix:///var/run/docker.sock\u0026quot;\r# match_fields: [\u0026quot;system.process.cgroup.id\u0026quot;]\r# match_pids: [\u0026quot;process.pid\u0026quot;, \u0026quot;process.ppid\u0026quot;]\r# match_source: true\r# match_source_index: 4\r# match_short_id: false\r# cleanup_timeout: 60\r# # To connect to Docker over TLS you must specify a client and CA certificate.\r# #ssl:\r# # certificate_authority: \u0026quot;/etc/pki/root/ca.pem\u0026quot;\r# # certificate: \u0026quot;/etc/pki/client/cert.pem\u0026quot;\r# # key: \u0026quot;/etc/pki/client/cert.key\u0026quot;\r#\r# The following example enriches each event with docker metadata, it matches\r# container id from log path available in `source` field (by default it expects\r# it to be /var/lib/docker/containers/*/*.log).\r#\r#processors:\r#- add_docker_metadata: ~\r#- add_host_metadata: ~\r#================================ Outputs ======================================\r# Configure what output to use when sending the data collected by the beat.\r#-------------------------- Elasticsearch output -------------------------------\routput.elasticsearch:\r# Boolean flag to enable or disable the output module.\renabled: true\r# Array of hosts to connect to.\r# Scheme and port can be left out and will be set to the default (http and 9200)\r# In case you specify and additional path, the scheme is required: http://localhost:9200/path\r# IPv6 addresses should always be defined as: https://[2001:db8::1]:9200\rhosts: [\u0026quot;es01:9200\u0026quot;]\r# Set gzip compression level.\r#compression_level: 0\r# Optional protocol and basic auth credentials.\rprotocol: \u0026quot;https\u0026quot;\rusername: \u0026quot;beats_system\u0026quot;\rpassword: \u0026quot;ITklPCO1oTCWQIMdpWFT\u0026quot;\r# Use SSL settings for HTTPS.\rssl.enabled: true\r# SSL configuration. By default is off.\r# List of root certificates for HTTPS server verifications\rssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\r#============================== Dashboards =====================================\r# These settings control loading the sample dashboards to the Kibana index. Loading\r# the dashboards are disabled by default and can be enabled either by setting the\r# options here, or by using the `-setup` CLI flag or the `setup` command.\rsetup.dashboards.enabled: true\r#============================== Template =====================================\r# A template is used to set the mapping in Elasticsearch\r# By default template loading is enabled and the template is loaded.\r# These settings can be adjusted to load your own template or overwrite existing ones.\r# Set to false to disable template loading.\r#setup.template.enabled: true\r# Template name. By default the template name is \u0026quot;filebeat-%{[beat.version]}\u0026quot;\r# The template name and pattern has to be set in case the elasticsearch index pattern is modified.\rsetup.template.name: \u0026quot;logs-%{[beat.version]}\u0026quot;\r# Template pattern. By default the template pattern is \u0026quot;-%{[beat.version]}-*\u0026quot; to apply to the default index settings.\r# The first part is the version of the beat and then -* is used to match all daily indices.\r# The template name and pattern has to be set in case the elasticsearch index pattern is modified.\rsetup.template.pattern: \u0026quot;logs-%{[beat.version]}-*\u0026quot;\r# Path to fields.yml file to generate the template\r#setup.template.fields: \u0026quot;${path.config}/fields.yml\u0026quot;\r# Overwrite existing template\r#setup.template.overwrite: false\r# Elasticsearch template settings\rsetup.template.settings:\r# A dictionary of settings to place into the settings.index dictionary\r# of the Elasticsearch template. For more details, please check\r# https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html\r#index:\rnumber_of_shards: 1\r#codec: best_compression\r#number_of_routing_shards: 30\r# A dictionary of settings for the _source field. For more details, please check\r# https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html\r#_source:\r#enabled: false\r#============================== Kibana =====================================\r# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.\r# This requires a Kibana endpoint configuration.\rsetup.kibana:\r# Kibana Host\r# Scheme and port can be left out and will be set to the default (http and 5601)\r# In case you specify and additional path, the scheme is required: http://localhost:5601/path\r# IPv6 addresses should always be defined as: https://[2001:db8::1]:5601\rhost: \u0026quot;kib01:5601\u0026quot;\r# Optional protocol and basic auth credentials.\rprotocol: \u0026quot;https\u0026quot;\rusername: \u0026quot;elastic\u0026quot;\rpassword: \u0026quot;ASf3lYu7xoKMeesYuMPc\u0026quot;\r# Use SSL settings for HTTPS. Default is true.\rssl.enabled: true\rssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\r#================================ Logging ======================================\r# There are four options for the log output: file, stderr, syslog, eventlog\r# The file output is the default.\r# Sets log level. The default log level is info.\r# Available log levels are: error, warning, info, debug\rlogging.level: info\r# Send all logging output to syslog. The default is false.\rlogging.to_syslog: true\r# Send all logging output to Windows Event Logs. The default is false.\rlogging.to_eventlog: true\r# If enabled, filebeat periodically logs its internal metrics that have changed\r# in the last period. For each metric that changed, the delta from the value at\r# the beginning of the period is logged. Also, the total values for\r# all non-zero internal metrics are logged on shutdown. The default is true.\rlogging.metrics.enabled: true\r# The period after which to log the internal metrics. The default is 30s.\rlogging.metrics.period: 30s\r# Logging to rotating files. Set logging.to_files to false to disable logging to\r# files.\rlogging.to_files: true\rlogging.files:\r# Configure the path where the logs are written. The default is the logs directory\r# under the home path (the binary location).\rpath: /var/log/filebeat\r# The name of the files where the logs are written to.\rname: filebeat\rdocker-compose -f beats/beats-docker.yml up -d\rvim app/artificial_load.sh\r#!/bin/bash\rCOUNTER=0\rwhile [ $COUNTER -lt 10000 ] ;\rdo\rcurl -s --header \u0026quot;X-Forwarded-For: 5.198.223.255\u0026quot; localhost \u0026gt; /dev/null\rcurl -s localhost/owners/find \u0026gt; /dev/null\rcurl -s localhost/owners?lastName= \u0026gt; /dev/null\rcurl -s localhost/owners/1 \u0026gt; /dev/null\rcurl -s localhost/owners/4 \u0026gt; /dev/null\rcurl -s localhost/owners/6 \u0026gt; /dev/null\rcurl -s localhost/owners/8 \u0026gt; /dev/null\rcurl -s localhost/vets.html \u0026gt; /dev/null\rcurl -s localhost/oups \u0026gt; /dev/null\rlet COUNTER=COUNTER+1\rdone\rchmod +x app/artificial_load.sh\rMaintenant, ouvrez une nouvelle fenêtre de terminal et exécutez le script suivant pour simuler la charge sur votre serveur NGINX.\n./app/artificial_load.sh\rLancer Kibana pour commencer à explorer les tableaux de bord qui ont été inclus dans le processus de configuration.\nAccédez à Dashboard via le menu principal\nRecherchez nginx et ouvrez le tableau de bord ECS Filebeat Nginx Overview.\nVous verrez quelque chose de similaire à la page ci-dessous.\nFaites défiler vers le bas et vérifiez quel est le navigateur le plus utilisé. Vous remarquerez que ce devrait être curl car il est utilisé par le script de simulation de charge.\nMaintenant, cliquez sur Nginx access and error logs en haut du tableau de bord actuel pour voir le tableau de bord avec les journaux d\u0026rsquo;accès et d\u0026rsquo;erreurs que Filebeat a collecté de NGINX.\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez lire les fichiers journaux NGINX avec Filebeat et les indexer dans Elasticsearch. Vous avez également exploré les tableaux de bord Kibana et vu comment vous pouvez facilement surveiller les journaux NGINX.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_metrics/","title":"Lab - Metrics","tags":[],"description":"","content":"Objectif : Dans ce laboratoire, vous explorerez la facilité avec laquelle vous pouvez obtenir des métriques système et NGINX avec Metricbeat et les indexer dans Elasticsearch. Vous explorerez également les tableaux de bord Kibana et verrez avec quelle facilité vous pouvez surveiller ces métriques.\nDéployer un agent beats Ajoutez le service Metricbeat à la suite du service FIlebeat\nvim beats/beats-docker.yml\rbeats-docker.yml\nversion: '2.2'\rservices:\rfilebeat:\rimage: docker.elastic.co/beats/filebeat:${VERSION}\rcontainer_name: filebeat\rrestart: unless-stopped\rentrypoint: \u0026quot;filebeat -e -strict.perms=false\u0026quot;\ruser: root\rvolumes:\r- \u0026quot;./conf/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\u0026quot;\r- \u0026quot;/var/lib/docker/containers:/var/lib/docker/containers:ro\u0026quot;\r- \u0026quot;/var/run/docker.sock:/var/run/docker.sock:ro\u0026quot;\r- \u0026quot;/var/log:/tmp:ro\u0026quot;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rmetricbeat:\rimage: docker.elastic.co/beats/metricbeat:${VERSION}\rcontainer_name: metricbeat\rrestart: unless-stopped\rentrypoint: \u0026quot;metricbeat -e -strict.perms=false\u0026quot;\ruser: root\rvolumes:\r- \u0026quot;./conf/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro\u0026quot;\r- \u0026quot;/proc:/hostfs/proc:ro\u0026quot;\r- \u0026quot;/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\u0026quot;\r- \u0026quot;/:/hostfs:ro\u0026quot;\r- \u0026quot;/var/run/docker.sock:/var/run/docker.sock:ro\u0026quot;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge\rvim beats/conf/metricbeat.yml\r#-------------------------------- Autodiscovery -------------------------------\r# Autodiscover allows you to detect changes in the system and spawn new modules as they happen.\rmetricbeat.autodiscover:\rproviders:\r- type: docker\r# https://www.elastic.co/guide/en/beats/metricbeat/current/configuration-autodiscover-hints.html\rhints.enabled: true\rmetricbeat.modules:\r#------------------------------- System Module -------------------------------\r- module: system\rmetricsets: [\u0026quot;cpu\u0026quot;, \u0026quot;load\u0026quot;, \u0026quot;memory\u0026quot;, \u0026quot;network\u0026quot;, \u0026quot;process\u0026quot;, \u0026quot;process_summary\u0026quot;, \u0026quot;core\u0026quot;, \u0026quot;diskio\u0026quot;, \u0026quot;socket\u0026quot;]\rprocesses: ['.*']\rprocess.include_top_n:\rby_cpu: 5\rby_memory: 5\rperiod: 10s\rcpu.metrics: [\u0026quot;percentages\u0026quot;]\rcore.metrics: [\u0026quot;percentages\u0026quot;]\r- module: system\rperiod: 1m\rmetricsets:\r- filesystem\r- fsstat\rprocessors:\r- drop_event.when.regexp:\rsystem.filesystem.mount_point: '^/(sys|cgroup|proc|dev|etc|host|lib)($|/)'\r- module: system\rperiod: 15m\rmetricsets:\r- uptime\r#------------------------------- Docker Module -------------------------------\r- module: docker\rmetricsets: [\u0026quot;container\u0026quot;, \u0026quot;cpu\u0026quot;, \u0026quot;diskio\u0026quot;, \u0026quot;healthcheck\u0026quot;, \u0026quot;info\u0026quot;, \u0026quot;memory\u0026quot;, \u0026quot;network\u0026quot;]\rhosts: [\u0026quot;unix:///var/run/docker.sock\u0026quot;]\rperiod: 10s\r#================================ Processors ===================================\rprocessors:\r- add_docker_metadata: ~\r- add_locale:\rformat: offset\r- add_host_metadata:\rnetinfo.enabled: true\r#========================== Elasticsearch output ===============================\routput.elasticsearch:\rhosts: [\u0026quot;https://es01:9200\u0026quot;]\rusername: \u0026quot;beats_system\u0026quot;\rpassword: \u0026quot;ITklPCO1oTCWQIMdpWFT\u0026quot;\rssl.enabled: true\rssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\r#============================== Dashboards =====================================\rsetup.dashboards:\renabled: true\r#============================== Kibana =========================================\rsetup.kibana:\rhost: \u0026quot;https://kib01:5601\u0026quot;\rusername: \u0026quot;elastic\u0026quot;\rpassword: \u0026quot;ASf3lYu7xoKMeesYuMPc\u0026quot;\rssl.enabled: true\rssl.certificate_authorities: [\u0026quot;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026quot;]\rdocker-compose -f beats/beats-docker.yml up -d\rvim app/artificial_load.sh\r#!/bin/bash\rCOUNTER=0\rwhile [ $COUNTER -lt 10000 ] ;\rdo\rcurl -s --header \u0026quot;X-Forwarded-For: 5.198.223.255\u0026quot; localhost \u0026gt; /dev/null\rcurl -s localhost/owners/find \u0026gt; /dev/null\rcurl -s localhost/owners?lastName= \u0026gt; /dev/null\rcurl -s localhost/owners/1 \u0026gt; /dev/null\rcurl -s localhost/owners/4 \u0026gt; /dev/null\rcurl -s localhost/owners/6 \u0026gt; /dev/null\rcurl -s localhost/owners/8 \u0026gt; /dev/null\rcurl -s localhost/vets.html \u0026gt; /dev/null\rcurl -s localhost/oups \u0026gt; /dev/null\rlet COUNTER=COUNTER+1\rdone\rchmod +x app/artificial_load.sh\rMaintenant, ouvrez une nouvelle fenêtre de terminal et exécutez le script suivant pour simuler la charge sur votre serveur NGINX.\n./app/artificial_load.sh\rLancez Kibana pour commencer à explorer les tableaux de bord qui ont été inclus dans le processus de configuration.\nEnsuite, accédez à Dashboard via le menu principal.\nRecherchez le système et ouvrez la vue d\u0026rsquo;ensemble de Metricbeat System ECS.\nVous verrez quelque chose de similaire à la page ci-dessous.\nCliquez sur Vue d\u0026rsquo;ensemble de l\u0026rsquo;hôte en haut du tableau de bord actuel pour voir un tableau de bord avec plus d\u0026rsquo;informations que Metricbeat a collectées à partir de l\u0026rsquo;hôte de votre environnement de laboratoire.\nRetournez sur la page des tableaux de bord Kibana, recherchez nginx et ouvrez le tableau de bord ECS [Metricbeat Nginx] Overview.\nVous verrez quelque chose de similaire à la page ci-dessous.\nRetournez dans les tableaux de bord Kibana et cliquez sur Créer un nouveau tableau de bord pour comparer les données NGINX collectées à partir de Filebeat et Metricbeat.\nCliquez sur Ajouter depuis la bibliothèque pour commencer à ajouter des visualisations à votre tableau de bord.\nUtilisez la barre de requête pour filtrer par visualisations filebeat nginx et ajoutez les visualisations Filebeat suivantes : Journaux d\u0026rsquo;accès dans le temps et Codes de réponse dans le temps.\nMaintenant, filtrez par visualisations metricbeat nginx pour ajouter les visualisations Metricbeat suivantes : Taux de requêtes et Taux de lecture/écriture/attente.\nFermez la boîte de dialogue Ajouter à partir de la bibliothèque et enregistrez votre tableau de bord sous le nom de Filebeat x Metricbeat.\nVérifiez les différentes informations que vous pouvez obtenir à partir des journaux et des métriques de NGINX dans le tableau de bord que vous venez de créer.\nNotez que vous pouvez utiliser les données de Filebeat et de Metricbeat pour vérifier le nombre de requêtes par seconde, comme le montrent les visualisations Access logs over time et Request Rate. La version open source de NGINX ne fournit pas de métriques sur les codes de réponse, mais vous pouvez utiliser Filebeat pour obtenir ces informations à partir des journaux NGINX, comme vous pouvez le voir dans la visualisation des codes de réponse dans le temps. Avec les journaux NGINX, vous pouvez également vérifier l\u0026rsquo;emplacement, le système d\u0026rsquo;exploitation, le navigateur, la durée et de nombreuses autres informations sur les demandes. Cependant, les journaux NGINX ne vous disent pas combien de connexions ont été acceptées, traitées et abandonnées. Dans ce cas, vous pouvez utiliser Metricbeat pour collecter ces informations ainsi que le nombre de connexions actives et le nombre de connexions en lecture, écriture et attente, comme vous pouvez le voir dans la visualisation du taux de lecture / écriture / attente.\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez obtenir des mesures du système et de NGINX avec Metricbeat et les indexer dans Elasticsearch. Vous avez également exploré les tableaux de bord Kibana et vu avec quelle facilité vous pouvez surveiller ces mesures.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/","title":"Débutant","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/","title":"Elementaire","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/","title":"Intermediare","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/avance/","title":"Avancé","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/","title":"Elastic Tutoriel","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/","title":"Elastic","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/tags/","title":"Tags","tags":[],"description":"","content":""}]