[{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/prerequis/","title":"Prérequis","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/prerequis/installation/","title":"Installation","tags":[],"description":"","content":"Prérequis  Ubuntu ou Debian Docker Exécuter la commande ci-dessous  sudo sysctl -w vm.max_map_count=262144 Déployer la stack Elasticsearch Kibana dans Docker avec TLS activé Si les fonctions de sécurité sont activées, vous devez configurer le chiffrement TLS (Transport Layer Security) pour la couche de transport d\u0026rsquo;Elasticsearch. Bien qu\u0026rsquo;il soit possible d\u0026rsquo;utiliser une licence d\u0026rsquo;essai sans configurer TLS, nous vous conseillons de sécuriser votre pile dès le départ.\nPour obtenir un cluster Elasticsearch et Kibana opérationnel dans Docker avec la sécurité activée, vous pouvez utiliser Docker Compose :\nCréez les fichiers de composition et de configuration suivants. Ces fichiers sont également disponibles dans le dépôt elastic/stack-docs sur GitHub.\ninstances.yml identifie les instances pour lesquelles vous devez créer des certificats. .env définit des variables d\u0026rsquo;environnement pour spécifier la version d\u0026rsquo;Elasticsearch et l\u0026rsquo;emplacement où les certificats Elasticsearch seront créés. create-certs.yml est un fichier Docker Compose qui lance un conteneur pour générer les certificats pour Elasticsearch et Kibana. elastic-docker-tls.yml est un fichier Docker Compose qui met en place un cluster Elasticsearch à trois nœuds et une instance Kibana avec TLS activé afin que vous puissiez voir comment les choses fonctionnent. Cette configuration tout-en-un est un moyen pratique de mettre en place votre premier cluster de développement avant de construire un déploiement distribué avec plusieurs hôtes.\ninstances.yml :\ninstances:\r- name: es01\rdns:\r- es01\r- localhost\rip:\r- 127.0.0.1\r- name: es02\rdns:\r- es02\r- localhost\rip:\r- 127.0.0.1\r- name: es03\rdns:\r- es03\r- localhost\rip:\r- 127.0.0.1\r- name: \u0026#39;kib01\u0026#39;\rdns:\r- kib01\r- localhost\r- name: \u0026#39;package-registry\u0026#39;\rdns:\r- package-registry\r- localhost\r- name: \u0026#39;fleet-server\u0026#39;\rdns:\r- fleet-server\r- localhost .env:\nCOMPOSE_PROJECT_NAME=es\rCERTS_DIR=/usr/share/elasticsearch/config/certificates\rVERSION=7.17.0 create-certs.yml:\nversion: \u0026#39;2.2\u0026#39;\rservices:\rcreate_certs:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: create_certs\rcommand: \u0026gt;\rbash -c \u0026#39;\ryum install -y -q -e 0 unzip;\rif [[ ! -f /certs/bundle.zip ]]; then\rbin/elasticsearch-certutil cert --silent --pem --in config/certificates/instances.yml -out /certs/bundle.zip;\runzip /certs/bundle.zip -d /certs;\rfi;\rchown -R 1000:0 /certs\r\u0026#39;\rworking_dir: /usr/share/elasticsearch\rvolumes:\r- certs:/certs\r- .:/usr/share/elasticsearch/config/certificates\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge elastic-docker-tls.yml:\nversion: \u0026#39;2.2\u0026#39;\rservices:\res01:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: es01\renvironment:\r- path.repo=/usr/share/elasticsearch/snapshots/\r- node.name=es01\r- cluster.name=es-docker-cluster\r- discovery.seed_hosts=es02,es03\r- cluster.initial_master_nodes=es01,es02,es03\r- bootstrap.memory_lock=true\r- \u0026#34;ES_JAVA_OPTS=-Xms256m -Xmx256m\u0026#34;\r- xpack.license.self_generated.type=basic\r- xpack.security.enabled=true\r- xpack.security.http.ssl.enabled=true\r- xpack.security.http.ssl.key=$CERTS_DIR/es01/es01.key\r- xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.http.ssl.certificate=$CERTS_DIR/es01/es01.crt\r- xpack.security.transport.ssl.enabled=true\r- xpack.security.transport.ssl.verification_mode=certificate\r- xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.transport.ssl.certificate=$CERTS_DIR/es01/es01.crt\r- xpack.security.transport.ssl.key=$CERTS_DIR/es01/es01.key\r- xpack.security.authc.api_key.enabled=true\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- data01:/usr/share/elasticsearch/data\r- certs:$CERTS_DIR\rports:\r- 9200:9200\rnetworks:\r- elastic\rhealthcheck:\rtest: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost:9200 \u0026gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi\rinterval: 30s\rtimeout: 10s\rretries: 5\res02:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: es02\renvironment:\r- node.name=es02\r- path.repo=/usr/share/elasticsearch/snapshots/\r- cluster.name=es-docker-cluster\r- discovery.seed_hosts=es01,es03\r- cluster.initial_master_nodes=es01,es02,es03\r- bootstrap.memory_lock=true\r- \u0026#34;ES_JAVA_OPTS=-Xms256m -Xmx256m\u0026#34;\r- xpack.license.self_generated.type=basic\r- xpack.security.enabled=true\r- xpack.security.http.ssl.enabled=true\r- xpack.security.http.ssl.key=$CERTS_DIR/es02/es02.key\r- xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.http.ssl.certificate=$CERTS_DIR/es02/es02.crt\r- xpack.security.transport.ssl.enabled=true\r- xpack.security.transport.ssl.verification_mode=certificate\r- xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.transport.ssl.certificate=$CERTS_DIR/es02/es02.crt\r- xpack.security.transport.ssl.key=$CERTS_DIR/es02/es02.key\r- xpack.security.authc.api_key.enabled=true\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- data02:/usr/share/elasticsearch/data\r- certs:$CERTS_DIR\rnetworks:\r- elastic\res03:\rimage: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}\rcontainer_name: es03\renvironment:\r- node.name=es03\r- path.repo=/usr/share/elasticsearch/snapshots/\r- cluster.name=es-docker-cluster\r- discovery.seed_hosts=es01,es02\r- cluster.initial_master_nodes=es01,es02,es03\r- bootstrap.memory_lock=true\r- \u0026#34;ES_JAVA_OPTS=-Xms256m -Xmx256m\u0026#34;\r- xpack.license.self_generated.type=basic\r- xpack.security.enabled=true\r- xpack.security.http.ssl.enabled=true\r- xpack.security.http.ssl.key=$CERTS_DIR/es03/es03.key\r- xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.http.ssl.certificate=$CERTS_DIR/es03/es03.crt\r- xpack.security.transport.ssl.enabled=true\r- xpack.security.transport.ssl.verification_mode=certificate\r- xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt\r- xpack.security.transport.ssl.certificate=$CERTS_DIR/es03/es03.crt\r- xpack.security.transport.ssl.key=$CERTS_DIR/es03/es03.key\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- data03:/usr/share/elasticsearch/data\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rkib01:\rimage: docker.elastic.co/kibana/kibana:${VERSION}\rcontainer_name: kib01\rdepends_on:\res01: { condition: service_healthy}\rports:\r- 5601:5601\renvironment:\rSERVERNAME: localhost\rELASTICSEARCH_URL: https://es01:9200\rELASTICSEARCH_HOSTS: https://es01:9200\rELASTICSEARCH_USERNAME: $USER_KIBANA_SYSTEM\rELASTICSEARCH_PASSWORD: $PASSWORD_KIBANA_SYSTEM\rELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES: $CERTS_DIR/ca/ca.crt\rSERVER_SSL_ENABLED: \u0026#34;true\u0026#34;\rSERVER_SSL_KEY: $CERTS_DIR/kib01/kib01.key\rSERVER_SSL_CERTIFICATE: $CERTS_DIR/kib01/kib01.crt\rSERVER_SSL_CERTIFICATEAUTHORITIES: $CERTS_DIR/ca/ca.crt\rXPACK_SECURITY_ENCRYPTIONKEY: \u0026#34;fhjskloppd678ehkdfdlliverpoolfcr\u0026#34;\rXPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: \u0026#34;fhjskloppd678ehkdfdlliverpoolfcr\u0026#34;\rhealthcheck:\rtest: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost/api/status | grep -q \u0026#39;Looking good\u0026#39; \u0026gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi\rretries: 100\rinterval: 5s\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rapm-server:\rimage: docker.elastic.co/apm/apm-server:${VERSION}\rcontainer_name: apm-server\rdepends_on:\res01: { condition: service_healthy }\rkib01: { condition: service_healthy }\rcap_add: [\u0026#34;CHOWN\u0026#34;, \u0026#34;DAC_OVERRIDE\u0026#34;, \u0026#34;SETGID\u0026#34;, \u0026#34;SETUID\u0026#34;]\rcap_drop: [\u0026#34;ALL\u0026#34;]\rports:\r- 8200:8200\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rcommand: \u0026gt;\rapm-server -e\r-E apm-server.rum.enabled=true\r-E setup.kibana.host=kib01:5601\r-E setup.template.settings.index.number_of_replicas=1\r-E apm-server.kibana.enabled=true\r-E apm-server.kibana.host=kib01:5601\r-E apm-server.kibana.protocol=https\r-E apm-server.kibana.username=$USER_ELASTIC\r-E apm-server.kibana.password=$PASSWORD_ELASTIC\r-E apm-server.kibana.ssl.enabled=true\r-E apm-server.kibana.ssl.certificate_authorities=[\u0026#34;$CERTS_DIR/ca/ca.crt\u0026#34;]\r-E output.elasticsearch.hosts=[\u0026#34;https://es01:9200\u0026#34;]\r-E output.elasticsearch.username=$USER_ELASTIC\r-E output.elasticsearch.password=$PASSWORD_ELASTIC\r-E output.elasticsearch.ssl.certificate_authorities=[\u0026#34;$CERTS_DIR/ca/ca.crt\u0026#34;]\rhealthcheck:\rinterval: 10s\rretries: 12\rtest: curl --write-out \u0026#39;HTTP %{http_code}\u0026#39; --fail --silent --output /dev/null http://localhost:8200/\rvolumes:\rdata01:\rdriver: local\rdata02:\rdriver: local\rdata03:\rdriver: local\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge 1- Générez et appliquez une licence d\u0026rsquo;essai qui prend en charge Transport Layer Security.\n2- Activez Transport Layer Security pour crypter les communications des clients.\n3- Activez Transport Layer Security pour crypter les communications internodales.\n4- Autorisez l\u0026rsquo;utilisation de certificats auto-signés en ne demandant pas de vérification du nom d\u0026rsquo;hôte.\nGénérez des certificats pour Elasticsearch en faisant apparaître le conteneur create-certs :\ndocker-compose -f create-certs.yml run --rm create_certs Vérifiez a présence des volumes\ndocker volume ls DRIVER VOLUME NAME\rlocal es_certs Vérifiez la présence des certificats\nsudo ls -R /var/lib/docker/volumes/es_certs/_data/ /var/lib/docker/volumes/es_certs/_data/:\rbundle.zip ca\tes01 es02 es03 fleet-server\tkib01 package-registry\r/var/lib/docker/volumes/es_certs/_data/ca:\rca.crt\r/var/lib/docker/volumes/es_certs/_data/es01:\res01.crt es01.key\r/var/lib/docker/volumes/es_certs/_data/es02:\res02.crt es02.key\r/var/lib/docker/volumes/es_certs/_data/es03:\res03.crt es03.key\r/var/lib/docker/volumes/es_certs/_data/fleet-server:\rfleet-server.crt fleet-server.key\r/var/lib/docker/volumes/es_certs/_data/kib01:\rkib01.crt kib01.key\r/var/lib/docker/volumes/es_certs/_data/package-registry:\rpackage-registry.crt package-registry.key Mettez en place le cluster Elasticsearch à trois nœuds :\ndocker-compose -f elastic-docker-tls.yml up -d À ce stade, Kibana ne peut pas se connecter au cluster Elasticsearch. Vous devez générer un mot de passe pour l\u0026rsquo;utilisateur intégré kibana_system, mettre à jour le mot de passe ELASTICSEARCH_PASSWORD dans le fichier compose, et redémarrer pour permettre à Kibana de communiquer avec le cluster sécurisé.\nExécutez l\u0026rsquo;outil elasticsearch-setup-passwords pour générer des mots de passe pour tous les utilisateurs intégrés, y compris l\u0026rsquo;utilisateur kibana_system. Si vous n\u0026rsquo;utilisez pas PowerShell sous Windows, supprimez les caractères \\de fin de ligne et joignez les lignes avant d\u0026rsquo;exécuter cette commande.\ndocker exec es01 /bin/bash -c \u0026#34;bin/elasticsearch-setup-passwords \\\rauto --batch --url https://es01:9200\u0026#34; Si la commande tombe en erreur, veuillez relancer la commande quand le noeud Elasticsearch est pret.\nChanged password for user apm_system\rPASSWORD apm_system = cFupG97Ha1vh8Ntdmi8V\rChanged password for user kibana_system\rPASSWORD kibana_system = im0I9MGIDXHSy5gpUgmm\rChanged password for user kibana\rPASSWORD kibana = im0I9MGIDXHSy5gpUgmm\rChanged password for user logstash_system\rPASSWORD logstash_system = 3ZunAd3WpUcp1tKnb3Rq\rChanged password for user beats_system\rPASSWORD beats_system = yn88diKHJhU5wF7h9Rh9\rChanged password for user remote_monitoring_user\rPASSWORD remote_monitoring_user = wfliiMix1pep0Gnm6Ah8\rChanged password for user elastic\rPASSWORD elastic = fLzlyoIb8RsCT639v7HH Prenez note des mots de passe générés. Vous devez configurer le mot de passe de l\u0026rsquo;utilisateur kibana_system dans le fichier compose pour permettre à Kibana de se connecter à Elasticsearch, et vous aurez besoin du mot de passe du superutilisateur elastic pour vous connecter à Kibana et soumettre des requêtes à Elasticsearch.\nDéfinissez les variables d\u0026rsquo;authentification dans le fichier .env.\nCOMPOSE_PROJECT_NAME=es\rCERTS_DIR=/usr/share/elasticsearch/config/certificates\rVERSION=7.17.0\r### Credentials\rUSER_APM_SYSTEM=apm_system\rPASSWORD_APM_SYSTEM=tE7F2LePRNPgUC4SN0nT\rUSER_KIBANA_SYSTEM=kibana_system\rPASSWORD_KIBANA_SYSTEM=zJE8y8KlV79dv6OCmfpF\rUSER_KIBANA=kibana\rPASSWORD_KIBANA=zJE8y8KlV79dv6OCmfpF\rUSER_BEATS_SYSTEM=beats_system\rPASSWORD_BEATS_SYSTEM=ITklPCO1oTCWQIMdpWFT\rUSER_ELASTIC=elastic\rPASSWORD_ELASTIC=ASf3lYu7xoKMeesYuMPc Utilisez docker-compose pour redémarrer le cluster et Kibana :\ndocker-compose -f elastic-docker-tls.yml stop\rdocker-compose -f elastic-docker-tls.yml up -d Ouvrez Kibana pour charger les données de l\u0026rsquo;échantillon et interagir avec le cluster : Kibana\nComme SSL est également activé pour les communications entre Kibana et les navigateurs clients, vous devez accéder à Kibana via le protocole HTTPS.\nOuvrez le menu de droit et cliquez sur \u0026ldquo;Stack Monitorng\u0026rdquo;\nCliquez sur l\u0026rsquo;option \u0026ldquo;Or, set up with self monitoring\u0026rdquo;\nDéloyer une application blanche mkdir -p app/conf\rvim app/petclinic.yml petclinic.yml\nversion: \u0026#39;2.2\u0026#39;\rservices:\rnginx:\rimage: nginx:1.17.3\rcontainer_name: nginx\rlabels:\r\u0026#34;co.elastic.logs/module\u0026#34;: \u0026#34;nginx\u0026#34;\r\u0026#34;co.elastic.logs/fileset.stdout\u0026#34;: \u0026#34;access\u0026#34;\r\u0026#34;co.elastic.logs/fileset.stderr\u0026#34;: \u0026#34;error\u0026#34;\r\u0026#34;co.elastic.metrics/module\u0026#34;: \u0026#34;nginx\u0026#34;\r\u0026#34;co.elastic.metrics/hosts\u0026#34;: \u0026#34;nginx:80\u0026#34;\r\u0026#34;co.elastic.metrics/metricsets\u0026#34;: \u0026#34;stubstatus\u0026#34;\rports:\r- 8081:80\rvolumes:\r- ./conf/default.conf:/etc/nginx/conf.d/default.conf:ro\rnetworks:\r- elastic\rpetclinic:\rimage: docker.io/michaelhyatt/elastic-k8s-o11y-workshop-petclinic:1.25.0\rcontainer_name: petclinic\rlabels:\r\u0026#34;co.elastic.metrics/module\u0026#34;: \u0026#34;prometheus\u0026#34;\r\u0026#34;co.elastic.metrics/hosts\u0026#34;: \u0026#34;$${data.host}:$${data.port}\u0026#34;\r\u0026#34;co.elastic.metrics/metrics_path\u0026#34;: \u0026#34;/metrics/prometheus\u0026#34;\r\u0026#34;co.elastic.metrics/period\u0026#34;: \u0026#34;1m\u0026#34;\renvironment:\rELASTIC_APM_SERVER_URLS: \u0026#34;http://apm-server:8200\u0026#34;\rELASTIC_APM_SERVER_URLS_FOR_RUM: \u0026#34;http://localhost:8200\u0026#34;\rELASTIC_APM_SECRET_TOKEN: \u0026#34;\u0026#34;\rELASTIC_APM_SERVICE_NAME: \u0026#34;spring-petclinic-monolith\u0026#34;\rELASTIC_APM_APPLICATION_PACKAGES: \u0026#34;org.springframework.samples\u0026#34;\rELASTIC_APM_ENABLE_LOG_CORRELATION: \u0026#34;true\u0026#34;\rELASTIC_APM_CAPTURE_JMX_METRICS: \u0026gt;\robject_name[java.lang:type=GarbageCollector,name=*] attribute[CollectionCount:metric_name=collection_count] attribute[CollectionTime:metric_name=collection_time],\robject_name[java.lang:type=Memory] attribute[HeapMemoryUsage:metric_name=heap]\rJAVA_OPTS: \u0026gt;\r-Xms100m\r-Xmx256m\r-Dspring.profiles.active=mysql\r-Ddatabase=mysql\r-Dspring.datasource.username=root\r-Dspring.datasource.password=petclinic\r-Dspring.datasource.initialization-mode=always\r-Dspring.datasource.url=jdbc:mysql://mysql:3306/petclinic?autoReconnect=true\u0026amp;useSSL=false\r-XX:+StartAttachListener\rports:\r- 8080:8080\rnetworks:\r- elastic\rmysql:\rimage: mysql:5.7.27\rcontainer_name: mysql\rlabels:\r\u0026#34;co.elastic.logs/module\u0026#34;: \u0026#34;mysql\u0026#34;\r\u0026#34;co.elastic.metrics/module\u0026#34;: \u0026#34;mysql\u0026#34;\r\u0026#34;co.elastic.metrics/hosts\u0026#34;: \u0026#34;root:petclinic@tcp($${data.host}:3306)/\u0026#34;\renvironment:\rMYSQL_ROOT_PASSWORD: petclinic\rMYSQL_DATABASE: petclinic\rports:\r- 3306\rnetworks:\r- elastic\rnetworks:\relastic:\rdriver: bridge vim app/conf/default.conf default.conf\nserver {\rlisten 80;\rserver_name localhost;\rlocation /intake {\rif ($request_method = \u0026#39;OPTIONS\u0026#39;) {\r# This is a bit too wide, would be enough to replace it with only APM server url for CORS support.\radd_header \u0026#39;Access-Control-Allow-Origin\u0026#39; \u0026#39;*\u0026#39;;\radd_header \u0026#39;Access-Control-Allow-Methods\u0026#39; \u0026#39;GET,POST,OPTIONS\u0026#39;;\radd_header \u0026#39;Access-Control-Allow-Headers\u0026#39; \u0026#39;Accept:,Accept-Encoding,Accept-Language:,Cache-Control,Connection,DNT,Pragma,Host,Referer,Upgrade-Insecure-Requests,User-Agent,elastic-apm-traceparent\u0026#39;;\radd_header \u0026#39;Access-Control-Max-Age\u0026#39; 1728000;\radd_header \u0026#39;Access-Control-Allow-Credentials\u0026#39; \u0026#39;true\u0026#39;;\radd_header \u0026#39;Content-Type\u0026#39; \u0026#39;text/plain; charset=utf-8\u0026#39;;\radd_header \u0026#39;Content-Length\u0026#39; 0;\rreturn 200;\r}\r}\rlocation / {\rproxy_pass http://petclinic:8080/;\r}\rlocation = /owners/find {\rreturn 301 /#$uri;\r}\rlocation = /vets.html {\rreturn 301 /#$uri;\r}\rlocation = /oups {\rreturn 301 /#$uri;\r}\rlocation /nginx_status {\rstub_status on;\rallow all; # A bit too wide\r# deny all;\r}\rerror_page 500 502 503 504 /50x.html;\rlocation = /50x.html {\rroot /usr/share/nginx/html;\r}\r} docker-compose -f app/petclinic.yml up -d Accédez à la application blanche en cliquant ici\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/alerting/","title":"Lab - Alertes","tags":[],"description":"","content":"Vous êtes le nouvel administrateur d\u0026rsquo;un cluster Elasticsearch à 3 nœuds. En prenant possession du cluster, vous constatez que aucune alerte n\u0026rsquo;est remonter sur l\u0026rsquo;état de la plateforme Elastic. Vos supérieurs vous demandent de donner la priorité à construire une solution d\u0026rsquo;alerting permettant de fournir des indicateurs de fiabilisés la plateforme.\nDans ce laboratoire pratique, vous aurez l\u0026rsquo;occasion de :\n Utiliser les API _security pour créer une API Key. utiliser l\u0026rsquo;API actions/connectors pour créer un connecteur de donnée Utiliser l\u0026rsquo;API alerting/rule pour mettre rapidement en place des alertes.  Créer des alertes avec le module Rules \u0026amp; Connector Créer une API Key Utilisez l\u0026rsquo;outil de console Kibana pour exécuter ce qui suit :\nPOST /_security/api_key\r{\r\u0026#34;name\u0026#34;: \u0026#34;my-api-key\u0026#34;,\r\u0026#34;expiration\u0026#34;: \u0026#34;30d\u0026#34;,\r\u0026#34;metadata\u0026#34;: {\r\u0026#34;application\u0026#34;: \u0026#34;my-application\u0026#34;,\r\u0026#34;environment\u0026#34;: {\r\u0026#34;level\u0026#34;: 1,\r\u0026#34;trusted\u0026#34;: true,\r\u0026#34;tags\u0026#34;: [\u0026#34;prod\u0026#34;, \u0026#34;pprod\u0026#34;]\r}\r}\r} {\r\u0026#34;id\u0026#34; : \u0026#34;uiVdOn8BIwAgRd-L1SZa\u0026#34;,\r\u0026#34;name\u0026#34; : \u0026#34;my-api-key\u0026#34;,\r\u0026#34;expiration\u0026#34; : 1648543702335,\r\u0026#34;api_key\u0026#34; : \u0026#34;AuXI4K3aSZ2jDYUbycs-8g\u0026#34;,\r\u0026#34;encoded\u0026#34; : \u0026#34;dWlWZE9uOEJJd0FnUmQtTDFTWmE6QXVYSTRLM2FTWjJqRFlVYnljcy04Zw==\u0026#34;\r} Créer un connecteur Server Log Utilisez l\u0026rsquo;outil POSTMAN pour exécuter ce qui suit :\ncurl --location --request POST \u0026#39;https://localhost:5601/api/actions/connector\u0026#39; \\\r--header \u0026#39;kbn-xsrf: true\u0026#39; \\\r--header \u0026#39;Authorization: APIKey YnlSTU9uOEJJd0FnUmQtTE9PQXc6em52akIyQlNRdHlPc3R4ODhTNFg3QQ==\u0026#39; \\\r--header \u0026#39;Content-Type: text/plain\u0026#39; \\\r--data-raw \u0026#39;{\r\u0026#34;name\u0026#34;: \u0026#34;Monitoring: Write to Kibana log TEST\u0026#34;,\r\u0026#34;config\u0026#34;: {},\r\u0026#34;connector_type_id\u0026#34;: \u0026#34;.server-log\u0026#34;\r}\u0026#39; Récupérer l\u0026rsquo;ID du connecteur curl --location --request GET \u0026#39;https://localhost:5601/api/actions/connectors\u0026#39; \\\r--header \u0026#39;kbn-xsrf: true\u0026#39; \\\r--header \u0026#39;Authorization: APIKey YnlSTU9uOEJJd0FnUmQtTE9PQXc6em52akIyQlNRdHlPc3R4ODhTNFg3QQ==\u0026#39; \\\r--data-raw \u0026#39;\u0026#39; {\r\u0026#34;id\u0026#34;: \u0026#34;6c65f7f0-97a6-11ec-b236-41c39a1728b8\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;Monitoring: Write to Kibana log\u0026#34;,\r\u0026#34;config\u0026#34;: {},\r\u0026#34;connector_type_id\u0026#34;: \u0026#34;.server-log\u0026#34;,\r\u0026#34;is_preconfigured\u0026#34;: false,\r\u0026#34;referenced_by_count\u0026#34;: 1,\r\u0026#34;is_missing_secrets\u0026#34;: false\r} Vous pouvez maintenant voir dans l\u0026rsquo;interface Kibana le connecteur :\nCréer une alerte sur la consommation des ressources CPU Usage Dans l\u0026rsquo;outil POSTMAN changer la méthode d\u0026rsquo;authentification en Basic Auth et renseigner le login et password de l\u0026rsquo;utilisateur elastic.\ncurl --location --request POST \u0026#39;https://localhost:5601/api/alerting/rule\u0026#39; \\\r--header \u0026#39;kbn-xsrf: true\u0026#39; \\\r--header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\\r--header \u0026#39;Content-Type: text/plain\u0026#39; \\\r--data-raw \u0026#39;{\r\u0026#34;enabled\u0026#34;: true,\r\u0026#34;tags\u0026#34;: [\u0026#34;monitoring\u0026#34;, \u0026#34;cpu\u0026#34;],\r\u0026#34;consumer\u0026#34;: \u0026#34;monitoring\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;CPU Usage\u0026#34;,\r\u0026#34;throttle\u0026#34;: \u0026#34;1d\u0026#34;,\r\u0026#34;schedule\u0026#34;: {\r\u0026#34;interval\u0026#34;: \u0026#34;1m\u0026#34;\r},\r\u0026#34;params\u0026#34;: {\r\u0026#34;threshold\u0026#34;: 85,\r\u0026#34;duration\u0026#34;: \u0026#34;5m\u0026#34;\r},\r\u0026#34;rule_type_id\u0026#34;: \u0026#34;monitoring_alert_cpu_usage\u0026#34;,\r\u0026#34;notify_when\u0026#34;: \u0026#34;onThrottleInterval\u0026#34;,\r\u0026#34;actions\u0026#34;: [\r{\r\u0026#34;group\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;id\u0026#34;: \u0026#34;6c65f7f0-97a6-11ec-b236-41c39a1728b8\u0026#34;,\r\u0026#34;params\u0026#34;: {\r\u0026#34;message\u0026#34;: \u0026#34;{{context.internalShortMessage}}\u0026#34;\r}\r}\r]\r}\r\u0026#39; Disk Usage curl --location --request POST \u0026#39;https://localhost:5601/api/alerting/rule\u0026#39; \\\r--header \u0026#39;kbn-xsrf: true\u0026#39; \\\r--header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\\r--header \u0026#39;Content-Type: text/plain\u0026#39; \\\r--data-raw \u0026#39;{\r\u0026#34;enabled\u0026#34;: true,\r\u0026#34;tags\u0026#34;: [],\r\u0026#34;consumer\u0026#34;: \u0026#34;monitoring\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;Disk Usage\u0026#34;,\r\u0026#34;throttle\u0026#34;: \u0026#34;1d\u0026#34;,\r\u0026#34;schedule\u0026#34;: {\r\u0026#34;interval\u0026#34;: \u0026#34;1m\u0026#34;\r},\r\u0026#34;params\u0026#34;: {\r\u0026#34;threshold\u0026#34;: 80,\r\u0026#34;duration\u0026#34;: \u0026#34;5m\u0026#34;\r},\r\u0026#34;rule_type_id\u0026#34;: \u0026#34;monitoring_alert_disk_usage\u0026#34;,\r\u0026#34;notify_when\u0026#34;: \u0026#34;onThrottleInterval\u0026#34;,\r\u0026#34;actions\u0026#34;: [\r{\r\u0026#34;group\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;id\u0026#34;: \u0026#34;6c65f7f0-97a6-11ec-b236-41c39a1728b8\u0026#34;,\r\u0026#34;params\u0026#34;: {\r\u0026#34;message\u0026#34;: \u0026#34;{{context.internalShortMessage}}\u0026#34;\r}\r}\r]\r}\u0026#39; Experiation de la licence curl --location --request POST \u0026#39;https://localhost:5601/api/alerting/rule\u0026#39; \\\r--header \u0026#39;kbn-xsrf: true\u0026#39; \\\r--header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\\r--header \u0026#39;Content-Type: text/plain\u0026#39; \\\r--data-raw \u0026#39;{\r\u0026#34;enabled\u0026#34;: true,\r\u0026#34;tags\u0026#34;: [],\r\u0026#34;consumer\u0026#34;: \u0026#34;monitoring\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;License expiration\u0026#34;,\r\u0026#34;throttle\u0026#34;: \u0026#34;1d\u0026#34;,\r\u0026#34;schedule\u0026#34;: {\r\u0026#34;interval\u0026#34;: \u0026#34;1m\u0026#34;\r},\r\u0026#34;params\u0026#34;: {},\r\u0026#34;rule_type_id\u0026#34;: \u0026#34;monitoring_alert_license_expiration\u0026#34;,\r\u0026#34;notify_when\u0026#34;: \u0026#34;onThrottleInterval\u0026#34;,\r\u0026#34;actions\u0026#34;: [\r{\r\u0026#34;group\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;id\u0026#34;: \u0026#34;6c65f7f0-97a6-11ec-b236-41c39a1728b8\u0026#34;,\r\u0026#34;params\u0026#34;: {\r\u0026#34;message\u0026#34;: \u0026#34;{{context.internalShortMessage}}\u0026#34;\r}\r}\r]\r}\u0026#39; Etat de santé du cluster \rcurl --location --request POST \u0026#39;https://localhost:5601/api/alerting/rule\u0026#39; \\\r--header \u0026#39;kbn-xsrf: true\u0026#39; \\\r--header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\\r--header \u0026#39;Content-Type: text/plain\u0026#39; \\\r--data-raw \u0026#39;{\r\u0026#34;enabled\u0026#34;: true,\r\u0026#34;tags\u0026#34;: [],\r\u0026#34;consumer\u0026#34;: \u0026#34;monitoring\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;Cluster health\u0026#34;,\r\u0026#34;throttle\u0026#34;: \u0026#34;1d\u0026#34;,\r\u0026#34;schedule\u0026#34;: {\r\u0026#34;interval\u0026#34;: \u0026#34;1m\u0026#34;\r},\r\u0026#34;params\u0026#34;: {},\r\u0026#34;rule_type_id\u0026#34;: \u0026#34;monitoring_alert_cluster_health\u0026#34;,\r\u0026#34;notify_when\u0026#34;: \u0026#34;onThrottleInterval\u0026#34;,\r\u0026#34;actions\u0026#34;: [\r{\r\u0026#34;group\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;id\u0026#34;: \u0026#34;6c65f7f0-97a6-11ec-b236-41c39a1728b8\u0026#34;,\r\u0026#34;params\u0026#34;: {\r\u0026#34;message\u0026#34;: \u0026#34;{{context.internalShortMessage}}\u0026#34;\r}\r}\r]\r}\u0026#39; Thread pool write rejections curl --location --request POST \u0026#39;https://localhost:5601/api/alerting/rule\u0026#39; \\\r--header \u0026#39;kbn-xsrf: true\u0026#39; \\\r--header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\\r--header \u0026#39;Content-Type: text/plain\u0026#39; \\\r--data-raw \u0026#39;{\r\u0026#34;enabled\u0026#34;: true,\r\u0026#34;tags\u0026#34;: [],\r\u0026#34;consumer\u0026#34;: \u0026#34;monitoring\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;Thread pool write rejections\u0026#34;,\r\u0026#34;throttle\u0026#34;: \u0026#34;1d\u0026#34;,\r\u0026#34;schedule\u0026#34;: {\r\u0026#34;interval\u0026#34;: \u0026#34;1m\u0026#34;\r},\r\u0026#34;params\u0026#34;: {\r\u0026#34;threshold\u0026#34;: 300,\r\u0026#34;duration\u0026#34;: \u0026#34;5m\u0026#34;\r},\r\u0026#34;rule_type_id\u0026#34;: \u0026#34;monitoring_alert_thread_pool_write_rejections\u0026#34;,\r\u0026#34;notify_when\u0026#34;: \u0026#34;onThrottleInterval\u0026#34;,\r\u0026#34;actions\u0026#34;: [\r{\r\u0026#34;group\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;id\u0026#34;: \u0026#34;6c65f7f0-97a6-11ec-b236-41c39a1728b8\u0026#34;,\r\u0026#34;params\u0026#34;: {\r\u0026#34;message\u0026#34;: \u0026#34;{{context.internalShortMessage}}\u0026#34;\r}\r}\r]\r}\u0026#39; Thread pool search rejections curl --location --request POST \u0026#39;https://localhost:5601/api/alerting/rule\u0026#39; \\\r--header \u0026#39;kbn-xsrf: true\u0026#39; \\\r--header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\\r--header \u0026#39;Content-Type: text/plain\u0026#39; \\\r--data-raw \u0026#39;{\r\u0026#34;enabled\u0026#34;: true,\r\u0026#34;tags\u0026#34;: [],\r\u0026#34;consumer\u0026#34;: \u0026#34;monitoring\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;Thread pool search rejections\u0026#34;,\r\u0026#34;throttle\u0026#34;: \u0026#34;1d\u0026#34;,\r\u0026#34;schedule\u0026#34;: {\r\u0026#34;interval\u0026#34;: \u0026#34;1m\u0026#34;\r},\r\u0026#34;params\u0026#34;: {\r\u0026#34;threshold\u0026#34;: 300,\r\u0026#34;duration\u0026#34;: \u0026#34;5m\u0026#34;\r},\r\u0026#34;rule_type_id\u0026#34;: \u0026#34;monitoring_alert_thread_pool_search_rejections\u0026#34;,\r\u0026#34;notify_when\u0026#34;: \u0026#34;onThrottleInterval\u0026#34;,\r\u0026#34;actions\u0026#34;: [\r{\r\u0026#34;group\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;id\u0026#34;: \u0026#34;6c65f7f0-97a6-11ec-b236-41c39a1728b8\u0026#34;,\r\u0026#34;params\u0026#34;: {\r\u0026#34;message\u0026#34;: \u0026#34;{{context.internalShortMessage}}\u0026#34;\r}\r}\r]\r}\u0026#39; Shard size curl --location --request POST \u0026#39;https://localhost:5601/api/alerting/rule\u0026#39; \\\r--header \u0026#39;kbn-xsrf: true\u0026#39; \\\r--header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\\r--header \u0026#39;Content-Type: text/plain\u0026#39; \\\r--data-raw \u0026#39;{\r\u0026#34;enabled\u0026#34;: true,\r\u0026#34;tags\u0026#34;: [],\r\u0026#34;consumer\u0026#34;: \u0026#34;monitoring\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;Shard size\u0026#34;,\r\u0026#34;throttle\u0026#34;: \u0026#34;12h\u0026#34;,\r\u0026#34;schedule\u0026#34;: {\r\u0026#34;interval\u0026#34;: \u0026#34;1m\u0026#34;\r},\r\u0026#34;params\u0026#34;: {\r\u0026#34;indexPattern\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;threshold\u0026#34;: 55\r},\r\u0026#34;rule_type_id\u0026#34;: \u0026#34;monitoring_shard_size\u0026#34;,\r\u0026#34;notify_when\u0026#34;: \u0026#34;onThrottleInterval\u0026#34;,\r\u0026#34;actions\u0026#34;: [\r{\r\u0026#34;group\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;id\u0026#34;: \u0026#34;6c65f7f0-97a6-11ec-b236-41c39a1728b8\u0026#34;,\r\u0026#34;params\u0026#34;: {\r\u0026#34;message\u0026#34;: \u0026#34;{{context.internalShortMessage}}\u0026#34;\r}\r}\r]\r}\u0026#39; Vous pouvez maintenant voir dans l\u0026rsquo;interface Kibana les alertes :\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez créer des connecteurs et des alertes et les indexer dans Elasticsearch.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/security/","title":"Lab - Habilitation","tags":[],"description":"","content":"Roles Kibana Les rôles sont un ensemble de privilèges qui vous permettent d\u0026rsquo;effectuer des actions dans Kibana et Elasticsearch. Les utilisateurs ne reçoivent pas directement de privilèges, mais se voient plutôt attribuer un ou plusieurs rôles qui décrivent le niveau d\u0026rsquo;accès souhaité. Lorsque vous attribuez plusieurs rôles à un utilisateur, ce dernier reçoit une union des privilèges des rôles. Cela signifie que vous ne pouvez pas réduire les privilèges d\u0026rsquo;un utilisateur en lui attribuant un rôle supplémentaire. Vous devez plutôt supprimer ou modifier l\u0026rsquo;un de ses rôles existants.\nUser Observability Vous allez créer un role pour les utilisateurs qui doivent consulter les différentes informations de leurs applications sur le menu Observability. Cette création sera faite via API d\u0026rsquo;Elasticsearch. Pour cela vous allez ouvrir un dans le menu Kibana Management -\u0026gt; DevTool.\nPOST /_security/role/read_observability\r{\r\u0026#34;cluster\u0026#34;: [],\r\u0026#34;indices\u0026#34;: [\r{\r\u0026#34;names\u0026#34;: [\r\u0026#34;metricbeat-*\u0026#34;,\r\u0026#34;filebeat-*\u0026#34;,\r\u0026#34;traces-apm*,apm-*,logs-apm*,apm-*,metrics-apm*,apm-*\u0026#34;\r],\r\u0026#34;privileges\u0026#34;: [\r\u0026#34;read\u0026#34;\r],\r\u0026#34;allow_restricted_indices\u0026#34;: false\r}\r],\r\u0026#34;applications\u0026#34;: [\r{\r\u0026#34;application\u0026#34;: \u0026#34;kibana-.kibana\u0026#34;,\r\u0026#34;privileges\u0026#34;: [\r\u0026#34;feature_logs.read\u0026#34;,\r\u0026#34;feature_infrastructure.read\u0026#34;,\r\u0026#34;feature_apm.read\u0026#34;,\r\u0026#34;feature_uptime.read\u0026#34;,\r\u0026#34;feature_observabilityCases.read\u0026#34;\r],\r\u0026#34;resources\u0026#34;: [\r\u0026#34;space:default\u0026#34;\r]\r}\r],\r\u0026#34;run_as\u0026#34;: [],\r\u0026#34;metadata\u0026#34;: {},\r\u0026#34;transient_metadata\u0026#34;: {\r\u0026#34;enabled\u0026#34;: true\r}\r} {\r\u0026#34;role\u0026#34; : {\r\u0026#34;created\u0026#34; : true\r}\r} Vérifions la configuration du role :\nGET /_security/role/read_observability {\r\u0026#34;read_observability\u0026#34; : {\r\u0026#34;cluster\u0026#34; : [ ],\r\u0026#34;indices\u0026#34; : [\r{\r\u0026#34;names\u0026#34; : [\r\u0026#34;metricbeat-*\u0026#34;,\r\u0026#34;filebeat-*\u0026#34;,\r\u0026#34;traces-apm*,apm-*,logs-apm*,apm-*,metrics-apm*,apm-*\u0026#34;\r],\r\u0026#34;privileges\u0026#34; : [\r\u0026#34;read\u0026#34;\r],\r\u0026#34;allow_restricted_indices\u0026#34; : false\r}\r],\r\u0026#34;applications\u0026#34; : [\r{\r\u0026#34;application\u0026#34; : \u0026#34;kibana-.kibana\u0026#34;,\r\u0026#34;privileges\u0026#34; : [\r\u0026#34;feature_logs.read\u0026#34;,\r\u0026#34;feature_infrastructure.read\u0026#34;,\r\u0026#34;feature_apm.read\u0026#34;,\r\u0026#34;feature_uptime.read\u0026#34;,\r\u0026#34;feature_observabilityCases.read\u0026#34;\r],\r\u0026#34;resources\u0026#34; : [\r\u0026#34;space:default\u0026#34;\r]\r}\r],\r\u0026#34;run_as\u0026#34; : [ ],\r\u0026#34;metadata\u0026#34; : { },\r\u0026#34;transient_metadata\u0026#34; : {\r\u0026#34;enabled\u0026#34; : true\r}\r}\r} Ensuite vous allez définir un utilisateur qui aura l\u0026rsquo;habilitation de lire les données d\u0026rsquo;observabilité grace au role précédament crée.\nPOST /_security/user/user_observability\r{\r\u0026#34;username\u0026#34;: \u0026#34;user_observability\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;test1234\u0026#34;,\r\u0026#34;roles\u0026#34;: [\r\u0026#34;read_observability\u0026#34;\r],\r\u0026#34;full_name\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;email\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;metadata\u0026#34;: {},\r\u0026#34;enabled\u0026#34;: true\r} {\r\u0026#34;created\u0026#34; : true\r} Vérifions la configuration du role :\nGET /_security/user/user_observability {\r\u0026#34;user_observability\u0026#34; : {\r\u0026#34;username\u0026#34; : \u0026#34;user_observability\u0026#34;,\r\u0026#34;roles\u0026#34; : [\r\u0026#34;read_observability\u0026#34;\r],\r\u0026#34;full_name\u0026#34; : \u0026#34;\u0026#34;,\r\u0026#34;email\u0026#34; : \u0026#34;\u0026#34;,\r\u0026#34;metadata\u0026#34; : { },\r\u0026#34;enabled\u0026#34; : true\r}\r} Maintenant ouvrez une page de votre navigateur privé pour vous connectez à Kibana avec cet utilisateur : Accerder à Kibana\nSélectionnez dans le menu Observability\nPuis observer que l\u0026rsquo;utilisateur ne voit pas les données de type APM et Uptime.\nA vous de jouez ! A vous de corriger les habilitations de l\u0026rsquo;utilisateur pour la lecture de données manquantes, voici quelque lien utile pour votre problème :\n https://www.elastic.co/guide/en/elasticsearch/reference/current/security-api-put-role.html https://www.elastic.co/guide/en/kibana/current/kibana-role-management.html https://www.elastic.co/guide/en/elasticsearch/reference/8.0/security-privileges.html#privileges-list-indices   Administrator Observability Vous allez créer un role pour les administrateurs qui doivent consulter/modifier/supprimer les différentes informations de leurs applications sur le menu Observability. Cette création sera faite via API d\u0026rsquo;Elasticsearch. Pour cela vous allez ouvrir un dans le menu Kibana Management -\u0026gt; DevTool.\nCorriger l\u0026rsquo;erreur dans le role administrateur que vous avez trouver sur le role user, puis exécuter cette requete :\nPOST /_security/role/admin_observability\r{\r\u0026#34;cluster\u0026#34;: [\r\u0026#34;create_snapshot\u0026#34;,\r\u0026#34;manage_ccr\u0026#34;,\r\u0026#34;manage_ilm\u0026#34;,\r\u0026#34;manage_saml\u0026#34;,\r\u0026#34;manage_watcher\u0026#34;,\r\u0026#34;monitor\u0026#34;,\r\u0026#34;read_ilm\u0026#34;\r],\r\u0026#34;indices\u0026#34;: [\r{\r\u0026#34;names\u0026#34;: [\r\u0026#34;metricbeat-*\u0026#34;,\r\u0026#34;filebeat-*\u0026#34;,\r\u0026#34;traces-apm*,apm-*,logs-apm*,apm-*,metrics-apm*,apm-*\u0026#34;\r],\r\u0026#34;privileges\u0026#34;: [\r\u0026#34;read\u0026#34;,\r\u0026#34;monitor\u0026#34;,\r\u0026#34;create\u0026#34;,\r\u0026#34;write\u0026#34;,\r\u0026#34;delete\u0026#34;,\r\u0026#34;delete_index\u0026#34;\r],\r\u0026#34;allow_restricted_indices\u0026#34;: false\r}\r],\r\u0026#34;applications\u0026#34;: [\r{\r\u0026#34;application\u0026#34;: \u0026#34;kibana-.kibana\u0026#34;,\r\u0026#34;privileges\u0026#34;: [\r\u0026#34;feature_logs.all\u0026#34;,\r\u0026#34;feature_infrastructure.all\u0026#34;,\r\u0026#34;feature_apm.all\u0026#34;,\r\u0026#34;feature_uptime.all\u0026#34;,\r\u0026#34;feature_observabilityCases.all\u0026#34;,\r\u0026#34;feature_dev_tools.all\u0026#34;,\r\u0026#34;feature_indexPatterns.read\u0026#34;\r],\r\u0026#34;resources\u0026#34;: [\r\u0026#34;space:default\u0026#34;\r]\r}\r],\r\u0026#34;run_as\u0026#34;: [],\r\u0026#34;metadata\u0026#34;: {},\r\u0026#34;transient_metadata\u0026#34;: {\r\u0026#34;enabled\u0026#34;: true\r}\r} {\r\u0026#34;role\u0026#34; : {\r\u0026#34;created\u0026#34; : true\r}\r} Vérifions la configuration du role :\nGET /_security/role/admin_observability {\r\u0026#34;admin_observability\u0026#34; : {\r\u0026#34;cluster\u0026#34; : [\r\u0026#34;create_snapshot\u0026#34;,\r\u0026#34;manage_ccr\u0026#34;,\r\u0026#34;manage_ilm\u0026#34;,\r\u0026#34;manage_saml\u0026#34;,\r\u0026#34;manage_watcher\u0026#34;,\r\u0026#34;monitor\u0026#34;,\r\u0026#34;read_ilm\u0026#34;\r],\r\u0026#34;indices\u0026#34; : [\r{\r\u0026#34;names\u0026#34; : [\r\u0026#34;metricbeat-*\u0026#34;,\r\u0026#34;filebeat-*\u0026#34;,\r\u0026#34;uptime-*\u0026#34;,\r\u0026#34;apm-*\u0026#34;,\r\u0026#34;heartbeat-*\u0026#34;\r],\r\u0026#34;privileges\u0026#34; : [\r\u0026#34;read\u0026#34;,\r\u0026#34;monitor\u0026#34;,\r\u0026#34;create\u0026#34;,\r\u0026#34;write\u0026#34;,\r\u0026#34;delete\u0026#34;,\r\u0026#34;delete_index\u0026#34;\r],\r\u0026#34;allow_restricted_indices\u0026#34; : false\r}\r],\r\u0026#34;applications\u0026#34; : [\r{\r\u0026#34;application\u0026#34; : \u0026#34;kibana-.kibana\u0026#34;,\r\u0026#34;privileges\u0026#34; : [\r\u0026#34;feature_logs.all\u0026#34;,\r\u0026#34;feature_infrastructure.all\u0026#34;,\r\u0026#34;feature_apm.all\u0026#34;,\r\u0026#34;feature_uptime.all\u0026#34;,\r\u0026#34;feature_observabilityCases.all\u0026#34;,\r\u0026#34;feature_dev_tools.all\u0026#34;,\r\u0026#34;feature_indexPatterns.read\u0026#34;\r],\r\u0026#34;resources\u0026#34; : [\r\u0026#34;space:default\u0026#34;\r]\r}\r],\r\u0026#34;run_as\u0026#34; : [ ],\r\u0026#34;metadata\u0026#34; : { },\r\u0026#34;transient_metadata\u0026#34; : {\r\u0026#34;enabled\u0026#34; : true\r}\r}\r} Ensuite vous allez définir un utilisateur qui aura l\u0026rsquo;habilitation de lire les données d\u0026rsquo;observabilité grace au role précédament crée.\nPOST /_security/user/admin_observability\r{\r\u0026#34;username\u0026#34;: \u0026#34;admin_observability\u0026#34;,\r\u0026#34;roles\u0026#34;: [\r\u0026#34;admin_observability\u0026#34;\r],\r\u0026#34;full_name\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;email\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;metadata\u0026#34;: {},\r\u0026#34;enabled\u0026#34;: true\r} {\r\u0026#34;created\u0026#34; : true\r} Vérifions la configuration du role :\nGET /_security/user/user_observability {\r\u0026#34;user_observability\u0026#34; : {\r\u0026#34;username\u0026#34; : \u0026#34;user_observability\u0026#34;,\r\u0026#34;roles\u0026#34; : [\r\u0026#34;read_observability\u0026#34;\r],\r\u0026#34;full_name\u0026#34; : \u0026#34;\u0026#34;,\r\u0026#34;email\u0026#34; : \u0026#34;\u0026#34;,\r\u0026#34;metadata\u0026#34; : { },\r\u0026#34;enabled\u0026#34; : true\r}\r} Maintenant ouvrez une page de votre navigateur privé pour vous connectez à Kibana avec cet utilisateur : Accerder à Kibana\nSélectionnez dans le menu Observability\nPuis observer que l\u0026rsquo;utilisateur ne voit pas les données de type APM et Uptime.\nGET apm-*/_search\rGET metricbeat-*/_search\rGET filebeat-*/_search\rGET heartbeat-*/_search Maintenant l\u0026rsquo;administrateur souhaite créer un index dans Elasticsearch afin de regrouper les données en un point d\u0026rsquo;accès\nPUT my-index-observability {\r\u0026#34;error\u0026#34; : {\r\u0026#34;root_cause\u0026#34; : [\r{\r\u0026#34;type\u0026#34; : \u0026#34;security_exception\u0026#34;,\r\u0026#34;reason\u0026#34; : \u0026#34;action [indices:admin/create] is unauthorized for user [admin_observability] with roles [admin_observability], this action is granted by the index privileges [create_index,manage,all]\u0026#34;\r}\r],\r\u0026#34;type\u0026#34; : \u0026#34;security_exception\u0026#34;,\r\u0026#34;reason\u0026#34; : \u0026#34;action [indices:admin/create] is unauthorized for user [admin_observability] with roles [admin_observability], this action is granted by the index privileges [create_index,manage,all]\u0026#34;\r},\r\u0026#34;status\u0026#34; : 403\r} A vous de jouez ! A vous de corriger les habilitations de l\u0026rsquo;administrateur pour la création d\u0026rsquo;un index, voici quelque lien utile pour votre problème :\n https://www.elastic.co/guide/en/elasticsearch/reference/current/security-api-put-role.html https://www.elastic.co/guide/en/kibana/current/kibana-role-management.html https://www.elastic.co/guide/en/elasticsearch/reference/8.0/security-privileges.html#privileges-list-indices  Résumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez créer et mettre à jour des roles pour vos utilisateurs. Vous avez également exploré les différentes habilitations possibles sur Elasticsearch.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_logs/","title":"Lab - Logs","tags":[],"description":"","content":"Objectif : Dans ce laboratoire, vous explorerez la facilité avec laquelle vous pouvez lire les fichiers journaux NGINX avec Filebeat et les indexer dans Elasticsearch. Vous explorerez également les tableaux de bord Kibana et verrez avec quelle facilité vous pouvez surveiller les journaux NGINX.\nDéployer un agent beats mkdir -P beats/conf vim beats/beats-docker.yml beats-docker.yml\nversion: \u0026#39;2.2\u0026#39;\rservices:\rfilebeat:\rimage: docker.elastic.co/beats/filebeat:${VERSION}\rcontainer_name: filebeat\rrestart: unless-stopped\rentrypoint: \u0026#34;filebeat -e -strict.perms=false\u0026#34;\ruser: root\rvolumes:\r- \u0026#34;./conf/filebeat.yml:/usr/share/filebeat/filebeat.yml:rw\u0026#34;\r- \u0026#34;/var/lib/docker/containers:/var/lib/docker/containers:ro\u0026#34;\r- \u0026#34;/var/run/docker.sock:/var/run/docker.sock:ro\u0026#34;\r- \u0026#34;/var/log:/tmp:ro\u0026#34;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge vim beats/conf/filebeat.yml ######################## Filebeat Configuration ############################\r#========================== Modules configuration ============================\rfilebeat.modules:\r#------------------------------- System Module -------------------------------\r- module: system\r# Syslog\rsyslog:\renabled: true\r# Authorization logs\rauth:\renabled: true\r#=========================== Filebeat inputs =============================\r# List of inputs to fetch data.\rfilebeat.inputs:\r#------------------------------ Log input --------------------------------\r- type: log\r# Change to true to enable this input configuration.\renabled: true\r# Paths that should be crawled and fetched. Glob based paths.\r# To fetch all \u0026#34;.log\u0026#34; files from a specific level of subdirectories\r# /var/log/*/*.log can be used.\r# For each file found under this path, a harvester is started.\r# Make sure not file is defined twice as this can lead to unexpected behaviour.\rpaths:\r- \u0026#34;/var/lib/docker/containers/*/*-json.log\u0026#34;\r- \u0026#39;/tmp/*.log\u0026#39;\r#========================== Filebeat autodiscover ==============================\r# Autodiscover allows you to detect changes in the system and spawn new modules\r# or inputs as they happen.\rfilebeat.autodiscover:\r# List of enabled autodiscover providers\rproviders:\r- type: docker\rhints.enabled: true\r#================================ Processors ===================================\r#\r# The following example enriches each event with docker metadata, it matches\r# given fields to an existing container id and adds info from that container:\r#\rprocessors:\r- add_docker_metadata: ~\r- add_locale:\rformat: offset\r- add_host_metadata:\rnetinfo.enabled: true\r#================================ Outputs ======================================\r# Configure what output to use when sending the data collected by the beat.\r#-------------------------- Elasticsearch output -------------------------------\routput.elasticsearch:\r# Boolean flag to enable or disable the output module.\renabled: true\r# Array of hosts to connect to.\r# Scheme and port can be left out and will be set to the default (http and 9200)\r# In case you specify and additional path, the scheme is required: http://localhost:9200/path\r# IPv6 addresses should always be defined as: https://[2001:db8::1]:9200\rhosts: [\u0026#34;es01:9200\u0026#34;]\r# Set gzip compression level.\r#compression_level: 0\r# Optional protocol and basic auth credentials.\rprotocol: \u0026#34;https\u0026#34;\rusername: \u0026#34;elastic\u0026#34;\rpassword: \u0026#34;CHANGEME\u0026#34;\r# Use SSL settings for HTTPS.\rssl.enabled: true\r# SSL configuration. By default is off.\r# List of root certificates for HTTPS server verifications\rssl.certificate_authorities: [\u0026#34;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026#34;]\r#============================== Dashboards =====================================\r# These settings control loading the sample dashboards to the Kibana index. Loading\r# the dashboards are disabled by default and can be enabled either by setting the\r# options here, or by using the `-setup` CLI flag or the `setup` command.\rsetup.dashboards.enabled: true\r#============================== Template =====================================\r# Template name. By default the template name is \u0026#34;filebeat-%{[beat.version]}\u0026#34;\r# The template name and pattern has to be set in case the elasticsearch index pattern is modified.\rsetup.template.name: \u0026#34;logs-%{[beat.version]}\u0026#34;\r# Template pattern. By default the template pattern is \u0026#34;-%{[beat.version]}-*\u0026#34; to apply to the default index settings.\r# The first part is the version of the beat and then -* is used to match all daily indices.\r# The template name and pattern has to be set in case the elasticsearch index pattern is modified.\rsetup.template.pattern: \u0026#34;logs-%{[beat.version]}-*\u0026#34;\r# Path to fields.yml file to generate the template\r#setup.template.fields: \u0026#34;${path.config}/fields.yml\u0026#34;\r# Overwrite existing template\r#setup.template.overwrite: false\r# Elasticsearch template settings\rsetup.template.settings:\r# A dictionary of settings to place into the settings.index dictionary\r# of the Elasticsearch template. For more details, please check\r# https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html\r#index:\rnumber_of_shards: 1\r#codec: best_compression\r#number_of_routing_shards: 30\r# A dictionary of settings for the _source field. For more details, please check\r# https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html\r#_source:\r#enabled: false\r#============================== Kibana =====================================\r# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.\r# This requires a Kibana endpoint configuration.\rsetup.kibana:\r# Kibana Host\r# Scheme and port can be left out and will be set to the default (http and 5601)\r# In case you specify and additional path, the scheme is required: http://localhost:5601/path\r# IPv6 addresses should always be defined as: https://[2001:db8::1]:5601\rhost: \u0026#34;kib01:5601\u0026#34;\r# Optional protocol and basic auth credentials.\rprotocol: \u0026#34;https\u0026#34;\rusername: \u0026#34;elastic\u0026#34;\rpassword: \u0026#34;CHANGEME\u0026#34;\r# Use SSL settings for HTTPS. Default is true.\rssl.enabled: true\rssl.certificate_authorities: [\u0026#34;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026#34;]\r#================================ Logging ======================================\r# There are four options for the log output: file, stderr, syslog, eventlog\r# The file output is the default.\r# Sets log level. The default log level is info.\r# Available log levels are: error, warning, info, debug\rlogging.level: info\r# Send all logging output to syslog. The default is false.\rlogging.to_syslog: true\r# Send all logging output to Windows Event Logs. The default is false.\rlogging.to_eventlog: true\r# If enabled, filebeat periodically logs its internal metrics that have changed\r# in the last period. For each metric that changed, the delta from the value at\r# the beginning of the period is logged. Also, the total values for\r# all non-zero internal metrics are logged on shutdown. The default is true.\rlogging.metrics.enabled: true\r# The period after which to log the internal metrics. The default is 30s.\rlogging.metrics.period: 30s\r# Logging to rotating files. Set logging.to_files to false to disable logging to\r# files.\rlogging.to_files: true\rlogging.files:\r# Configure the path where the logs are written. The default is the logs directory\r# under the home path (the binary location).\rpath: /var/log/filebeat\r# The name of the files where the logs are written to.\rname: filebeat Changer la valeur du champs password avec la valeur du mot de passe générer automatiquement.\ndocker-compose -f beats/beats-docker.yml up -d vim app/artificial_load.sh #!/bin/bash\rCOUNTER=0\rwhile [ $COUNTER -lt 10000 ] ;\rdo\rcurl -s --header \u0026#34;X-Forwarded-For: 5.198.223.255\u0026#34; localhost \u0026gt; /dev/null\rcurl -s localhost/owners/find \u0026gt; /dev/null\rcurl -s localhost/owners?lastName= \u0026gt; /dev/null\rcurl -s localhost/owners/1 \u0026gt; /dev/null\rcurl -s localhost/owners/4 \u0026gt; /dev/null\rcurl -s localhost/owners/6 \u0026gt; /dev/null\rcurl -s localhost/owners/8 \u0026gt; /dev/null\rcurl -s localhost/vets.html \u0026gt; /dev/null\rcurl -s localhost/oups \u0026gt; /dev/null\rlet COUNTER=COUNTER+1\rdone chmod +x app/artificial_load.sh Maintenant, ouvrez une nouvelle fenêtre de terminal et exécutez le script suivant pour simuler la charge sur votre serveur NGINX.\n./app/artificial_load.sh Lancer Kibana pour commencer à explorer les tableaux de bord qui ont été inclus dans le processus de configuration.\nAccédez à Dashboard via le menu principal\nRecherchez nginx et ouvrez le tableau de bord ECS Filebeat Nginx Overview.\nVous verrez quelque chose de similaire à la page ci-dessous.\nFaites défiler vers le bas et vérifiez quel est le navigateur le plus utilisé. Vous remarquerez que ce devrait être curl car il est utilisé par le script de simulation de charge.\nMaintenant, cliquez sur Nginx access and error logs en haut du tableau de bord actuel pour voir le tableau de bord avec les journaux d\u0026rsquo;accès et d\u0026rsquo;erreurs que Filebeat a collecté de NGINX.\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez lire les fichiers journaux NGINX avec Filebeat et les indexer dans Elasticsearch. Vous avez également exploré les tableaux de bord Kibana et vu comment vous pouvez facilement surveiller les journaux NGINX.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/avance/term/","title":"Labs - Query niveau I","tags":[],"description":"","content":"Préparation PUT /shakespeare { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;speaker\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;play_name\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;line_id\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, \u0026#34;speech_number\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;} } } } curl -H \u0026#39;Content-Type: application/x-ndjson\u0026#39; -XPOST \u0026#39;localhost:9200/bank/account/_bulk?pretty\u0026#39; --data-binary @accounts.json curl -H \u0026#39;Content-Type: application/x-ndjson\u0026#39; -XPOST \u0026#39;localhost:9200/shakespeare/doc/_bulk?pretty\u0026#39; --data-binary @shakespeare_6.0.json GET _cat/nodes?v GET _cat/indices?v ## API Search Recherche plusieurs terms (match) Renvoie les documents qui correspondent à un texte, un nombre, une date ou une valeur booléenne fournis. Le texte fourni est analysé avant de correspondre.\nGET _search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;text_entry\u0026#34;: \u0026#34;to be or not to be\u0026#34; } } } Recherche une phrase en entière (match phrase) La requête match_phrase analyse le texte et crée une requête de phrase à partir du texte analysé.\nGET _search { \u0026#34;query\u0026#34;: { \u0026#34;match_phrase\u0026#34;: { \u0026#34;text_entry\u0026#34;: \u0026#34;to be or not to be\u0026#34; } } } Recherche un term dans un champs spécifique (multi match) La requête multi_match s\u0026rsquo;appuie sur la requête match pour permettre les requêtes multi-champs.\nGET _search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Crime\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;text_entry\u0026#34;, \u0026#34;relatedContent.og:description\u0026#34;] } } } Recherche plusieurs terms dans un champs spécifique (query string) Renvoie les documents basés sur une chaîne de requête fournie, en utilisant un analyseur syntaxique strict.\nGET _search { \u0026#34;query\u0026#34;: { \u0026#34;query_string\u0026#34;: { \u0026#34;default_field\u0026#34;: \u0026#34;text_entry\u0026#34;, \u0026#34;query\u0026#34;: \u0026#34;(romeo AND juliet) OR (mother AND father)\u0026#34; } } } Recherche un term dans un champs spécifique sans utiliser un analyseur de texte (term) Retourne les documents qui contiennent un terme exact dans un champ fourni.\nGET _search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;speaker\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;ROMEO\u0026#34; } } } } Recherche plusieurs terms dans un champs spécifique sans utiliser un analyseur de texte (terms) Retourne les documents qui contiennent un terme exact dans un champ fourni.\nGET _search { \u0026#34;query\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;speaker\u0026#34;: [ \u0026#34;ROMEO\u0026#34;, \u0026#34;JUILIET\u0026#34;, \u0026#34;HAMLET\u0026#34; ] } } } Recherche une valeur entre 40 et 50 dans un champs spécifique (range) Renvoie les documents qui contiennent des termes compris dans une plage donnée.\nGET _search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gte\u0026#34;: 40, \u0026#34;lt\u0026#34;: 50 } } } } Recherche une valeur wildcard dans un champs spécifique (wildcard) Renvoie les documents qui contiennent des termes correspondant à un motif de caractère générique.\nUn opérateur wildcard est un caractère de remplacement qui correspond à un ou plusieurs caractères. Par exemple, l\u0026rsquo;opérateur wildcard * correspond à zéro ou plusieurs caractères. Vous pouvez combiner des opérateurs wildcard avec d\u0026rsquo;autres caractères pour créer un motif wildcard.\nGET _search { \u0026#34;query\u0026#34;: { \u0026#34;wildcard\u0026#34;: { \u0026#34;city.keyword\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;*ville\u0026#34; } } } } Recherche une valeur avec une regex dans un champs spécifique (regex) Renvoie les documents qui contiennent des termes correspondant à une expression régulière.\nGET _search { \u0026#34;query\u0026#34;: { \u0026#34;regex\u0026#34;: { \u0026#34;email.keyword\u0026#34;: \u0026#34;.*@xurban\\\\.com\u0026#34; } } } "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/ilm/","title":"Lab - Index Lifecycle Policy","tags":[],"description":"","content":"Vous pouvez configurer des politiques de gestion du cycle de vie des index (ILM) pour gérer automatiquement les index en fonction de vos exigences en matière de performances, de résilience et de rétention. Par exemple, vous pouvez utiliser ILM pour :\n Faire tourner un nouvel index lorsqu\u0026rsquo;un index atteint une certaine taille ou un certain nombre de documents. créer un nouvel index chaque jour, semaine ou mois et archiver les précédents supprimer les index périmés pour appliquer les normes de conservation des données.  Vous pouvez créer et gérer les politiques de cycle de vie des index via Kibana Management ou les API ILM. Lorsque vous activez la gestion du cycle de vie des index pour Beats ou le plugin de sortie Logstash Elasticsearch, des politiques par défaut sont configurées automatiquement.\nLa mise en place de règle de gestion permet :\n Augmenter les performances de recherche et/ou de visualisation Obtenir une meilleure résilience de ses données De définir des standards de rétention.  L\u0026rsquo;avantage de la fonctionnalité ILM est d\u0026rsquo;automatiser cette gestion avec des règles simple d\u0026rsquo;usage.\nILM Settings Par défaut sur votre cluster la fonctionnalité ILM est configuré à un interval de vérification de 10 minutes.\nCe paramètre peut être modifié dans des contexts hors prod.\nGET _cluster/settings\rPUT _cluster/settings\r{\r\u0026#34;persistent\u0026#34;:{\r\u0026#34;indices.lifecycle.poll_interval\u0026#34;: \u0026#34;1s\u0026#34;\r}\r} {\r\u0026#34;acknowledged\u0026#34; : true,\r\u0026#34;persistent\u0026#34; : {\r\u0026#34;indices\u0026#34; : {\r\u0026#34;lifecycle\u0026#34; : {\r\u0026#34;poll_interval\u0026#34; : \u0026#34;1s\u0026#34;\r}\r}\r},\r\u0026#34;transient\u0026#34; : { }\r} ILM Policy La définition d\u0026rsquo;une règle intègre plusieurs paramètres :\n Phase : Il existe plusieurs type de phase hot, warm et cold. Rollover : Le roulement d\u0026rsquo;un index s\u0026rsquo;applique avec au moins un de ces paramètres : max_age, max_size, max_docs. Delete : La rétention d\u0026rsquo;un index avec la fonction de suppression.  Il est recommander d\u0026rsquo;effectuer dans la phase hot une rotation d\u0026rsquo;index sur les paramètres suivant :\n Logs :  max_age : 15d max_size : 45gb   Metric :  max_age : 15d max_size : 40gb    Et une deuxième recommandation est d\u0026rsquo;effectuer une retention d\u0026rsquo;index égale à 90 jours.\nCela permet d\u0026rsquo;augmenter les performances de l\u0026rsquo;index et d\u0026rsquo;optimiser les recherches.\nPour notre besoin d\u0026rsquo;aujourd\u0026rsquo;hui, nous allons préparer une ILM avec une phase très courte. Ouvrez dans le menu Kibana le DevTool.\nPUT _ilm/policy/observability-policy\r{\r\u0026#34;policy\u0026#34;: {\r\u0026#34;phases\u0026#34;: {\r\u0026#34;hot\u0026#34;: {\r\u0026#34;actions\u0026#34;: {\r\u0026#34;rollover\u0026#34;: {\r\u0026#34;max_docs\u0026#34;: 10\r},\r\u0026#34;set_priority\u0026#34;: {\r\u0026#34;priority\u0026#34;: 50\r}\r}\r},\r\u0026#34;delete\u0026#34;: {\r\u0026#34;min_age\u0026#34;: \u0026#34;60d\u0026#34;,\r\u0026#34;actions\u0026#34;: {\r\u0026#34;delete\u0026#34;: {}\r}\r}\r}\r}\r} {\r\u0026#34;acknowledged\u0026#34; : true\r} Components Template Settings Nous allons configurer des paramètres par défaut pour tous les index ELasticsearch qui seront créé.\nIl est recommandé d\u0026rsquo;avoir les paramètres de réplications suivant :\n shard : 1 replicas : 1  PUT _component_template/observability-settings\r{\r\u0026#34;template\u0026#34;: {\r\u0026#34;settings\u0026#34;: {\r\u0026#34;number_of_shards\u0026#34;: 1,\r\u0026#34;number_of_replicas\u0026#34;: 10,\r\u0026#34;index.lifecycle.name\u0026#34;: \u0026#34;observability-policy\u0026#34;\r}\r},\r\u0026#34;_meta\u0026#34;: {\r\u0026#34;description\u0026#34;: \u0026#34;Settings for Observability data\u0026#34;\r}\r} {\r\u0026#34;acknowledged\u0026#34; : true\r} Mapping NOus allons configurer un mapping des champs par défaut pour toutes les données d\u0026rsquo;observabilité.\nPUT _component_template/observability-mappings\r{\r\u0026#34;template\u0026#34;: {\r\u0026#34;mappings\u0026#34;: {\r\u0026#34;properties\u0026#34;: {\r\u0026#34;@timestamp\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;,\r\u0026#34;format\u0026#34;: \u0026#34;date_optional_time||epoch_millis\u0026#34;\r},\r\u0026#34;message\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;wildcard\u0026#34;\r}\r}\r}\r},\r\u0026#34;_meta\u0026#34;: {\r\u0026#34;description\u0026#34;: \u0026#34;Mappings for @timestamp and message fields\u0026#34;\r}\r} {\r\u0026#34;acknowledged\u0026#34; : true\r} Index Template L\u0026rsquo;index template est une fonctionnalité permettant de définir des paramètres par défaut à vos index. Cela permet d\u0026rsquo;automatiser la gestion des index en appliquant des configurations de réplications, de règles de gestion automatiquement.\nPUT _index_template/observability-template\r{\r\u0026#34;index_patterns\u0026#34;: [\u0026#34;observability-*\u0026#34;],\r\u0026#34;data_stream\u0026#34;: { },\r\u0026#34;composed_of\u0026#34;: [ \u0026#34;observability-mappings\u0026#34;, \u0026#34;observability-settings\u0026#34; ],\r\u0026#34;priority\u0026#34;: 500,\r\u0026#34;_meta\u0026#34;: {\r\u0026#34;description\u0026#34;: \u0026#34;Template for my time series data\u0026#34;\r}\r} {\r\u0026#34;acknowledged\u0026#34; : true\r} Créer votre Data Stream PUT _data_stream/observability-time-series {\r\u0026#34;acknowledged\u0026#34; : true\r} Ajouter des données dans le Data Stream PUT observability-time-series/_bulk\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:21:15.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:25:42.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026#34;GET /favicon.ico HTTP/1.0\\\u0026#34; 200 3638\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:21:15.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:25:42.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026#34;GET /favicon.ico HTTP/1.0\\\u0026#34; 200 3638\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:21:15.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:25:42.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026#34;GET /favicon.ico HTTP/1.0\\\u0026#34; 200 3638\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:21:15.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:25:42.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026#34;GET /favicon.ico HTTP/1.0\\\u0026#34; 200 3638\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:21:15.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:25:42.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026#34;GET /favicon.ico HTTP/1.0\\\u0026#34; 200 3638\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:21:15.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:25:42.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026#34;GET /favicon.ico HTTP/1.0\\\u0026#34; 200 3638\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:21:15.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:25:42.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026#34;GET /favicon.ico HTTP/1.0\\\u0026#34; 200 3638\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:21:15.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34;}\r{\u0026#34;create\u0026#34;:{}}\r{\u0026#34;@timestamp\u0026#34;:\u0026#34;2099-05-06T16:25:42.000Z\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;192.0.2.255 - - [06/May/2099:16:25:42 +0000] \\\u0026#34;GET /favicon.ico HTTP/1.0\\\u0026#34; 200 3638\u0026#34;} {\r\u0026#34;took\u0026#34; : 12,\r\u0026#34;errors\u0026#34; : false,\r\u0026#34;items\u0026#34; : [\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;HggBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 0,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;HwgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 1,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;IAgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 2,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;IQgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 3,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;IggBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 4,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;IwgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 5,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;JAgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 6,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;JQgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 7,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;JggBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 8,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;JwgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 9,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;KAgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 10,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;KQgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 11,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;KggBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 12,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;KwgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 13,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;LAgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 14,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r},\r{\r\u0026#34;create\u0026#34; : {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;LQgBHn8BzEvhAp6LaS34\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 15,\r\u0026#34;_primary_term\u0026#34; : 1,\r\u0026#34;status\u0026#34; : 201\r}\r}\r]\r} Mettre à jours les données Data Stream POST observability-time-series/_doc\r{\r\u0026#34;@timestamp\u0026#34;: \u0026#34;2099-05-06T16:21:15.000Z\u0026#34;,\r\u0026#34;message\u0026#34;: \u0026#34;192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\u0026#34;GET /images/bg.jpg HTTP/1.0\\\u0026#34; 200 24736\u0026#34;\r} {\r\u0026#34;_index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000002\u0026#34;,\r\u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;,\r\u0026#34;_id\u0026#34; : \u0026#34;ZQgCHn8BzEvhAp6LozUb\u0026#34;,\r\u0026#34;_version\u0026#34; : 1,\r\u0026#34;result\u0026#34; : \u0026#34;created\u0026#34;,\r\u0026#34;_shards\u0026#34; : {\r\u0026#34;total\u0026#34; : 2,\r\u0026#34;successful\u0026#34; : 2,\r\u0026#34;failed\u0026#34; : 0\r},\r\u0026#34;_seq_no\u0026#34; : 0,\r\u0026#34;_primary_term\u0026#34; : 1\r} On constate que le nom de l\u0026rsquo;index est différent .ds-observability-time-series-2022.02.21-000002, il y a eu une rotation automatique de l\u0026rsquo;index. On constate alors que la politique de rotation est bien appliquée.\nILM Check GET _ilm/status {\r\u0026#34;operation_mode\u0026#34; : \u0026#34;RUNNING\u0026#34;\r} GET _ilm/policy/observability-policy {\r\u0026#34;observability-policy\u0026#34; : {\r\u0026#34;version\u0026#34; : 1,\r\u0026#34;modified_date\u0026#34; : \u0026#34;2022-02-21T20:35:02.304Z\u0026#34;,\r\u0026#34;policy\u0026#34; : {\r\u0026#34;phases\u0026#34; : {\r\u0026#34;hot\u0026#34; : {\r\u0026#34;min_age\u0026#34; : \u0026#34;0ms\u0026#34;,\r\u0026#34;actions\u0026#34; : {\r\u0026#34;rollover\u0026#34; : {\r\u0026#34;max_docs\u0026#34; : 10\r},\r\u0026#34;set_priority\u0026#34; : {\r\u0026#34;priority\u0026#34; : 50\r}\r}\r},\r\u0026#34;delete\u0026#34; : {\r\u0026#34;min_age\u0026#34; : \u0026#34;60d\u0026#34;,\r\u0026#34;actions\u0026#34; : {\r\u0026#34;delete\u0026#34; : {\r\u0026#34;delete_searchable_snapshot\u0026#34; : true\r}\r}\r}\r}\r},\r\u0026#34;in_use_by\u0026#34; : {\r\u0026#34;indices\u0026#34; : [\r\u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;.ds-observability-time-series-2022.02.21-000002\u0026#34;\r],\r\u0026#34;data_streams\u0026#34; : [\r\u0026#34;observability-time-series\u0026#34;\r],\r\u0026#34;composable_templates\u0026#34; : [\r\u0026#34;observability-template\u0026#34;\r]\r}\r}\r} On retrouve la configuration de notre ILM ainsi que les index rattachés.\nGET observability-time-series/_ilm/explain {\r\u0026#34;indices\u0026#34; : {\r\u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34; : {\r\u0026#34;index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000001\u0026#34;,\r\u0026#34;managed\u0026#34; : true,\r\u0026#34;policy\u0026#34; : \u0026#34;observability-policy\u0026#34;,\r\u0026#34;lifecycle_date_millis\u0026#34; : 1645475884407,\r\u0026#34;age\u0026#34; : \u0026#34;4.91m\u0026#34;,\r\u0026#34;phase\u0026#34; : \u0026#34;hot\u0026#34;,\r\u0026#34;phase_time_millis\u0026#34; : 1645475859767,\r\u0026#34;action\u0026#34; : \u0026#34;complete\u0026#34;,\r\u0026#34;action_time_millis\u0026#34; : 1645475885210,\r\u0026#34;step\u0026#34; : \u0026#34;complete\u0026#34;,\r\u0026#34;step_time_millis\u0026#34; : 1645475885210,\r\u0026#34;phase_execution\u0026#34; : {\r\u0026#34;policy\u0026#34; : \u0026#34;observability-policy\u0026#34;,\r\u0026#34;phase_definition\u0026#34; : {\r\u0026#34;min_age\u0026#34; : \u0026#34;0ms\u0026#34;,\r\u0026#34;actions\u0026#34; : {\r\u0026#34;rollover\u0026#34; : {\r\u0026#34;max_docs\u0026#34; : 10\r},\r\u0026#34;set_priority\u0026#34; : {\r\u0026#34;priority\u0026#34; : 50\r}\r}\r},\r\u0026#34;version\u0026#34; : 1,\r\u0026#34;modified_date_in_millis\u0026#34; : 1645475702304\r}\r},\r\u0026#34;.ds-observability-time-series-2022.02.21-000002\u0026#34; : {\r\u0026#34;index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.21-000002\u0026#34;,\r\u0026#34;managed\u0026#34; : true,\r\u0026#34;policy\u0026#34; : \u0026#34;observability-policy\u0026#34;,\r\u0026#34;lifecycle_date_millis\u0026#34; : 1645475884525,\r\u0026#34;age\u0026#34; : \u0026#34;4.91m\u0026#34;,\r\u0026#34;phase\u0026#34; : \u0026#34;hot\u0026#34;,\r\u0026#34;phase_time_millis\u0026#34; : 1645475884809,\r\u0026#34;action\u0026#34; : \u0026#34;rollover\u0026#34;,\r\u0026#34;action_time_millis\u0026#34; : 1645475885210,\r\u0026#34;step\u0026#34; : \u0026#34;check-rollover-ready\u0026#34;,\r\u0026#34;step_time_millis\u0026#34; : 1645475885210,\r\u0026#34;phase_execution\u0026#34; : {\r\u0026#34;policy\u0026#34; : \u0026#34;observability-policy\u0026#34;,\r\u0026#34;phase_definition\u0026#34; : {\r\u0026#34;min_age\u0026#34; : \u0026#34;0ms\u0026#34;,\r\u0026#34;actions\u0026#34; : {\r\u0026#34;rollover\u0026#34; : {\r\u0026#34;max_docs\u0026#34; : 10\r},\r\u0026#34;set_priority\u0026#34; : {\r\u0026#34;priority\u0026#34; : 50\r}\r}\r},\r\u0026#34;version\u0026#34; : 1,\r\u0026#34;modified_date_in_millis\u0026#34; : 1645475702304\r}\r}\r}\r} On peut observer les différentes informations de nos index concernant ILM appliquée deçu.\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez mettre en place une politique de gestion du cylce de vie de vos index. Vous avez également exploré les différentes composants d\u0026rsquo;une politique de gestion d\u0026rsquo;index au travers des settings, mappings, template et data stream.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_metrics/","title":"Lab - Metrics","tags":[],"description":"","content":"Objectif : Dans ce laboratoire, vous explorerez la facilité avec laquelle vous pouvez obtenir des métriques système et NGINX avec Metricbeat et les indexer dans Elasticsearch. Vous explorerez également les tableaux de bord Kibana et verrez avec quelle facilité vous pouvez surveiller ces métriques.\nDéployer un agent beats Ajoutez le service Metricbeat à la suite du service Beats\nvim beats/beats-docker.yml beats-docker.yml\nversion: \u0026#39;2.2\u0026#39;\rservices:\rfilebeat:\rimage: docker.elastic.co/beats/filebeat:${VERSION}\rcontainer_name: filebeat\rrestart: unless-stopped\rentrypoint: \u0026#34;filebeat -e -strict.perms=false\u0026#34;\ruser: root\rvolumes:\r- \u0026#34;./conf/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\u0026#34;\r- \u0026#34;/var/lib/docker/containers:/var/lib/docker/containers:ro\u0026#34;\r- \u0026#34;/var/run/docker.sock:/var/run/docker.sock:ro\u0026#34;\r- \u0026#34;/var/log:/tmp:ro\u0026#34;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rmetricbeat:\rimage: docker.elastic.co/beats/metricbeat:${VERSION}\rcontainer_name: metricbeat\rrestart: unless-stopped\rentrypoint: \u0026#34;metricbeat -e -strict.perms=false\u0026#34;\ruser: root\rvolumes:\r- \u0026#34;./conf/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro\u0026#34;\r- \u0026#34;/proc:/hostfs/proc:ro\u0026#34;\r- \u0026#34;/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\u0026#34;\r- \u0026#34;/:/hostfs:ro\u0026#34;\r- \u0026#34;/var/run/docker.sock:/var/run/docker.sock:ro\u0026#34;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge vim beats/conf/metricbeat.yml #-------------------------------- Autodiscovery -------------------------------\r# Autodiscover allows you to detect changes in the system and spawn new modules as they happen.\rmetricbeat.autodiscover:\rproviders:\r- type: docker\r# https://www.elastic.co/guide/en/beats/metricbeat/current/configuration-autodiscover-hints.html\rhints.enabled: true\rmetricbeat.modules:\r#------------------------------- System Module -------------------------------\r- module: system\rmetricsets: [\u0026#34;cpu\u0026#34;, \u0026#34;load\u0026#34;, \u0026#34;memory\u0026#34;, \u0026#34;network\u0026#34;, \u0026#34;process\u0026#34;, \u0026#34;process_summary\u0026#34;, \u0026#34;core\u0026#34;, \u0026#34;diskio\u0026#34;, \u0026#34;socket\u0026#34;]\rprocesses: [\u0026#39;.*\u0026#39;]\rprocess.include_top_n:\rby_cpu: 5\rby_memory: 5\rperiod: 10s\rcpu.metrics: [\u0026#34;percentages\u0026#34;]\rcore.metrics: [\u0026#34;percentages\u0026#34;]\r- module: system\rperiod: 1m\rmetricsets:\r- filesystem\r- fsstat\rprocessors:\r- drop_event.when.regexp:\rsystem.filesystem.mount_point: \u0026#39;^/(sys|cgroup|proc|dev|etc|host|lib)($|/)\u0026#39;\r- module: system\rperiod: 15m\rmetricsets:\r- uptime\r#------------------------------- Docker Module -------------------------------\r- module: docker\rmetricsets: [\u0026#34;container\u0026#34;, \u0026#34;cpu\u0026#34;, \u0026#34;diskio\u0026#34;, \u0026#34;healthcheck\u0026#34;, \u0026#34;info\u0026#34;, \u0026#34;memory\u0026#34;, \u0026#34;network\u0026#34;]\rhosts: [\u0026#34;unix:///var/run/docker.sock\u0026#34;]\rperiod: 10s\r#================================ Processors ===================================\rprocessors:\r- add_docker_metadata: ~\r- add_locale:\rformat: offset\r- add_host_metadata:\rnetinfo.enabled: true\r#========================== Elasticsearch output ===============================\routput.elasticsearch:\rhosts: [\u0026#34;https://es01:9200\u0026#34;]\rusername: \u0026#34;beats_system\u0026#34;\rpassword: \u0026#34;CHANGEME\u0026#34;\rssl.enabled: true\rssl.certificate_authorities: [\u0026#34;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026#34;]\r#============================== Dashboards =====================================\rsetup.dashboards:\renabled: true\r#============================== Kibana =========================================\rsetup.kibana:\rhost: \u0026#34;https://kib01:5601\u0026#34;\rusername: \u0026#34;elastic\u0026#34;\rpassword: \u0026#34;CHANGEME\u0026#34;\rssl.enabled: true\rssl.certificate_authorities: [\u0026#34;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026#34;] Changer la valeur du champs password avec la valeur du mot de passe générer automatiquement.\ndocker-compose -f beats/beats-docker.yml up -d vim app/artificial_load.sh #!/bin/bash\rCOUNTER=0\rwhile [ $COUNTER -lt 10000 ] ;\rdo\rcurl -s --header \u0026#34;X-Forwarded-For: 5.198.223.255\u0026#34; localhost \u0026gt; /dev/null\rcurl -s localhost/owners/find \u0026gt; /dev/null\rcurl -s localhost/owners?lastName= \u0026gt; /dev/null\rcurl -s localhost/owners/1 \u0026gt; /dev/null\rcurl -s localhost/owners/4 \u0026gt; /dev/null\rcurl -s localhost/owners/6 \u0026gt; /dev/null\rcurl -s localhost/owners/8 \u0026gt; /dev/null\rcurl -s localhost/vets.html \u0026gt; /dev/null\rcurl -s localhost/oups \u0026gt; /dev/null\rlet COUNTER=COUNTER+1\rdone chmod +x app/artificial_load.sh Maintenant, ouvrez une nouvelle fenêtre de terminal et exécutez le script suivant pour simuler la charge sur votre serveur NGINX.\n./app/artificial_load.sh Lancez Kibana pour commencer à explorer les tableaux de bord qui ont été inclus dans le processus de configuration.\nEnsuite, accédez à Dashboard via le menu principal.\nRecherchez le système et ouvrez la vue d\u0026rsquo;ensemble de Metricbeat System ECS.\nVous verrez quelque chose de similaire à la page ci-dessous.\nCliquez sur Vue d\u0026rsquo;ensemble de l\u0026rsquo;hôte en haut du tableau de bord actuel pour voir un tableau de bord avec plus d\u0026rsquo;informations que Metricbeat a collectées à partir de l\u0026rsquo;hôte de votre environnement de laboratoire.\nRetournez sur la page des tableaux de bord Kibana, recherchez nginx et ouvrez le tableau de bord ECS [Metricbeat Nginx] Overview.\nVous verrez quelque chose de similaire à la page ci-dessous.\nRetournez dans les tableaux de bord Kibana et cliquez sur Créer un nouveau tableau de bord pour comparer les données NGINX collectées à partir de Filebeat et Metricbeat.\nCliquez sur Ajouter depuis la bibliothèque pour commencer à ajouter des visualisations à votre tableau de bord.\nUtilisez la barre de requête pour filtrer par visualisations filebeat nginx et ajoutez les visualisations Filebeat suivantes : Journaux d\u0026rsquo;accès dans le temps et Codes de réponse dans le temps.\nMaintenant, filtrez par visualisations metricbeat nginx pour ajouter les visualisations Metricbeat suivantes : Taux de requêtes et Taux de lecture/écriture/attente.\nFermez la boîte de dialogue Ajouter à partir de la bibliothèque et enregistrez votre tableau de bord sous le nom de Filebeat x Metricbeat.\nVérifiez les différentes informations que vous pouvez obtenir à partir des journaux et des métriques de NGINX dans le tableau de bord que vous venez de créer.\nNotez que vous pouvez utiliser les données de Filebeat et de Metricbeat pour vérifier le nombre de requêtes par seconde, comme le montrent les visualisations Access logs over time et Request Rate. La version open source de NGINX ne fournit pas de métriques sur les codes de réponse, mais vous pouvez utiliser Filebeat pour obtenir ces informations à partir des journaux NGINX, comme vous pouvez le voir dans la visualisation des codes de réponse dans le temps. Avec les journaux NGINX, vous pouvez également vérifier l\u0026rsquo;emplacement, le système d\u0026rsquo;exploitation, le navigateur, la durée et de nombreuses autres informations sur les demandes. Cependant, les journaux NGINX ne vous disent pas combien de connexions ont été acceptées, traitées et abandonnées. Dans ce cas, vous pouvez utiliser Metricbeat pour collecter ces informations ainsi que le nombre de connexions actives et le nombre de connexions en lecture, écriture et attente, comme vous pouvez le voir dans la visualisation du taux de lecture / écriture / attente.\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez obtenir des mesures du système et de NGINX avec Metricbeat et les indexer dans Elasticsearch. Vous avez également exploré les tableaux de bord Kibana et vu avec quelle facilité vous pouvez surveiller ces mesures.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/","title":"Débutant","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/index_alias/","title":"Labs - Index et ALias","tags":[],"description":"","content":"Description Dans Elasticsearch, les données que nous indexons sont stockées dans un index. Le mot \u0026ldquo;index\u0026rdquo; est utilisé à la fois comme un verbe et un nom. Essentiellement, nous effectuons une opération d\u0026rsquo;indexation afin de stocker des données dans un index. Cependant, avant de pouvoir le faire, nous devons d\u0026rsquo;abord comprendre la structure d\u0026rsquo;un index et comment en définir un pour répondre à des besoins spécifiques. Dans ce laboratoire pratique, vous allez définir des index Elasticsearch en effectuant les tâches suivantes :\n Configurer le nombre de shards primaires d\u0026rsquo;un index. Configurer le nombre de tiroirs de réplique d\u0026rsquo;un index. Attribuer les tiroirs d\u0026rsquo;un index aux nœuds chauds. Allouer les tessons d\u0026rsquo;un index aux nœuds chauds. Associer des index avec des alias.  Vous travaillez en tant qu\u0026rsquo;administrateur système pour une entreprise qui souhaite utiliser Elasticsearch avec Kibana pour stocker et analyser certaines données de journal. On vous demande de préparer le cluster Elasticsearch pour les données de journal en créant quelques index. Les journaux sont considérés comme des données chronologiques, et nous nous intéressons généralement aux journaux les plus récents. Nous devons nous assurer que les données dont nous nous soucions le plus sont allouées à nos nœuds les plus rapides, ou \u0026ldquo;chauds\u0026rdquo;. Les données dont nous nous soucions moins peuvent être attribuées à des nœuds \u0026ldquo;chauds\u0026rdquo; plus lents, qui ne seront pas indexés ou recherchés aussi souvent. Nous devons également être en mesure de rechercher les données en utilisant des alias tels que \u0026ldquo;this_week\u0026rdquo;, \u0026ldquo;yesterday\u0026rdquo; ou \u0026ldquo;today\u0026rdquo;. Les alias facilitent la recherche des données qui vous intéressent car vous n\u0026rsquo;avez pas besoin de connaître les noms d\u0026rsquo;index spécifiques.\nVous disposez d\u0026rsquo;un cluster Elasticsearch préconfiguré à 6 nœuds avec Kibana déjà configuré et en cours d\u0026rsquo;exécution sur le nœud coordinator-1. Vous devrez utiliser l\u0026rsquo;outil de console de Kibana pour interagir avec les API d\u0026rsquo;Elasticsearch afin de créer les index suivants :\n   Name Aliases Primaries Replicas Allocation     tuto-logs-2020-01-05 logs / this_week 2 1 warm   tuto-logs-2020-01-06 logs / this_week 2 1 warm   tuto-logs-2020-01-07 logs / this_week 2 1 warm   tuto-logs-2020-01-05 logs / this_week 2 1 warm   tuto-logs-2020-01-05 logs / this_week 2 1 warm   tuto-logs-2020-01-05 logs / this_week / yesterday 2 1 hot   tuto-logs-2020-01-05 logs / this_week / today 2 1 hot    Création des index Utilisez l\u0026rsquo;outil de console Kibana pour exécuter ce qui suit :\nCréer l\u0026rsquo;index tuto-logs-2020-01-05 PUT tuto-logs-2020-01-05 { \u0026#34;aliases\u0026#34;: { \u0026#34;logs\u0026#34;: {}, \u0026#34;this_week\u0026#34;: {} }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 2, \u0026#34;number_of_replicas\u0026#34;: 1, \u0026#34;index.routing.allocation.require.temp\u0026#34;: \u0026#34;warm\u0026#34; } } Créer l\u0026rsquo;index tuto-logs-2020-01-06 PUT tuto-logs-2020-01-06 { \u0026#34;aliases\u0026#34;: { \u0026#34;logs\u0026#34;: {}, \u0026#34;this_week\u0026#34;: {} }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 2, \u0026#34;number_of_replicas\u0026#34;: 1, \u0026#34;index.routing.allocation.require.temp\u0026#34;: \u0026#34;warm\u0026#34; } } Créer l\u0026rsquo;index tuto-logs-2020-01-07 PUT tuto-logs-2020-01-07 { \u0026#34;aliases\u0026#34;: { \u0026#34;logs\u0026#34;: {}, \u0026#34;this_week\u0026#34;: {} }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 2, \u0026#34;number_of_replicas\u0026#34;: 1, \u0026#34;index.routing.allocation.require.temp\u0026#34;: \u0026#34;warm\u0026#34; } } Créer l\u0026rsquo;index tuto-logs-2020-01-08 PUT tuto-logs-2020-01-08 { \u0026#34;aliases\u0026#34;: { \u0026#34;logs\u0026#34;: {}, \u0026#34;this_week\u0026#34;: {} }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 2, \u0026#34;number_of_replicas\u0026#34;: 1, \u0026#34;index.routing.allocation.require.temp\u0026#34;: \u0026#34;warm\u0026#34; } } Créer l\u0026rsquo;index tuto-logs-2020-01-09 PUT tuto-logs-2020-01-09 { \u0026#34;aliases\u0026#34;: { \u0026#34;logs\u0026#34;: {}, \u0026#34;this_week\u0026#34;: {} }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 2, \u0026#34;number_of_replicas\u0026#34;: 1, \u0026#34;index.routing.allocation.require.temp\u0026#34;: \u0026#34;warm\u0026#34; } } Créer l\u0026rsquo;index tuto-logs-2020-01-10 PUT tuto-logs-2020-01-10 { \u0026#34;aliases\u0026#34;: { \u0026#34;logs\u0026#34;: {}, \u0026#34;this_week\u0026#34;: {}, \u0026#34;yesterday\u0026#34;: {} }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 2, \u0026#34;number_of_replicas\u0026#34;: 1, \u0026#34;index.routing.allocation.require.temp\u0026#34;: \u0026#34;hot\u0026#34; } } A vous de jouez ! Créer l\u0026rsquo;index tuto-logs-2020-01-11 A vous de me fournir la configuration de l\u0026rsquo;index correspondant aux informations dans le tableau.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/avance/sort/","title":"Labs - Query niveau II","tags":[],"description":"","content":"Préparation PUT /shakespeare { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;speaker\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;play_name\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;line_id\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, \u0026#34;speech_number\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;} } } } curl -H \u0026#39;Content-Type: application/x-ndjson\u0026#39; -XPOST \u0026#39;localhost:9200/bank/account/_bulk?pretty\u0026#39; --data-binary @accounts.json curl -H \u0026#39;Content-Type: application/x-ndjson\u0026#39; -XPOST \u0026#39;localhost:9200/shakespeare/doc/_bulk?pretty\u0026#39; --data-binary @shakespeare_6.0.json GET _cat/nodes?v GET _cat/indices?v Sort Permet d\u0026rsquo;ajouter un ou plusieurs tris sur des champs spécifiques. Chaque tri peut également être inversé. Le tri est défini au niveau de chaque champ, avec un nom de champ spécial pour _score pour trier par score, et _doc pour trier par ordre d\u0026rsquo;index.\nTri ascendant GET bank/_search { \u0026#34;sort\u0026#34;: [ { \u0026#34;account_number\u0026#34;: { \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34; } } ] } Tri ascendant descendant GET bank/_search { \u0026#34;sort\u0026#34;: [ { \u0026#34;account_number\u0026#34;: { \u0026#34;order\u0026#34;: \u0026#34;desc\u0026#34; } } ] } Tri descendant GET bank/_search { \u0026#34;sort\u0026#34;: [ { \u0026#34;age\u0026#34;: { \u0026#34;order\u0026#34;: \u0026#34;desc\u0026#34; } } ] } Plusieurs tri descendant GET bank/_search { \u0026#34;sort\u0026#34;: [ { \u0026#34;age\u0026#34;: { \u0026#34;order\u0026#34;: \u0026#34;desc\u0026#34; } }, { \u0026#34;balance\u0026#34;: { \u0026#34;order\u0026#34;: \u0026#34;desc\u0026#34; } } ] } Tri ascendant GET bank/_search { \u0026#34;sort\u0026#34;: [ { \u0026#34;firstname.keyword\u0026#34;: { \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34; } } ] } "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_apm/","title":"Lab - APM","tags":[],"description":"","content":"Serveur APM Objectif : Dans ce laboratoire, vous apprendrez comment il est facile d\u0026rsquo;utiliser APM pour instrumenter les applications afin de collecter des informations détaillées sur les performances ainsi que les erreurs et les envoyer à votre déploiement Elasticsearch. Vous explorerez également l\u0026rsquo;application APM Kibana et verrez avec quelle facilité vous pouvez surveiller les performances des applications.\nAjoutez le service APM ci-dessous dans le fichier elastic-docker-tls.yml :\n apm-server:\rimage: docker.elastic.co/apm/apm-server:${VERSION}\rcontainer_name: apm-server\rdepends_on:\res01: { condition: service_healthy }\rkib01: { condition: service_healthy }\rcap_add: [\u0026#34;CHOWN\u0026#34;, \u0026#34;DAC_OVERRIDE\u0026#34;, \u0026#34;SETGID\u0026#34;, \u0026#34;SETUID\u0026#34;]\rcap_drop: [\u0026#34;ALL\u0026#34;]\rports:\r- 8200:8200\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rcommand: \u0026gt;\rapm-server -e\r-E apm-server.rum.enabled=true\r-E setup.kibana.host=kib01:5601\r-E setup.template.settings.index.number_of_replicas=1\r-E apm-server.kibana.enabled=true\r-E apm-server.kibana.host=kib01:5601\r-E apm-server.kibana.protocol=https\r-E apm-server.kibana.username=$USER_ELASTIC\r-E apm-server.kibana.password=$PASSWORD_ELASTIC\r-E apm-server.kibana.ssl.enabled=true\r-E apm-server.kibana.ssl.certificate_authorities=[\u0026#34;$CERTS_DIR/ca/ca.crt\u0026#34;]\r-E output.elasticsearch.hosts=[\u0026#34;https://es01:9200\u0026#34;]\r-E output.elasticsearch.username=$USER_ELASTIC\r-E output.elasticsearch.password=$PASSWORD_ELASTIC\r-E output.elasticsearch.ssl.certificate_authorities=[\u0026#34;$CERTS_DIR/ca/ca.crt\u0026#34;]\rhealthcheck:\rinterval: 10s\rretries: 12\rtest: curl --write-out \u0026#39;HTTP %{http_code}\u0026#39; --fail --silent --output /dev/null http://localhost:8200/ docker-compose -f elastic-docker-tls.yml up -d L\u0026rsquo;application Petclinic contient des variables d\u0026rsquo;environnement pour contacter le serveur APM :\n petclinic:\rimage: docker.io/michaelhyatt/elastic-k8s-o11y-workshop-petclinic:1.25.0\rcontainer_name: petclinic\rlabels:\r\u0026#34;co.elastic.metrics/module\u0026#34;: \u0026#34;prometheus\u0026#34;\r\u0026#34;co.elastic.metrics/hosts\u0026#34;: \u0026#34;$${data.host}:$${data.port}\u0026#34;\r\u0026#34;co.elastic.metrics/metrics_path\u0026#34;: \u0026#34;/metrics/prometheus\u0026#34;\r\u0026#34;co.elastic.metrics/period\u0026#34;: \u0026#34;1m\u0026#34;\renvironment:\rELASTIC_APM_SERVER_URLS: \u0026#34;http://apm-server:8200\u0026#34;\rELASTIC_APM_SERVER_URLS_FOR_RUM: \u0026#34;http://localhost:8200\u0026#34;\rELASTIC_APM_SECRET_TOKEN: \u0026#34;\u0026#34;\rELASTIC_APM_SERVICE_NAME: \u0026#34;spring-petclinic-monolith\u0026#34;\rELASTIC_APM_APPLICATION_PACKAGES: \u0026#34;org.springframework.samples\u0026#34;\rELASTIC_APM_ENABLE_LOG_CORRELATION: \u0026#34;true\u0026#34;\rELASTIC_APM_CAPTURE_JMX_METRICS: \u0026gt;\robject_name[java.lang:type=GarbageCollector,name=*] attribute[CollectionCount:metric_name=collection_count] attribute[CollectionTime:metric_name=collection_time],\robject_name[java.lang:type=Memory] attribute[HeapMemoryUsage:metric_name=heap] Ces variables d\u0026rsquo;environnent font des références aux agents APM installés dans le code de l\u0026rsquo;application.\nMaintenant que les trois microservices sont en cours d\u0026rsquo;exécution, accédez à la page Web de Petclinic et vous devriez voir la page d\u0026rsquo;accueil suivante :\nCliquez sur FIND OWNERS et VETERINARIANS pour générer des données de performance à envoyer au serveur APM.\nCliquez sur ERROR pour générer des erreurs qui seront envoyées au serveur APM. Assurez-vous que vous obtenez le statut 404 et le message d\u0026rsquo;erreur No message available comme suit :\nSi vous n\u0026rsquo;obtenez pas cette erreur, cliquez sur HOME et cliquez à nouveau sur ERROR jusqu\u0026rsquo;à ce que vous obteniez cette erreur.\nLancez l\u0026rsquo;application APM pour commencer à explorer les données collectées.\nAprès avoir lancé l\u0026rsquo;application APM, vous accédez à l\u0026rsquo;aperçu des services.\nCliquez sur Détails du service pour explorer la santé globale du front-end en vérifiant les métriques sur les transactions, les erreurs et l\u0026rsquo;infrastructure.\nEnsuite, cliquez sur l\u0026rsquo;aperçu des transactions et sélectionnez le type de transaction http-request pour explorer les requêtes du frontend.\nEnsuite, cliquez sur GET /api/vets pour explorer le traçage distribué et voir comment les applications et les services interagissent entre eux.\nEnsuite, cliquez sur l\u0026rsquo;aperçu des erreurs pour explorer les erreurs de l\u0026rsquo;application.\nEnsuite, cliquez sur l\u0026rsquo;erreur \u0026ldquo;Aucun message disponible\u0026rdquo; pour voir la trace de la pile qui indique l\u0026rsquo;origine de l\u0026rsquo;erreur.\nEnfin, cliquez sur la transaction GET /api/error pour voir les erreurs associées et comment elles se sont propagées parmi les services.\nRésumé : Dans ce laboratoire, vous avez appris comment il est facile de configurer des agents APM pour collecter des informations de trace et des erreurs afin de les indexer dans Elasticsearch. Vous avez également exploré l\u0026rsquo;application APM Kibana et vu avec quelle facilité vous pouvez surveiller les performances des applications.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/backup/","title":"Lab - Backup &amp; Restore","tags":[],"description":"","content":"La haute disponibilité et la redondance d\u0026rsquo;Elasticsearch en font une plateforme stable et fiable pour le stockage de quantités massives de données. Toutefois, pour vous protéger contre les erreurs humaines et les catastrophes naturelles, vous devez toujours sauvegarder vos données Elasticsearch. L\u0026rsquo;endroit où vous stockez vos sauvegardes de données Elasticsearch est entièrement à votre discrétion. Dans ce laboratoire pratique, nous utiliserons le système de fichiers local pour démontrer comment :\n Créer des dépôts instantanés Sauvegarder des index spécifiques Restaurer des données à partir d\u0026rsquo;un instantané  Créez le référentiel \u0026ldquo;observability_repo\u0026rdquo;. Utilisez l\u0026rsquo;outil DevTool Kibana pour exécuter ce qui suit :\nPUT _snapshot/observability_repo?verify=false\r{\r\u0026#34;type\u0026#34;: \u0026#34;fs\u0026#34;,\r\u0026#34;settings\u0026#34;: {\r\u0026#34;location\u0026#34;: \u0026#34;/usr/share/elasticsearch/snapshots/\u0026#34;\r}\r} Sauvegarde de l\u0026rsquo;index \u0026ldquo;observability-time-series\u0026rdquo; Utilisez l\u0026rsquo;outil de console Kibana pour exécuter ce qui suit :\nPUT _snapshot/observability_repo/observability?wait_for_completion=true\r{\r\u0026#34;indices\u0026#34;: \u0026#34;observability-time-series\u0026#34;,\r\u0026#34;include_global_state\u0026#34;: false\r} Restaurez l\u0026rsquo;index \u0026ldquo;observability-time-series\u0026rdquo; en tant que \u0026ldquo;observability-time-series_restored\u0026rdquo; Utilisez l\u0026rsquo;outil de console Kibana pour exécuter ce qui suit :\nPOST _snapshot/observability-time-series_repo/observability-time-series/_restore\r{\r\u0026#34;indices\u0026#34;: \u0026#34;observability-time-series\u0026#34;,\r\u0026#34;rename_pattern\u0026#34;: \u0026#34;(.+)\u0026#34;,\r\u0026#34;rename_replacement\u0026#34;: \u0026#34;$1_restored\u0026#34;\r} {\r\u0026#34;accepted\u0026#34; : true\r} GET _cat/indices green open metricbeat-7.17.0-2022.02.22-000001 WBLcTqYORtS5LJyFttVBXQ 1 1 22122 0 67.6mb 34.8mb\rgreen open apm-7.17.0-error-000001 TuCoez2IQP6xmRJl70TKvw 1 1 1842 0 4.7mb 2.3mb\ryellow open .ds-observability-time-series-2022.02.22-000002 xKbIQkulR0mMwv8aCbR5Og 1 10 1 0 12.3kb 4.1kb\ryellow open .ds-observability-time-series-2022.02.22-000001 i_sIi8P2SUu6mNmlsMjv3Q 1 10 16 0 19.4kb 6.5kb\rgreen open apm-7.17.0-transaction-000001 O14qvTcvQyOOIp8kIGGpKg 1 1 17027 0 25mb 11.1mb\rgreen open .apm-agent-configuration jkaqvfq0Sy25CHaLDswUUA 1 1 0 0 452b 226b\rgreen open apm-7.17.0-metric-000001 mXYNU6V9SU2tlAmODIjPHQ 1 1 4497 0 4.7mb 2.3mb\rgreen open apm-7.17.0-span-000001 iOVtWj8iRL6b-YbxROQ9ig 1 1 75766 0 44.5mb 19.8mb\rgreen open apm-7.17.0-onboarding-2022.02.22 dJ8FT0LvSn2HTUynoxWtbQ 1 1 1 0 16.1kb 8kb\rgreen open apm-7.17.0-profile-000001 dQEJ37KkSzmQr4DVKLQnAw 1 1 0 0 452b 226b\rgreen open filebeat-7.17.0-2022.02.22-000001 hN3UWBgXRYm9KA66iHfayQ 1 1 236916 0 279.3mb 138.5mb\rgreen open .ds-observability-time-series-2022.02.22-000001_restored _WQSy8o3QTi6l4inCqpA8Q 1 1 16 0 13.1kb 6.5kb\rgreen open .security-7 o2VUY0seRxSefLHyOge4rQ 1 1 60 0 531.1kb 295.6kb\rgreen open .kibana_7.17.0_001 J_lf9M3zRjmHgMdRhwcqLw 1 1 4424 328 8.1mb 4mb\rgreen open .apm-custom-link fnAtCfqXSsOCN7dqyGQT8A 1 1 0 0 452b 226b\rgreen open .ds-observability-time-series-2022.02.22-000002_restored SUVTggxqRMODlSz4pE3gEw 1 1 1 0 8.3kb 4.1kb\rgreen open heartbeat-7.17.0-2022.02.22-000001 U50p8dOMSz2jhWz7kHRDnw 1 1 648 0 2.6mb 1.3mb\rgreen open .async-search JjeGtgVgTYKlJ8PsvmwL7Q 1 1 0 0 6.9kb 3.4kb\rgreen open .kibana_task_manager_7.17.0_001 x63yGuhDSaudkMeqtmxANA 1 1 18 1122 753.7kb 368.6kb SLM Policy La gestion du cycle de vie des instantanés (SLM) est le moyen le plus simple de sauvegarder régulièrement un cluster. Une politique SLM prend automatiquement des instantanés selon une planification prédéfinie. La politique peut également supprimer les instantanés en fonction des règles de rétention que vous définissez.\nPUT _slm/policy/daily-observability-snpashots\r{\r\u0026#34;name\u0026#34;: \u0026#34;\u0026lt;observability-{now/d}\u0026gt;\u0026#34;,\r\u0026#34;schedule\u0026#34;: \u0026#34;0 30 1 * * ?\u0026#34;,\r\u0026#34;repository\u0026#34;: \u0026#34;observability_repo\u0026#34;,\r\u0026#34;config\u0026#34;: {\r\u0026#34;indices\u0026#34;: [\r\u0026#34;observability-time-series\u0026#34;\r]\r},\r\u0026#34;retention\u0026#34;: {\r\u0026#34;expire_after\u0026#34;: \u0026#34;30d\u0026#34;,\r\u0026#34;min_count\u0026#34;: 15,\r\u0026#34;max_count\u0026#34;: 30\r}\r} GET _slm/policy/daily-observability-snpashots {\r\u0026#34;daily-observability-snpashots\u0026#34; : {\r\u0026#34;version\u0026#34; : 1,\r\u0026#34;modified_date_millis\u0026#34; : 1645547161680,\r\u0026#34;policy\u0026#34; : {\r\u0026#34;name\u0026#34; : \u0026#34;\u0026lt;observability-{now/d}\u0026gt;\u0026#34;,\r\u0026#34;schedule\u0026#34; : \u0026#34;0 30 1 * * ?\u0026#34;,\r\u0026#34;repository\u0026#34; : \u0026#34;observability_repo\u0026#34;,\r\u0026#34;config\u0026#34; : {\r\u0026#34;indices\u0026#34; : [\r\u0026#34;observability-time-series\u0026#34;\r]\r},\r\u0026#34;retention\u0026#34; : {\r\u0026#34;expire_after\u0026#34; : \u0026#34;30d\u0026#34;,\r\u0026#34;min_count\u0026#34; : 15,\r\u0026#34;max_count\u0026#34; : 30\r}\r},\r\u0026#34;next_execution_millis\u0026#34; : 1645579800000,\r\u0026#34;stats\u0026#34; : {\r\u0026#34;policy\u0026#34; : \u0026#34;daily-observability-snpashots\u0026#34;,\r\u0026#34;snapshots_taken\u0026#34; : 0,\r\u0026#34;snapshots_failed\u0026#34; : 0,\r\u0026#34;snapshots_deleted\u0026#34; : 0,\r\u0026#34;snapshot_deletion_failures\u0026#34; : 0\r}\r}\r} "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/mapping/","title":"Labs - Mapping","tags":[],"description":"","content":"Description Les modèles dynamiques dans Elasticsearch permettent d\u0026rsquo;indexer très facilement les données sans avoir à créer des mappages explicites pour chaque champ. Cependant, il peut arriver que vous préfériez créer des mappages explicites, ou même désactiver complètement le mappage dynamique, afin d\u0026rsquo;avoir un contrôle plus étroit de la structure de votre index et des exigences en matière de type de données. Dans cette activité d\u0026rsquo;apprentissage, vous avez l\u0026rsquo;occasion de créer des mappages de champ explicites pour un index contenant des données de journal. Plus précisément, vous allez vous exercer à\n Créer des champs de chaîne de caractères analysés avec un analyseur spécifique. Créer des champs de chaîne de caractères non analysés avec des limites de caractères Créer des mappages de champs geo_point Créer des mappages de champs numériques Créer des mappages de champs de date Créer des mappages de champs IP Créer des mappages de champs d\u0026rsquo;imbrication (objets) Réindexer des données d\u0026rsquo;un index dans un autre avec des mappings différents.  Vous travaillez en tant qu\u0026rsquo;administrateur Elasticsearch pour un cluster à 6 nœuds et vous êtes chargé de corriger certains mappages de champs pour un index contenant des données de journal. Les données de journal actuelles ont été ingérées sans aucune préparation et la plupart des champs créés ne sont pas du type souhaité. L\u0026rsquo;index logs existant devra être réindexé dans un nouvel index appelé tuto-logs_new. Vous êtes chargé de créer l\u0026rsquo;index tuto-logs_new avec les exigences de mappage suivantes :\n   Field Datatype Character Limit Analyzer     @message text  standard   @tags keyword 128    @timestamp date     @version keyword 256    agent text  standard   agent.keyword keyword 256    bytes long     clientip ip     extension keyword 256    geo.coordinates geo_point     geo.dest keyword 128    geo.src keyword 128    geo.srcdest keyword 128    headings keyword 256    host keyword 256    ip ip     links keyword 256    machine.os keyword 256    machine.ram long     memory long     phpmemory long     referer keyword 256    relatedContent.article:modified_time date     relatedContent.article:published_time date     relatedContent.article:section keyword 128    relatedContent.article:tag keyword 128    relatedContent.og:description text  standard   relatedContent.og:image keyword 256    relatedContent.og:image:height long     relatedContent.og:image:height long     relatedContent.og:site_name keyword 256    relatedContent.og:title text  standard   relatedContent.og:title.keyword keyword 256    relatedContent.og:type keyword 128    relatedContent.og:url text  simple   relatedContent.og:url.keyword keyword 256    relatedContent.twitter:card keyword 128    relatedContent.twitter:description text  standard   relatedContent.twitter:image keyword 256    relatedContent.twitter:site keyword 128    relatedContent.twitter:title text  standard   relatedContent.twitter:title.keyword keyword 128    relatedContent.twitter:title.keyword keyword 128    relatedContent.url.keyword keyword 256    request text  simple   request.keyword keyword 256    response keyword 128    response keyword 128    spaces text  whitespace   url text  simple   url.keyword keyword 256    utc_time date     xss text  standard   xss.keyword keyword 512     L\u0026rsquo;index tuto-logs_new doit conserver les mêmes paramètres d\u0026rsquo;index que l\u0026rsquo;index logs pour le nombre de shards primaires et de replica. Une fois que l\u0026rsquo;index tuto-logs_new a été créé, vous pouvez réindexer les documents dans le nouvel index.\ncurl --location --request POST \u0026#39;https://localhost:9200/tuto-logs/doc/_bulk?pretty\u0026#39; \\ --header \u0026#39;Content-Type: application/x-ndjson\u0026#39; \\ --header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\ --data-binary @logs.json PUT tuto-logs_new { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;@message\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;@tags\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 }, \u0026#34;@timestamp\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, \u0026#34;@version\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;agent\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 } } }, \u0026#34;bytes\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, \u0026#34;clientip\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;ip\u0026#34; }, \u0026#34;extension\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;geo\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;coordinates\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;geo_point\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 }, \u0026#34;src\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 }, \u0026#34;srcdest\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 } } }, \u0026#34;headings\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;host\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;ip\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;ip\u0026#34; }, \u0026#34;links\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;machine\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;os\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;ram\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; } } }, \u0026#34;memory\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, \u0026#34;phpmemory\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, \u0026#34;referer\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;relatedContent\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;article:modified_time\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, \u0026#34;article:published_time\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, \u0026#34;article:section\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 }, \u0026#34;article:tag\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 }, \u0026#34;og:description\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;og:image\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;og:image:height\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, \u0026#34;og:image:width\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, \u0026#34;og:site_name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;og:title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 } } }, \u0026#34;og:type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 }, \u0026#34;og:url\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;simple\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 } } }, \u0026#34;twitter:card\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 }, \u0026#34;twitter:description\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;twitter:image\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 }, \u0026#34;twitter:site\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 }, \u0026#34;twitter:title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 } } }, \u0026#34;url\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;simple\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 } } } } }, \u0026#34;request\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;simple\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 } } }, \u0026#34;response\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 128 }, \u0026#34;spaces\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;whitespace\u0026#34; }, \u0026#34;url\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;simple\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 } } }, \u0026#34;utc_time\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, \u0026#34;xss\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 512 } } } } }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 4, \u0026#34;number_of_replicas\u0026#34;: 3 } } POST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;tuto-logs\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;tuto-logs_new\u0026#34; } } "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/avance/query/","title":"Labs - Query niveau III","tags":[],"description":"","content":"Préparation PUT /shakespeare { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;speaker\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;play_name\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;line_id\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, \u0026#34;speech_number\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;} } } } curl -H \u0026#39;Content-Type: application/x-ndjson\u0026#39; -XPOST \u0026#39;localhost:9200/bank/account/_bulk?pretty\u0026#39; --data-binary @accounts.json curl -H \u0026#39;Content-Type: application/x-ndjson\u0026#39; -XPOST \u0026#39;localhost:9200/shakespeare/doc/_bulk?pretty\u0026#39; --data-binary @shakespeare_6.0.json GET _cat/nodes?v GET _cat/indices?v API Search ### Recherche un terms via un boolean GET _search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;gender.keyword\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;F\u0026#34; } } } ] } } } Recherche un terms via un boolean et ne pas recherche un term dans les résultats GET _search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;gender.keyword\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;F\u0026#34; } } } ], \u0026#34;must_not\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;state.keyword\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;RI\u0026#34; } } } ] } } } Recherche un terms via un boolean, ne pas rechercher un term dans les résultats et de rechercher des résultats avec au moins un des terms GET _search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;gender.keyword\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;F\u0026#34; } } } ], \u0026#34;must_not\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;state.keyword\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;RI\u0026#34; } } } ], \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;lastname.keyword\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;Meyers\u0026#34; } } }, { \u0026#34;term\u0026#34;: { \u0026#34;lastname.keyword\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;Owens\u0026#34; } } } ], \u0026#34;minimum_should_match\u0026#34;: 1 } } } Recherche un terms via un boolean, ne pas rechercher un term dans les résultats, de rechercher des résultats avec au moins un des terms et un filtre sur la ville GET _search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;gender.keyword\u0026#34;: { \u0026#34;_name\u0026#34;: \u0026#34;gender\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;F\u0026#34; } } } ], \u0026#34;must_not\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;state.keyword\u0026#34;: { \u0026#34;_name\u0026#34;: \u0026#34;state\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;RI\u0026#34; } } } ], \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;lastname.keyword\u0026#34;: { \u0026#34;_name\u0026#34;: \u0026#34;lastname_1\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;Meyers\u0026#34; } } }, { \u0026#34;term\u0026#34;: { \u0026#34;lastname.keyword\u0026#34;: { \u0026#34;_name\u0026#34;: \u0026#34;lastname_2\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;Owens\u0026#34; } } } ], \u0026#34;minimum_should_match\u0026#34;: 1, \u0026#34;filter\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;city.keyword\u0026#34;: \u0026#34;Jacksonburg\u0026#34; } } } } } Meme requete qu\u0026rsquo;au dessus avec le meme score GET _search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;gender.keyword\u0026#34;: { \u0026#34;_name\u0026#34;: \u0026#34;gender\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;F\u0026#34; } } } ], \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;lastname.keyword\u0026#34;: { \u0026#34;_name\u0026#34;: \u0026#34;lastname_1\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;Meyers\u0026#34; } } } ], \u0026#34;minimum_should_match\u0026#34;: 1, \u0026#34;filter\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;city.keyword\u0026#34;: \u0026#34;Jacksonburg\u0026#34; } } } } } "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/template_mapping/","title":"Labs - Index Template et Mapping","tags":[],"description":"","content":"Description L\u0026rsquo;une des fonctionnalités les plus conviviales d\u0026rsquo;Elasticsearch est le mappage dynamique. Le mappage dynamique est le mécanisme utilisé par Elasticsearch pour détecter les champs et les mettre en correspondance avec un type de données approprié. À l\u0026rsquo;aide de modèles d\u0026rsquo;index, nous pouvons définir la structure d\u0026rsquo;une série d\u0026rsquo;index pour répondre à des exigences spécifiques ou remplacer et contrôler le comportement du mappage dynamique. Avec le mappage dynamique, nous pouvons sauter le processus de définition explicite de chaque champ possible et de son type de données et indiquer à Elasticsearch comment détecter les types de données souhaités au fur et à mesure qu\u0026rsquo;ils sont découverts pendant l\u0026rsquo;indexation. En conséquence, le mappage dynamique nous permet d\u0026rsquo;être opérationnel très rapidement avec nos données. Dans ce laboratoire pratique, vous allez effectuer les tâches suivantes :\n Créer un modèle d\u0026rsquo;index Définir des mappages de champs explicites Définir des mappages de champs dynamiques  Vous travaillez en tant qu\u0026rsquo;administrateur Elasticsearch pour une société d\u0026rsquo;analyse de données qui souhaite utiliser votre cluster Elasticsearch existant à 6 nœuds pour analyser quelques ensembles de données. Pour faciliter l\u0026rsquo;indexation de chaque ensemble de données, vous devez configurer les modèles d\u0026rsquo;index nécessaires afin que les données soient stockées dans Elasticsearch avec les mappages corrects. Chaque modèle doit avoir 4 shards primaires et 3 shards répliques pour une réplication maximale sur les 4 nœuds de données. Les mappages des modèles requis sont décrits ci-dessous :\n   Name Index Pattern Aliases Explicit Mapping Dynamic Mapping     customers customers-* customers field: year_to_date / type: double name: long_to_integer / match mapping: long / mapping: integers   partners partners-* partners field: address / type: text name: string_to_keyword / match mapping: string / mapping: keyword   leads leads-* leads field: address / type: text ; field: estimate / type: double name: string_to_keyword / match mapping: string / match: lead_* / unmatch: *_text / mapping: keyword    Créer customers Index Template Utilisez l\u0026rsquo;outil de console Kibana pour exécuter ce qui suit :\nPUT _template/customers { \u0026#34;aliases\u0026#34;: { \u0026#34;customers\u0026#34;: {} }, \u0026#34;index_patterns\u0026#34;: [\u0026#34;customers-*\u0026#34;], \u0026#34;mappings\u0026#34;: { \u0026#34;dynamic_templates\u0026#34;: [ { \u0026#34;long_to_integer\u0026#34;: { \u0026#34;match_mapping_type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; } } } ], \u0026#34;properties\u0026#34;: { \u0026#34;year_to_date\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; } } }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 4, \u0026#34;number_of_replicas\u0026#34;: 3 } } Créer partners Index Template PUT _template/partners { \u0026#34;aliases\u0026#34;: { \u0026#34;partners\u0026#34;: {} }, \u0026#34;index_patterns\u0026#34;: [\u0026#34;partners-*\u0026#34;], \u0026#34;mappings\u0026#34;: { \u0026#34;dynamic_templates\u0026#34;: [ { \u0026#34;string_to_keyword\u0026#34;: { \u0026#34;match_mapping_type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } ], \u0026#34;properties\u0026#34;: { \u0026#34;address\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; } } }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 4, \u0026#34;number_of_replicas\u0026#34;: 3 } } A vous de jouez ! Créer leads Index Template A vous de me fournir le template correspondant aux informations dans le tableau.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/diagnostic/","title":"Lab - Diagnostic","tags":[],"description":"","content":"Vous êtes le nouvel administrateur d\u0026rsquo;un cluster Elasticsearch à 3 nœuds. En prenant possession du cluster, vous constatez que plusieurs index sont dans un état jaune. Vos supérieurs vous demandent de donner la priorité au dépannage des problèmes d\u0026rsquo;allocation d\u0026rsquo;index avant toute autre tâche.\nLorsqu\u0026rsquo;ils sont configurés correctement, les clusters Elasticsearch sont hautement disponibles et tolérants aux pannes. Cela ne signifie pas nécessairement qu\u0026rsquo;ils sont imperméables aux pannes. L\u0026rsquo;erreur humaine et la défaillance matérielle sont toujours possibles. Le dépannage des problèmes de disponibilité des données sur un système distribué peut être un défi. Prenons le temps de démystifier certaines routines de dépannage de base lorsque vous remarquez des index jaunes dans votre cluster Elasticsearch. Dans ce laboratoire pratique, vous aurez l\u0026rsquo;occasion de :\n Utiliser les API _cat pour obtenir rapidement des informations vitales sur votre cluster. utiliser l\u0026rsquo;API _cluster/allocation/explain pour découvrir pourquoi un index est ou n\u0026rsquo;est pas alloué Utiliser l\u0026rsquo;API _settings pour mettre rapidement à jour les paramètres d\u0026rsquo;index.  Résolution du problème de l\u0026rsquo;index \u0026ldquo;observability-time-series\u0026rdquo;. Utilisez l\u0026rsquo;outil de console Kibana pour exécuter ce qui suit :\nGET _cat/indices?v health status index uuid pri rep docs.count docs.deleted store.size pri.store.size\rgreen open metricbeat-7.17.0-2022.02.22-000001 WBLcTqYORtS5LJyFttVBXQ 1 1 956609 0 1.8gb 915.3mb\rgreen open apm-7.17.0-error-000001 TuCoez2IQP6xmRJl70TKvw 1 1 4994 0 19.9mb 9.9mb\ryellow open .ds-observability-time-series-2022.02.22-000002 xKbIQkulR0mMwv8aCbR5Og 1 10 1 0 12.5kb 4.1kb\ryellow open .ds-observability-time-series-2022.02.22-000001 i_sIi8P2SUu6mNmlsMjv3Q 1 10 16 0 19.6kb 6.5kb\rgreen open apm-7.17.0-transaction-000001 O14qvTcvQyOOIp8kIGGpKg 1 1 163280 0 130.7mb 62.3mb\rgreen open apm-7.17.0-metric-000001 mXYNU6V9SU2tlAmODIjPHQ 1 1 265903 0 73mb 36.4mb\rgreen open .apm-agent-configuration jkaqvfq0Sy25CHaLDswUUA 1 1 0 0 452b 226b\rgreen open apm-7.17.0-span-000001 iOVtWj8iRL6b-YbxROQ9ig 1 1 505334 0 377.8mb 153.4mb\rgreen open apm-7.17.0-onboarding-2022.02.22 dJ8FT0LvSn2HTUynoxWtbQ 1 1 1 0 16.1kb 8kb\rgreen open apm-7.17.0-profile-000001 dQEJ37KkSzmQr4DVKLQnAw 1 1 0 0 452b 226b\rgreen open .security-7 o2VUY0seRxSefLHyOge4rQ 1 1 60 0 531.1kb 295.6kb\rgreen open .ds-observability-time-series-2022.02.22-000001_restored _WQSy8o3QTi6l4inCqpA8Q 1 1 16 0 13.1kb 6.5kb\rgreen open filebeat-7.17.0-2022.02.22-000001 hN3UWBgXRYm9KA66iHfayQ 1 1 2453406 0 3.2gb 1.6gb\rgreen open .kibana_7.17.0_001 J_lf9M3zRjmHgMdRhwcqLw 1 1 4439 1913 8.3mb 4.1mb\rgreen open .apm-custom-link fnAtCfqXSsOCN7dqyGQT8A 1 1 0 0 452b 226b\rgreen open .ds-observability-time-series-2022.02.22-000002_restored SUVTggxqRMODlSz4pE3gEw 1 1 1 0 8.3kb 4.1kb\rgreen open heartbeat-7.17.0-2022.02.22-000001 U50p8dOMSz2jhWz7kHRDnw 1 1 25386 0 29.5mb 14.7mb\rgreen open .async-search JjeGtgVgTYKlJ8PsvmwL7Q 1 1 0 0 3.7kb 249b\rgreen open .kibana_task_manager_7.17.0_001 x63yGuhDSaudkMeqtmxANA 1 1 18 43080 15.2mb 7.6mb GET _cat/nodes?v ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name\r172.20.0.4 61 97 33 3.53 2.21 1.66 cdfhilmrstw * es01\r172.20.0.3 73 97 33 3.53 2.21 1.66 cdfhilmrstw - es03\r172.20.0.2 68 97 33 3.53 2.21 1.66 cdfhilmrstw - es02 GET _cluster/allocation/explain {\r\u0026#34;note\u0026#34; : \u0026#34;No shard was specified in the explain API request, so this response explains a randomly chosen unassigned shard. There may be other unassigned shards in this cluster which cannot be assigned for different reasons. It may not be possible to assign this shard until one of the other shards is assigned correctly. To explain the allocation of other shards (whether assigned or unassigned) you must specify the target shard in the request to this API.\u0026#34;,\r\u0026#34;index\u0026#34; : \u0026#34;.ds-observability-time-series-2022.02.22-000001\u0026#34;,\r\u0026#34;shard\u0026#34; : 0,\r\u0026#34;primary\u0026#34; : false,\r\u0026#34;current_state\u0026#34; : \u0026#34;unassigned\u0026#34;,\r\u0026#34;unassigned_info\u0026#34; : {\r\u0026#34;reason\u0026#34; : \u0026#34;INDEX_CREATED\u0026#34;,\r\u0026#34;at\u0026#34; : \u0026#34;2022-02-22T16:18:00.719Z\u0026#34;,\r\u0026#34;last_allocation_status\u0026#34; : \u0026#34;no_attempt\u0026#34;\r},\r\u0026#34;can_allocate\u0026#34; : \u0026#34;no\u0026#34;,\r\u0026#34;allocate_explanation\u0026#34; : \u0026#34;cannot allocate because allocation is not permitted to any of the nodes\u0026#34;,\r\u0026#34;node_allocation_decisions\u0026#34; : [\r{\r\u0026#34;node_id\u0026#34; : \u0026#34;8T5zcuSbRbugyhTN5hxzHQ\u0026#34;,\r\u0026#34;node_name\u0026#34; : \u0026#34;es02\u0026#34;,\r\u0026#34;transport_address\u0026#34; : \u0026#34;172.20.0.2:9300\u0026#34;,\r\u0026#34;node_attributes\u0026#34; : {\r\u0026#34;ml.machine_memory\u0026#34; : \u0026#34;8312127488\u0026#34;,\r\u0026#34;ml.max_open_jobs\u0026#34; : \u0026#34;512\u0026#34;,\r\u0026#34;xpack.installed\u0026#34; : \u0026#34;true\u0026#34;,\r\u0026#34;ml.max_jvm_size\u0026#34; : \u0026#34;268435456\u0026#34;,\r\u0026#34;transform.node\u0026#34; : \u0026#34;true\u0026#34;\r},\r\u0026#34;node_decision\u0026#34; : \u0026#34;no\u0026#34;,\r\u0026#34;weight_ranking\u0026#34; : 1,\r\u0026#34;deciders\u0026#34; : [\r{\r\u0026#34;decider\u0026#34; : \u0026#34;same_shard\u0026#34;,\r\u0026#34;decision\u0026#34; : \u0026#34;NO\u0026#34;,\r\u0026#34;explanation\u0026#34; : \u0026#34;a copy of this shard is already allocated to this node [[.ds-observability-time-series-2022.02.22-000001][0], node[8T5zcuSbRbugyhTN5hxzHQ], [R], s[STARTED], a[id=rj9XVRi9Te2vqQgIIwsb8Q]]\u0026#34;\r}\r]\r},\r{\r\u0026#34;node_id\u0026#34; : \u0026#34;QjZ5OxRQRxSGEq9fHq39ug\u0026#34;,\r\u0026#34;node_name\u0026#34; : \u0026#34;es01\u0026#34;,\r\u0026#34;transport_address\u0026#34; : \u0026#34;172.20.0.4:9300\u0026#34;,\r\u0026#34;node_attributes\u0026#34; : {\r\u0026#34;ml.machine_memory\u0026#34; : \u0026#34;8312127488\u0026#34;,\r\u0026#34;xpack.installed\u0026#34; : \u0026#34;true\u0026#34;,\r\u0026#34;transform.node\u0026#34; : \u0026#34;true\u0026#34;,\r\u0026#34;ml.max_open_jobs\u0026#34; : \u0026#34;512\u0026#34;,\r\u0026#34;ml.max_jvm_size\u0026#34; : \u0026#34;268435456\u0026#34;\r},\r\u0026#34;node_decision\u0026#34; : \u0026#34;no\u0026#34;,\r\u0026#34;weight_ranking\u0026#34; : 2,\r\u0026#34;deciders\u0026#34; : [\r{\r\u0026#34;decider\u0026#34; : \u0026#34;same_shard\u0026#34;,\r\u0026#34;decision\u0026#34; : \u0026#34;NO\u0026#34;,\r\u0026#34;explanation\u0026#34; : \u0026#34;a copy of this shard is already allocated to this node [[.ds-observability-time-series-2022.02.22-000001][0], node[QjZ5OxRQRxSGEq9fHq39ug], [R], s[STARTED], a[id=1Hb2K_nMTHqGP3LqlhDnjQ]]\u0026#34;\r}\r]\r},\r{\r\u0026#34;node_id\u0026#34; : \u0026#34;g9m0hRGUS1isZhC9CVdhgw\u0026#34;,\r\u0026#34;node_name\u0026#34; : \u0026#34;es03\u0026#34;,\r\u0026#34;transport_address\u0026#34; : \u0026#34;172.20.0.3:9300\u0026#34;,\r\u0026#34;node_attributes\u0026#34; : {\r\u0026#34;ml.machine_memory\u0026#34; : \u0026#34;8312127488\u0026#34;,\r\u0026#34;ml.max_open_jobs\u0026#34; : \u0026#34;512\u0026#34;,\r\u0026#34;xpack.installed\u0026#34; : \u0026#34;true\u0026#34;,\r\u0026#34;ml.max_jvm_size\u0026#34; : \u0026#34;268435456\u0026#34;,\r\u0026#34;transform.node\u0026#34; : \u0026#34;true\u0026#34;\r},\r\u0026#34;node_decision\u0026#34; : \u0026#34;no\u0026#34;,\r\u0026#34;weight_ranking\u0026#34; : 3,\r\u0026#34;deciders\u0026#34; : [\r{\r\u0026#34;decider\u0026#34; : \u0026#34;same_shard\u0026#34;,\r\u0026#34;decision\u0026#34; : \u0026#34;NO\u0026#34;,\r\u0026#34;explanation\u0026#34; : \u0026#34;a copy of this shard is already allocated to this node [[.ds-observability-time-series-2022.02.22-000001][0], node[g9m0hRGUS1isZhC9CVdhgw], [P], s[STARTED], a[id=iwUIWrc0S5SSE2R52VK8Mg]]\u0026#34;\r}\r]\r}\r]\r} A vous de jouez ! Expliquer le problème que rencontre le cluster Elasticsearch et la solution que vous proposez pour corriger ce comportement.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/d%C3%A9butant/lab_uptime/","title":"Lab - Uptime","tags":[],"description":"","content":"Objectif : Dans ce laboratoire, vous explorerez la facilité avec laquelle vous pouvez obtenir des métriques des disponibilités des services avec Heratbeat et les indexer dans Elasticsearch. Vous explorerez également les tableaux de bord Kibana et verrez avec quelle facilité vous pouvez surveiller ces métriques.\nDéployer un agent beats Ajoutez le service Heartbeat à la suite du service Beats\nvim beats/beats-docker.yml beats-docker.yml\nversion: \u0026#39;2.2\u0026#39;\rservices:\rfilebeat:\rimage: docker.elastic.co/beats/filebeat:${VERSION}\rcontainer_name: filebeat\rrestart: unless-stopped\rentrypoint: \u0026#34;filebeat -e -strict.perms=false\u0026#34;\ruser: root\rvolumes:\r- \u0026#34;./conf/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\u0026#34;\r- \u0026#34;/var/lib/docker/containers:/var/lib/docker/containers:ro\u0026#34;\r- \u0026#34;/var/run/docker.sock:/var/run/docker.sock:ro\u0026#34;\r- \u0026#34;/var/log:/tmp:ro\u0026#34;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rmetricbeat:\rimage: docker.elastic.co/beats/metricbeat:${VERSION}\rcontainer_name: metricbeat\rrestart: unless-stopped\rentrypoint: \u0026#34;metricbeat -e -strict.perms=false\u0026#34;\ruser: root\rvolumes:\r- \u0026#34;./conf/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro\u0026#34;\r- \u0026#34;/proc:/hostfs/proc:ro\u0026#34;\r- \u0026#34;/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\u0026#34;\r- \u0026#34;/:/hostfs:ro\u0026#34;\r- \u0026#34;/var/run/docker.sock:/var/run/docker.sock:ro\u0026#34;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rheartbeat:\rimage: docker.elastic.co/beats/heartbeat:${VERSION}\rcontainer_name: heartbeat\rrestart: unless-stopped\rentrypoint: \u0026#34;heartbeat -e -strict.perms=false\u0026#34;\ruser: heartbeat\rvolumes:\r- \u0026#34;./conf/heartbeat.yml:/usr/share/heartbeat/heartbeat.yml:ro\u0026#34;\r- \u0026#34;/var/run/docker.sock:/var/run/docker.socki:ro\u0026#34;\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rvolumes:\rcerts:\rdriver: local\rnetworks:\relastic:\rdriver: bridge vim beats/conf/heartbeat.yml heartbeat.monitors:\r- type: http\rid: nginx-service-status\rname: Nginx Status\rschedule: \u0026#39;@every 10s\u0026#39;\rurls:\r- http://nginx:8081\rtimeout: 30s\rcheck.response:\rstatus: 200\rbody:\r- \u0026#34;Welcome\u0026#34;\r- type: http\rid: petclinic-service-status\rname: Petclinic Status\rschedule: \u0026#39;@every 10s\u0026#39;\rurls:\r- http://petclinic:8080/metrics/prometheus\rtimeout: 30s\rcheck.response:\rstatus: 200\rbody:\r- \u0026#34;jvm_memory_committed_bytes\u0026#34;\r- type: tcp\rid: mysql-service-status\rname: MySQL Status\rschedule: \u0026#39;@every 10s\u0026#39;\rhosts: [\u0026#34;tcp://mysql:3306\u0026#34;]\rprocessors:\r- add_cloud_metadata: ~\r- add_docker_metadata: ~\routput.elasticsearch:\rhosts: \u0026#39;https://es01:9200\u0026#39;\rusername: \u0026#34;elastic\u0026#34;\rpassword: \u0026#34;CHANGEME\u0026#34;\rssl.certificate_authorities: [\u0026#34;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026#34;] Changer la valeur du champs password avec la valeur du mot de passe générer automatiquement.\ndocker-compose -f beats/beats-docker.yml up -d vim app/artificial_load.sh #!/bin/bash\rCOUNTER=0\rwhile [ $COUNTER -lt 10000 ] ;\rdo\rcurl -s --header \u0026#34;X-Forwarded-For: 5.198.223.255\u0026#34; localhost \u0026gt; /dev/null\rcurl -s localhost/owners/find \u0026gt; /dev/null\rcurl -s localhost/owners?lastName= \u0026gt; /dev/null\rcurl -s localhost/owners/1 \u0026gt; /dev/null\rcurl -s localhost/owners/4 \u0026gt; /dev/null\rcurl -s localhost/owners/6 \u0026gt; /dev/null\rcurl -s localhost/owners/8 \u0026gt; /dev/null\rcurl -s localhost/vets.html \u0026gt; /dev/null\rcurl -s localhost/oups \u0026gt; /dev/null\rlet COUNTER=COUNTER+1\rdone chmod +x app/artificial_load.sh Maintenant, ouvrez une nouvelle fenêtre de terminal et exécutez le script suivant pour simuler la charge sur votre serveur NGINX.\n./app/artificial_load.sh Naviguer dans l\u0026rsquo;application Petclinic quelque instant pour générer un traffic utilisateur sur un navigateur web.\nLancez Kibana pour commencer à explorer les tableaux de bord qui ont été inclus dans le menu Observability\nCliquez sur le bouton View app\nVous pouvez observer que l\u0026rsquo;agent beat réalise 3 vérification de disponibilité. Un pour chaque service de l\u0026rsquo;application.\nCliquez sur le monitor Nginx Status\nVous avez maintenant un vue détaillée du service nginx comme les temps de réponses, la disponibilité, etc\u0026hellip;\nParcours utilisateurs L\u0026rsquo;agent Hearbeat permet de simuler un parcours utilisateur via un navigateur. Ce type de vérification permet de valider en tout temps les scénarios d\u0026rsquo;un site web.\nModifiez la configuration de l\u0026rsquo;agent Heratbeat\nvim beats/conf/heartbeat.yml Ajouter les tests de navigation\n- type: browser\rid: home2edit-monitor\rname: Home -\u0026gt; Edit Owner journey\rschedule: \u0026#34;@every 10s\u0026#34;\rsource:\rinline:\rscript: |-\rstep(\u0026#34;load homepage\u0026#34;, async () =\u0026gt; {\rawait page.goto(\u0026#39;http://localhost:8081/\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\rstep(\u0026#34;click on find owners\u0026#34;, async () =\u0026gt; {\rawait page.click(\u0026#39;#main-navbar \u0026gt; ul \u0026gt; li:nth-child(3) \u0026gt; a\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\rstep(\u0026#34;click on find owners button\u0026#34;, async () =\u0026gt; {\rawait page.click(\u0026#39;#search-owner-form \u0026gt; div:nth-child(2) \u0026gt; div \u0026gt; button\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\rstep(\u0026#34;click on Eduardo Rodriguez\u0026#34;, async () =\u0026gt; {\rawait page.click(\u0026#39;#vets \u0026gt; tbody \u0026gt; tr:nth-child(3) \u0026gt; td:nth-child(1) \u0026gt; a\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\rstep(\u0026#34;click on edit owner button\u0026#34;, async () =\u0026gt; {\rawait page.click(\u0026#39;body \u0026gt; div.container-fluid \u0026gt; div \u0026gt; a:nth-child(3)\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\r- type: browser\rid: home2vets-monitor\rname: Home -\u0026gt; Show Vets journey\rschedule: \u0026#34;@every 10s\u0026#34;\rsource:\rinline:\rscript: |-\rstep(\u0026#34;load homepage\u0026#34;, async () =\u0026gt; {\rawait page.goto(\u0026#39;http://localhost:8081/\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\rstep(\u0026#34;click on vets\u0026#34;, async () =\u0026gt; {\rawait page.click(\u0026#39;#main-navbar \u0026gt; ul \u0026gt; li:nth-child(4) \u0026gt; a\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\r- type: browser\rid: home2addpet-monitor\rname: Home -\u0026gt; Add Owner journey\rschedule: \u0026#34;@every 10s\u0026#34;\rsource:\rinline:\rscript: |-\rstep(\u0026#34;load homepage\u0026#34;, async () =\u0026gt; {\rawait page.goto(\u0026#39;http://localhost:8081/\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\rstep(\u0026#34;click on find owners\u0026#34;, async () =\u0026gt; {\rawait page.click(\u0026#39;#main-navbar \u0026gt; ul \u0026gt; li:nth-child(3) \u0026gt; a\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\rstep(\u0026#34;click on add Owner button\u0026#34;, async () =\u0026gt; {\rawait page.click(\u0026#39;body \u0026gt; div.container-fluid \u0026gt; div \u0026gt; a\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\r- type: browser\rid: error-monitor\rname: Home -\u0026gt; Error journey\rschedule: \u0026#34;@every 10s\u0026#34;\rsource:\rinline:\rscript: |-\rstep(\u0026#34;load homepage\u0026#34;, async () =\u0026gt; {\rawait page.goto(\u0026#39;http://localhost:8081/\u0026#39;);\rawait page.waitForRequest(/intake/);\r});\rstep(\u0026#34;click on error\u0026#34;, async () =\u0026gt; {\rawait page.click(\u0026#39;#main-navbar \u0026gt; ul \u0026gt; li:nth-child(5) \u0026gt; a\u0026#39;);\rawait page.waitForRequest(/intake/); Vous pouvez naviguer dans l\u0026rsquo;interface Kibana Uptime pour visualiser les parcours utilisateurs :\nVous pouvez naviguer le parcours utilisateur Home -\u0026gt; Show Vets journey - inline pour visualiser les données de performances ainsi ques des captures d\u0026rsquo;écran :\nA vous de jouez ! On peut constater au travers des autres parcours utilisateurs que l\u0026rsquo;application n\u0026rsquo;a pas le comportement attendu. Proposer moi une analyse permettant de comprendre l\u0026rsquo;origine du problème grace a la solution Elastic. Et proposer moi une solution pour corriger le dysfonctionnement.\nRésumé : Dans ce laboratoire, vous avez exploré la facilité avec laquelle vous pouvez obtenir des mesures des vos services liée à l\u0026rsquo;application Petclinic avec Heartbeat et les indexer dans Elasticsearch. Vous avez également exploré les tableaux de bord Kibana et vu avec quelle facilité vous pouvez surveiller ces mesures.\n"},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/%C3%A9l%C3%A9mentaire/","title":"Elementaire","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/avance/tp_query/","title":"TP : Définir et exécuter des requêtes de recherche dans Elasticsearch","tags":[],"description":"","content":"Description Savoir comment collecter, analyser, enrichir et indexer des données dans Elasticsearch est important, mais savoir comment poser des questions précises sur les données est encore plus crucial. Après tout, vous ne pouvez pas épeler \u0026ldquo;Elasticsearch\u0026rdquo; sans \u0026ldquo;recherche\u0026rdquo; ! Que vous utilisiez Elasticsearch pour la recherche de sites, la recherche de produits, l\u0026rsquo;analyse opérationnelle ou la veille stratégique, savoir formuler des requêtes de recherche complexes est essentiel pour tirer de la valeur de toutes ces données que vous avez réussi à collecter, analyser, enrichir et indexer. Dans ce laboratoire pratique, vous allez effectuer les tâches suivantes :\n Rechercher un terme spécifique dans un champ Appliquer un filtre de recherche pour réduire l\u0026rsquo;ensemble de données recherchables Trier les données résultantes Mettre en évidence le terme recherché dans les résultats Paginer les résultats de la recherche  Vous travaillez en tant que consultant Elasticsearch et avez été engagé par une université locale qui cherche à mettre en œuvre Elasticsearch pour la recherche littéraire. L\u0026rsquo;équipe avec laquelle vous travaillez crée une interface utilisateur qui permettra aux étudiants d\u0026rsquo;effectuer des analyses de recherche sur diverses œuvres littéraires. La configuration de test avec laquelle vous travaillez est un cluster Elasticsearch à 6 nœuds chargé des œuvres complètes de Shakespeare. Pour que l\u0026rsquo;interface utilisateur affiche les résultats de recherche souhaités, vous devez aider l\u0026rsquo;équipe à proposer deux requêtes de recherche qui répondent aux exigences.\nPréparation PUT /shakespeare { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;speaker\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;play_name\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;line_id\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, \u0026#34;speech_number\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;} } } } curl -H \u0026#39;Content-Type: application/x-ndjson\u0026#39; -XPOST \u0026#39;localhost:9200/bank/account/_bulk?pretty\u0026#39; --data-binary @accounts.json curl -H \u0026#39;Content-Type: application/x-ndjson\u0026#39; -XPOST \u0026#39;localhost:9200/shakespeare/doc/_bulk?pretty\u0026#39; --data-binary @shakespeare_6.0.json GET _cat/nodes?v GET _cat/indices?v Créer une requête de recherche qui répond aux exigences de la requête Requête :\n Le type du document doit être une \u0026ldquo;scène\u0026rdquo;. Le champ text_entry doit contenir une forme du mot \u0026ldquo;london\u0026rdquo;. La pièce doit être parmi \u0026ldquo;Henry VI Part 1\u0026rdquo;, \u0026ldquo;Henry VI Part 2\u0026rdquo;, ou \u0026ldquo;Henry VI Part 3\u0026rdquo;. La taille du tableau des résultats doit être égale au nombre de résultats. Les résultats sont d\u0026rsquo;abord triés par nom de la pièce dans l\u0026rsquo;ordre croissant, puis par numéro de ligne dans l\u0026rsquo;ordre croissant.  "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/","title":"Intermediare","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/reindex/","title":"Labs - Reindex","tags":[],"description":"","content":"Description Que vous ayez besoin de modifier le mappage d\u0026rsquo;un index existant ou de prendre un sous-ensemble de données d\u0026rsquo;un index et de le copier dans un autre, l\u0026rsquo;API _reindex d\u0026rsquo;Elasticsearch vous couvre. Avec l\u0026rsquo;API _reindex, vous pouvez prendre toutes les données ou seulement un sous-ensemble de données d\u0026rsquo;un index et les copier dans un autre. Dans ce laboratoire pratique, vous aurez l\u0026rsquo;occasion de faire les exercices suivants :\n Réindexer un sous-ensemble de données d\u0026rsquo;un index vers un nouvel index. Créer un pipeline de nœuds d\u0026rsquo;ingestion Transformer les données pendant le processus de réindexation  Vous travaillez en tant que bibliothécaire de recherche et vous étudiez actuellement les œuvres de Shakespeare, en particulier Roméo et Juliette. Vous avez un cluster Elasticsearch à 6 nœuds et les œuvres complètes de Shakespeare, que vous utilisez pour votre analyse littéraire. Actuellement, les œuvres complètes de Shakespeare sont indexées dans un seul index appelé shakespeare, mais, comme vous vous concentrez actuellement sur la pièce Roméo et Juliette, vous préférez copier cette pièce dans son propre index.\nPour ce faire, vous devrez d\u0026rsquo;abord créer un nouvel index appelé romeo_and_juliet avec les mêmes mappages de champs que l\u0026rsquo;index shakespeare. Comme votre cluster Elasticsearch à 3 nœuds ne compte que 4 nœuds de données, vous souhaitez créer l\u0026rsquo;index romeo_and_juliet avec 4 shards primaires et 3 shards répliques pour une réplication maximale. Une fois l\u0026rsquo;index romeo_and_juliet créé, vous devrez utiliser l\u0026rsquo;API _reindex pour copier tous les documents dont le nom de pièce est \u0026ldquo;Romeo and Juliet\u0026rdquo; vers l\u0026rsquo;index romeo_and_juliet.\nEn plus de copier les données de la pièce Roméo et Juliette dans son propre index, vous souhaitez également modifier les données en cours de route pendant le processus de réindexation. Plus précisément, vous voulez prendre le contenu du champ text_entry et stocker chaque mot délimité par des espaces dans un tableau appelé word_array. En outre, vous voulez ajouter un champ word_count qui est égal au nombre de mots dans le champ word_array. Enfin, comme l\u0026rsquo;index ne contiendra que les données relatives à la pièce Roméo et Juliette, nous pouvons supprimer le champ play_name. Tout ceci peut être accompli avec un pipeline de nœuds d\u0026rsquo;acquisition utilisant les processeurs split, script et remove.\nPréparation des données PUT /shakespeare { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;speaker\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;play_name\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;}, \u0026#34;line_id\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, \u0026#34;speech_number\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;} } } } curl --location --request POST \u0026#39;https://localhost:9200/bank/account/_bulk?pretty\u0026#39; \\ --header \u0026#39;Content-Type: application/x-ndjson\u0026#39; \\ --header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\ --data-binary @accounts.json curl --location --request POST \u0026#39;https://localhost:9200/shakespeare/doc/_bulk?pretty\u0026#39; \\ --header \u0026#39;Content-Type: application/x-ndjson\u0026#39; \\ --header \u0026#39;Authorization: Basic ZWxhc3RpYzpXc1dnVkFUaUUxSWxsd2tEUXlQbw==\u0026#39; \\ --data-binary @shakespeare.json Créer l\u0026rsquo;index romeo_and_juiliet PUT romeo_and_juliet { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;line_id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;line_number\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 } } }, \u0026#34;play_name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;speaker\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;speech_number\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;text_entry\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 } } }, \u0026#34;type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;keyword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34;: 256 } } } } }, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 4, \u0026#34;number_of_replicas\u0026#34;: 3 } } Créer le shakespeare-tokenizer ingest node pipeline PUT _ingest/pipeline/shakespeare-tokenizer { \u0026#34;description\u0026#34;: \u0026#34;Tokenizes the text_entry field into an array. Adds a word_count field. Removes the play_name field.\u0026#34;, \u0026#34;processors\u0026#34;: [ { \u0026#34;split\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;text_entry\u0026#34;, \u0026#34;separator\u0026#34;: \u0026#34;\\\\s+\u0026#34;, \u0026#34;target_field\u0026#34;: \u0026#34;word_array\u0026#34; } }, { \u0026#34;script\u0026#34;: { \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;ctx.word_count = ctx.word_array.length\u0026#34; } }, { \u0026#34;remove\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;play_name\u0026#34; } } ] } Reindex le champ play \u0026ldquo;Romeo and Juliet\u0026rdquo; POST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;shakespeare\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;play_name\u0026#34;: \u0026#34;Romeo and Juliet\u0026#34; } } }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;romeo_and_juliet\u0026#34;, \u0026#34;pipeline\u0026#34;: \u0026#34;shakespeare-tokenizer\u0026#34; } } "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/intermediare/crud_documents/","title":"Labs - CRUD","tags":[],"description":"","content":"Description Quelle que soit la façon dont vous comptez utiliser Elasticsearch, il est essentiel de comprendre comment créer, mettre à jour et supprimer rapidement des documents dans Elasticsearch. Dans cette activité d\u0026rsquo;apprentissage, vous allez effectuer les tâches suivantes :\n Créer des documents dans Elasticsearch Mettre à jour des documents existants dans Elasticsearch Supprimer des documents d\u0026rsquo;un index Elasticsearch  Vous travaillez en tant qu\u0026rsquo;administrateur Elasticsearch pour une société bancaire. Un récent échec de déploiement et un retour en arrière de votre logiciel bancaire ont désynchronisé certaines actions qui ont été prises sur quelques comptes. Pour corriger rapidement la désynchronisation, on vous demande d\u0026rsquo;effectuer des opérations CRUD manuelles sur l\u0026rsquo;index bancaire dans Elasticsearch.\nUn compte doit être ajouté avec les données client suivantes :\n Numéro de compte : 1000 Solde : 65 536 Prénom : Jean Nom de famille : Doe Age : 23 ans Sexe : masculin Homme Adresse : 125 Bear Creek Pkwy Employeur : Linux Academy Courriel : john@linuxacademy.com Ville : Keller Etat : TX  Le compte 100 a changé d\u0026rsquo;adresse et les champs suivants doivent être mis à jour :\n Adresse : 1600 Pennsylvania Ave NW Ville : Washington Etat : DC  Créer Account 1000 PUT bank/_doc/1000 { \u0026#34;account_number\u0026#34;: 1000, \u0026#34;balance\u0026#34;: 65536, \u0026#34;firstname\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastname\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;age\u0026#34;: 23, \u0026#34;gender\u0026#34;: \u0026#34;M\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;125 Bear Creek Pkwy\u0026#34;, \u0026#34;employer\u0026#34;: \u0026#34;Linux Academy\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john@linuxacademy.com\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Keller\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;TX\u0026#34; } Mise à jour Account 100 POST bank/_update/100/ { \u0026#34;doc\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;1600 Pennsylvania Ave NW\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Washington\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;DC\u0026#34; } } Supprimer accounts 1 et 10 DELETE bank/_doc/1 DELETE bank/_doc/10 "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/avance/","title":"Avancé","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/avance/fleet/","title":"Bonus - Fleet &amp; Elastic Agent","tags":[],"description":"","content":"Serveur Fleet Fleet Server est un composant de la pile Elastic utilisé pour gérer de manière centralisée les agents Elastic. Il est lancé en tant que partie d\u0026rsquo;un agent Elastic sur un hôte destiné à servir de serveur. Un processus Fleet Server peut prendre en charge de nombreuses connexions d\u0026rsquo;agents Elastic et sert de plan de contrôle pour la mise à jour des stratégies d\u0026rsquo;agents, la collecte d\u0026rsquo;informations d\u0026rsquo;état et la coordination des actions entre les agents Elastic.\nFleet Server est le mécanisme utilisé par les agents Elastic pour communiquer avec Elasticsearch :\n Lorsqu\u0026rsquo;une nouvelle politique d\u0026rsquo;agent est créée, elle est enregistrée dans Elasticsearch. Pour s\u0026rsquo;inscrire à la politique, les agents Elastic envoient une demande à Fleet Server, en utilisant la clé d\u0026rsquo;inscription générée pour l\u0026rsquo;authentification. Le serveur Fleet reçoit la demande et extrait la politique d\u0026rsquo;agent d\u0026rsquo;Elasticsearch, puis l\u0026rsquo;envoie à tous les agents Elastic inscrits à cette politique. L\u0026rsquo;agent Elastic utilise les informations de configuration de la politique pour collecter et envoyer des données à Elasticsearch. Elastic Agent vérifie les mises à jour auprès de Fleet Server, en maintenant une connexion ouverte. Lorsqu\u0026rsquo;une politique est mise à jour, Fleet Server récupère la politique mise à jour dans Elasticsearch et l\u0026rsquo;envoie aux agents Elastic connectés.  Ajoutez les deux services ci-dessous dans le fichier elastic-docker-tls.yml :\n package-registry:\rimage: docker.elastic.co/package-registry/distribution:${VERSION}\rcontainer_name: package-registry\rports:\r- 443\renvironment:\r- EPR_ADDRESS=0.0.0.0:443\r- EPR_TLS_KEY=$CERTS_DIR/package-registry/package-registry.key\r- EPR_TLS_CERT=$CERTS_DIR/package-registry/package-registry.crt\rhealthcheck:\rtest: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost/health \u0026gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi\rretries: 100\rinterval: 5s\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic\rfleet-server:\rimage: docker.elastic.co/beats/elastic-agent:${VERSION}\rcontainer_name: fleet-server\rports:\r- 8220:8220\rhealthcheck:\rtest: [\u0026#34;CMD-SHELL\u0026#34;, \u0026#34;curl -s -k https://localhost:8220/api/status | grep -q \u0026#39;HEALTHY\u0026#39;\u0026#34;]\rretries: 300\rinterval: 1s\renvironment:\rFLEET_SERVER_ENABLE: \u0026#34;1\u0026#34;\rELASTICSEARCH_HOST: \u0026#34;https://es01:9200\u0026#34;\rELASTICSEARCH_CA: $CERTS_DIR/ca/ca.crt\rELASTICSEARCH_USERNAME: elastic\rELASTICSEARCH_PASSWORD: CHANGEME\rFLEET_URL: \u0026#34;https://fleet-server:8220\u0026#34;\rFLEET_SERVER_CERT: $CERTS_DIR/fleet-server/fleet-server.crt\rFLEET_SERVER_CERT_KEY: $CERTS_DIR/fleet-server/fleet-server.key\rKIBANA_FLEET_SETUP: \u0026#34;true\u0026#34;\rKIBANA_HOST: \u0026#34;https://kib01:5601\u0026#34;\rKIBANA_USERNAME: elastic\rKIBANA_PASSWORD: CHANGEME\rKIBANA_CA: $CERTS_DIR/ca/ca.crt\rdepends_on:\res01: { condition: service_healthy }\rkib01: { condition: service_healthy }\rvolumes:\r- certs:$CERTS_DIR\rnetworks:\r- elastic Définissez ELASTICSEARCH_PASSWORD et KIBANA_PASSWORD dans le fichier elastic-docker-tls.yml avec le mot de passe généré pour l\u0026rsquo;utilisateur elastic.\nfleet-server:\rimage: docker.elastic.co/beats/elastic-agent:${VERSION}\rcontainer_name: fleet-server\rports:\r- 8220:8220\rhealthcheck:\rtest: [\u0026#34;CMD-SHELL\u0026#34;, \u0026#34;curl -s -k https://localhost:8220/api/status | grep -q \u0026#39;HEALTHY\u0026#39;\u0026#34;]\rretries: 300\rinterval: 1s\renvironment:\rFLEET_SERVER_ENABLE: \u0026#34;1\u0026#34;\rELASTICSEARCH_HOST: \u0026#34;https://es01:9200\u0026#34;\rELASTICSEARCH_CA: $CERTS_DIR/ca/ca.crt\rELASTICSEARCH_USERNAME: elastic\rELASTICSEARCH_PASSWORD: CHANGEME\rFLEET_URL: \u0026#34;https://fleet-server:8220\u0026#34;\rFLEET_SERVER_CERT: $CERTS_DIR/fleet-server/fleet-server.crt\rFLEET_SERVER_CERT_KEY: $CERTS_DIR/fleet-server/fleet-server.key\rKIBANA_FLEET_SETUP: \u0026#34;true\u0026#34;\rKIBANA_HOST: \u0026#34;https://kib01:5601\u0026#34;\rKIBANA_USERNAME: elastic\rKIBANA_PASSWORD: CHANGEME\rKIBANA_CA: $CERTS_DIR/ca/ca.crt docker-compose -f elastic-docker-tls.yml up -d Vérifiez la connexion entre le serveur Fleet et Kibana :\nManagement -\u0026gt; Fleet\nServeur APM Ajoutez le service ELastic Agent dans le fichier elastic-docker-tls.yml : :\n elastic-agent:\rimage: docker.elastic.co/beats/elastic-agent-complete:${VERSION}\rcontainer_name: elastic-agent\rrestart: always\ruser: root # note, synthetic browser monitors require this set to `elastic-agent`\renvironment:\rFLEET_ENROLL: 1\rFLEET_URL: \u0026#34;https://fleet-server:8220\u0026#34;\rFLEET_TOKEN_POLICY_NAME: \u0026#34;Default policy\u0026#34;\rFLEET_CA: $CERTS_DIR/ca/ca.crt\rKIBANA_FLEET_HOST: https://kib01:5601\rKIBANA_FLEET_USERNAME: elastic\rKIBANA_FLEET_PASSWORD: CHANGEME\rKIBANA_FLEET_CA: $CERTS_DIR/ca/ca.crt\rdepends_on:\res01: { condition: service_healthy }\rfleet-server: { condition: service_healthy }\rvolumes:\r- certs:$CERTS_DIR\r- /var/run/docker.sock:/var/run/docker.sock:ro\r- /var/log:/var/log:ro\r- /var/lib/docker/containers:/var/lib/docker/containers:ro\r- /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\r- /proc:/hostfs/proc:ro\r- /:/hostfs:ro\rnetworks:\r- elastic Modifier la configuration par défaut des agents elastic via le serveur fleet sur l\u0026rsquo;interface Kibana :\nManagement -\u0026gt; Fleet\nCliquez sur Fleet settings\nFleet Server Hosts\nhttps://fleet-server:8220 Elasticsearch Output Configuration (YAML)\nssl.certificate_authorities: [\u0026#34;/usr/share/elasticsearch/config/certificates/ca/ca.crt\u0026#34;] Définissez KIBANA_FLEET_PASSWORD dans le fichier elastic-docker-tls.yml avec le mot de passe généré pour l\u0026rsquo;utilisateur elastic.\n elastic-agent:\rimage: docker.elastic.co/beats/elastic-agent-complete:${VERSION}\rcontainer_name: elastic-agent\rrestart: always\ruser: root # note, synthetic browser monitors require this set to `elastic-agent`\renvironment:\rFLEET_ENROLL: 1\rFLEET_URL: \u0026#34;https://fleet-server:8220\u0026#34;\rFLEET_TOKEN_POLICY_NAME: \u0026#34;Default policy\u0026#34;\rFLEET_CA: $CERTS_DIR/ca/ca.crt\rKIBANA_FLEET_HOST: https://kib01:5601\rKIBANA_FLEET_USERNAME: elastic\rKIBANA_FLEET_PASSWORD: CHANGEME\rKIBANA_FLEET_CA: $CERTS_DIR/ca/ca.crt\rdepends_on:\res01: { condition: service_healthy }\rfleet-server: { condition: service_healthy }\rvolumes:\r- certs:$CERTS_DIR\r- /var/run/docker.sock:/var/run/docker.sock:ro\r- /var/log:/var/log:ro\r- /var/lib/docker/containers:/var/lib/docker/containers:ro\r- /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro\r- /proc:/hostfs/proc:ro\r- /:/hostfs:ro\rnetworks:\r- elastic Après quelques minutes vous devez voir apparaitre l\u0026rsquo;agent elastic sur l\u0026rsquo;interface Kibana.\nIntégration du module APM "},{"uri":"https://maxime-cls.github.io/elastic-tutorial/","title":"Elastic Tutoriel","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/elastic/","title":"Elastic","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/elastic-tutorial/tags/","title":"Tags","tags":[],"description":"","content":""}]